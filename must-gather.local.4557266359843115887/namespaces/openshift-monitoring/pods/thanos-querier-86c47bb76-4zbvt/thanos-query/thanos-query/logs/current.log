2022-05-24T18:28:18.340798824Z level=info ts=2022-05-24T18:28:18.340729658Z caller=client.go:55 msg="enabling client to server TLS"
2022-05-24T18:28:18.340869870Z level=info ts=2022-05-24T18:28:18.340829547Z caller=options.go:115 msg="TLS client using provided certificate pool"
2022-05-24T18:28:18.340869870Z level=info ts=2022-05-24T18:28:18.340840032Z caller=options.go:148 msg="TLS client authentication enabled"
2022-05-24T18:28:18.341704674Z ts=2022-05-24T18:28:18.341669991Z caller=log.go:168 level=debug msg="Lookback delta is zero, setting to default value" value=5m0s
2022-05-24T18:28:18.342759219Z level=info ts=2022-05-24T18:28:18.342733523Z caller=options.go:27 protocol=gRPC msg="disabled TLS, key and cert must be set to enable"
2022-05-24T18:28:18.343272646Z level=info ts=2022-05-24T18:28:18.34323778Z caller=query.go:618 msg="starting query node"
2022-05-24T18:28:18.343725521Z level=info ts=2022-05-24T18:28:18.343685962Z caller=intrumentation.go:60 msg="changing probe status" status=healthy
2022-05-24T18:28:18.343725521Z level=info ts=2022-05-24T18:28:18.343711646Z caller=http.go:63 service=http/server component=query msg="listening for requests and metrics" address=127.0.0.1:9090
2022-05-24T18:28:18.343974317Z ts=2022-05-24T18:28:18.343944389Z caller=log.go:168 service=http/server component=query level=info msg="TLS is disabled." http2=false
2022-05-24T18:28:18.344017060Z level=info ts=2022-05-24T18:28:18.344000597Z caller=intrumentation.go:48 msg="changing probe status" status=ready
2022-05-24T18:28:18.344118789Z level=info ts=2022-05-24T18:28:18.34407352Z caller=grpc.go:127 service=gRPC/server component=query msg="listening for serving gRPC" address=127.0.0.1:10901
2022-05-24T18:28:20.434117245Z level=error ts=2022-05-24T18:28:20.434054917Z caller=resolver.go:99 msg="failed to lookup SRV records" host=_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local err="no such host"
2022-05-24T18:28:20.450660642Z level=error ts=2022-05-24T18:28:20.45061614Z caller=resolver.go:99 msg="failed to lookup SRV records" host=_grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local err="no such host"
2022-05-24T18:28:20.450692199Z level=error ts=2022-05-24T18:28:20.450664041Z caller=query.go:488 msg="failed to resolve addresses for storeAPIs" err="lookup SRV records \"_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local\": could not resolve \"_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local\": all servers responded with errors to at least one search domain. Errs ;could not resolve _grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for _grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local.: exchange: read udp 10.131.0.15:35298->172.30.0.10:53: i/o timeout"
2022-05-24T18:28:20.457562908Z level=error ts=2022-05-24T18:28:20.45752612Z caller=resolver.go:99 msg="failed to lookup SRV records" host=_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local err="no such host"
2022-05-24T18:28:20.461481091Z level=error ts=2022-05-24T18:28:20.461449836Z caller=resolver.go:99 msg="failed to lookup SRV records" host=_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local err="no such host"
2022-05-24T18:28:20.467155207Z level=error ts=2022-05-24T18:28:20.467128856Z caller=resolver.go:99 msg="failed to lookup SRV records" host=_grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local err="no such host"
2022-05-24T18:28:20.470119045Z level=error ts=2022-05-24T18:28:20.470090271Z caller=resolver.go:99 msg="failed to lookup SRV records" host=_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local err="no such host"
2022-05-24T18:28:20.475399227Z level=error ts=2022-05-24T18:28:20.475372723Z caller=resolver.go:99 msg="failed to lookup SRV records" host=_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local err="no such host"
2022-05-24T18:28:48.351395432Z level=error ts=2022-05-24T18:28:48.351347184Z caller=resolver.go:99 msg="failed to lookup SRV records" host=_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local err="no such host"
2022-05-24T18:28:48.356290525Z level=error ts=2022-05-24T18:28:48.356257132Z caller=resolver.go:99 msg="failed to lookup SRV records" host=_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local err="no such host"
2022-05-24T18:28:48.363291140Z level=error ts=2022-05-24T18:28:48.36326685Z caller=resolver.go:99 msg="failed to lookup SRV records" host=_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local err="no such host"
2022-05-24T18:28:48.368159329Z level=error ts=2022-05-24T18:28:48.368135259Z caller=resolver.go:99 msg="failed to lookup SRV records" host=_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local err="no such host"
2022-05-24T18:28:48.378753829Z level=error ts=2022-05-24T18:28:48.378730485Z caller=resolver.go:99 msg="failed to lookup SRV records" host=_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local err="no such host"
2022-05-24T18:28:48.387827141Z level=error ts=2022-05-24T18:28:48.387802987Z caller=resolver.go:99 msg="failed to lookup SRV records" host=_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local err="no such host"
2022-05-24T18:28:53.356459254Z level=info ts=2022-05-24T18:28:53.356411196Z caller=endpointset.go:371 component=endpointset msg="adding new rule with [storeAPI rulesAPI]" address=10.131.0.19:10901 extLset="{thanos_ruler_replica=\"thanos-ruler-user-workload-0\"}"
2022-05-24T18:28:53.356497365Z level=info ts=2022-05-24T18:28:53.356449566Z caller=endpointset.go:371 component=endpointset msg="adding new rule with [storeAPI rulesAPI]" address=10.129.2.37:10901 extLset="{thanos_ruler_replica=\"thanos-ruler-user-workload-1\"}"
2022-05-24T18:29:10.615694493Z level=warn ts=2022-05-24T18:29:10.615648138Z caller=proxy.go:286 component=proxy request="min_time:1653416650600 max_time:1653416950600 matchers:<name:\"__name__\" value:\"etcd_server_leader_changes_seen_total\" > aggregates:COUNTER " err="No StoreAPIs matched for this query" stores="store Addr: 10.129.2.37:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 9223372036854775807 Maxt: 9223372036854775807 filtered out: does not have data within this time period: [1653416650600,1653416950600]. Store time ranges: [9223372036854775807,9223372036854775807];store Addr: 10.131.0.19:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-0\"} Mint: 9223372036854775807 Maxt: 9223372036854775807 filtered out: does not have data within this time period: [1653416650600,1653416950600]. Store time ranges: [9223372036854775807,9223372036854775807]"
2022-05-24T18:29:10.634124996Z level=warn ts=2022-05-24T18:29:10.634084379Z caller=proxy.go:286 component=proxy request="min_time:1653416650627 max_time:1653416950627 matchers:<name:\"__name__\" value:\"etcd_server_leader_changes_seen_total\" > aggregates:COUNTER " err="No StoreAPIs matched for this query" stores="store Addr: 10.131.0.19:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-0\"} Mint: 9223372036854775807 Maxt: 9223372036854775807 filtered out: does not have data within this time period: [1653416650627,1653416950627]. Store time ranges: [9223372036854775807,9223372036854775807];store Addr: 10.129.2.37:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 9223372036854775807 Maxt: 9223372036854775807 filtered out: does not have data within this time period: [1653416650627,1653416950627]. Store time ranges: [9223372036854775807,9223372036854775807]"
2022-05-24T18:29:10.665686056Z level=warn ts=2022-05-24T18:29:10.665636971Z caller=proxy.go:286 component=proxy request="min_time:1653416650655 max_time:1653416950655 matchers:<name:\"__name__\" value:\"etcd_server_leader_changes_seen_total\" > aggregates:COUNTER " err="No StoreAPIs matched for this query" stores="store Addr: 10.131.0.19:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-0\"} Mint: 9223372036854775807 Maxt: 9223372036854775807 filtered out: does not have data within this time period: [1653416650655,1653416950655]. Store time ranges: [9223372036854775807,9223372036854775807];store Addr: 10.129.2.37:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 9223372036854775807 Maxt: 9223372036854775807 filtered out: does not have data within this time period: [1653416650655,1653416950655]. Store time ranges: [9223372036854775807,9223372036854775807]"
2022-05-24T18:29:10.810126575Z level=warn ts=2022-05-24T18:29:10.810085245Z caller=proxy.go:286 component=proxy request="min_time:1653416650799 max_time:1653416950799 matchers:<name:\"__name__\" value:\"etcd_server_leader_changes_seen_total\" > aggregates:COUNTER " err="No StoreAPIs matched for this query" stores="store Addr: 10.131.0.19:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-0\"} Mint: 9223372036854775807 Maxt: 9223372036854775807 filtered out: does not have data within this time period: [1653416650799,1653416950799]. Store time ranges: [9223372036854775807,9223372036854775807];store Addr: 10.129.2.37:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 9223372036854775807 Maxt: 9223372036854775807 filtered out: does not have data within this time period: [1653416650799,1653416950799]. Store time ranges: [9223372036854775807,9223372036854775807]"
2022-05-24T18:29:18.292188886Z level=warn ts=2022-05-24T18:29:18.292142783Z caller=proxy.go:286 component=proxy request="min_time:1653416658256 max_time:1653416958256 matchers:<name:\"__name__\" value:\"etcd_server_leader_changes_seen_total\" > aggregates:COUNTER " err="No StoreAPIs matched for this query" stores="store Addr: 10.129.2.37:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 9223372036854775807 Maxt: 9223372036854775807 filtered out: does not have data within this time period: [1653416658256,1653416958256]. Store time ranges: [9223372036854775807,9223372036854775807];store Addr: 10.131.0.19:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-0\"} Mint: 9223372036854775807 Maxt: 9223372036854775807 filtered out: does not have data within this time period: [1653416658256,1653416958256]. Store time ranges: [9223372036854775807,9223372036854775807]"
2022-05-24T18:29:18.380839115Z level=error ts=2022-05-24T18:29:18.380777068Z caller=query.go:491 msg="failed to resolve addresses for rulesAPIs" err="2 errors: lookup SRV records \"_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local\": could not resolve \"_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local\": all servers responded with errors to at least one search domain. Errs ;could not resolve _grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for _grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local.: exchange: read udp 10.131.0.15:60885->172.30.0.10:53: read: connection refused; lookup SRV records \"_grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local\": could not resolve \"_grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local\": all servers responded with errors to at least one search domain. Errs ;could not resolve _grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for _grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.: exchange: read udp 10.131.0.15:52443->172.30.0.10:53: read: connection refused;could not resolve _grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for _grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.cluster.local.: exchange: read udp 10.131.0.15:44890->172.30.0.10:53: read: connection refused"
2022-05-24T18:29:18.385244923Z level=error ts=2022-05-24T18:29:18.385208214Z caller=query.go:494 msg="failed to resolve addresses for targetsAPIs" err="lookup IP addresses \"_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local\": could not resolve \"prometheus-k8s-1.prometheus-operated.openshift-monitoring.svc.cluster.local.\": all servers responded with errors to at least one search domain. Errs ;could not resolve prometheus-k8s-1.prometheus-operated.openshift-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for prometheus-k8s-1.prometheus-operated.openshift-monitoring.svc.cluster.local.: exchange: read udp 10.131.0.15:54564->172.30.0.10:53: read: connection refused"
2022-05-24T18:29:20.870952294Z level=warn ts=2022-05-24T18:29:20.870887949Z caller=proxy.go:286 component=proxy request="min_time:1653416660858 max_time:1653416960858 matchers:<name:\"__name__\" value:\"etcd_server_leader_changes_seen_total\" > aggregates:COUNTER " err="No StoreAPIs matched for this query" stores="store Addr: 10.131.0.19:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-0\"} Mint: 9223372036854775807 Maxt: 9223372036854775807 filtered out: does not have data within this time period: [1653416660858,1653416960858]. Store time ranges: [9223372036854775807,9223372036854775807];store Addr: 10.129.2.37:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 9223372036854775807 Maxt: 9223372036854775807 filtered out: does not have data within this time period: [1653416660858,1653416960858]. Store time ranges: [9223372036854775807,9223372036854775807]"
2022-05-24T18:29:23.356496537Z level=info ts=2022-05-24T18:29:23.356451324Z caller=endpointset.go:371 component=endpointset msg="adding new sidecar with [storeAPI rulesAPI exemplarsAPI targetsAPI MetricMetadataAPI]" address=10.130.2.14:10901 extLset="{prometheus=\"openshift-monitoring/k8s\", prometheus_replica=\"prometheus-k8s-1\"}"
2022-05-24T18:29:23.356496537Z level=info ts=2022-05-24T18:29:23.356483268Z caller=endpointset.go:371 component=endpointset msg="adding new sidecar with [storeAPI rulesAPI exemplarsAPI targetsAPI MetricMetadataAPI]" address=10.129.2.36:10901 extLset="{prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"}"
2022-05-24T18:29:23.356530080Z level=info ts=2022-05-24T18:29:23.356498524Z caller=endpointset.go:371 component=endpointset msg="adding new sidecar with [storeAPI rulesAPI exemplarsAPI targetsAPI MetricMetadataAPI]" address=10.131.0.17:10901 extLset="{prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-0\"}"
2022-05-24T18:33:23.353704206Z level=info ts=2022-05-24T18:33:23.353656156Z caller=endpointset.go:371 component=endpointset msg="adding new sidecar with [storeAPI rulesAPI exemplarsAPI targetsAPI MetricMetadataAPI]" address=10.131.2.8:10901 extLset="{prometheus=\"openshift-monitoring/k8s\", prometheus_replica=\"prometheus-k8s-0\"}"
2022-05-24T18:33:28.343907700Z level=warn ts=2022-05-24T18:33:28.343855746Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.129.2.37:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.37:10901: connect: connection refused\"" address=10.129.2.37:10901
2022-05-24T18:33:28.345242526Z level=info ts=2022-05-24T18:33:28.345213685Z caller=endpointset.go:348 component=endpointset msg="removing endpoint because it's unhealthy or does not exist" address=10.129.2.37:10901 extLset="{thanos_ruler_replica=\"thanos-ruler-user-workload-1\"}"
2022-05-24T18:33:33.345763085Z level=warn ts=2022-05-24T18:33:33.345715495Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.129.2.37:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.37:10901: connect: connection refused\"" address=10.129.2.37:10901
2022-05-24T18:33:38.345302518Z level=warn ts=2022-05-24T18:33:38.345254956Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.129.2.37:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.37:10901: connect: connection refused\"" address=10.129.2.37:10901
2022-05-24T18:33:43.353921600Z level=info ts=2022-05-24T18:33:43.353877002Z caller=endpointset.go:371 component=endpointset msg="adding new rule with [storeAPI rulesAPI]" address=10.129.2.37:10901 extLset="{thanos_ruler_replica=\"thanos-ruler-user-workload-1\"}"
2022-05-24T18:34:58.343791231Z level=warn ts=2022-05-24T18:34:58.343740634Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.130.2.14:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.130.2.14:10901: connect: connection refused\"" address=10.130.2.14:10901
2022-05-24T18:34:58.345115942Z level=info ts=2022-05-24T18:34:58.345084135Z caller=endpointset.go:348 component=endpointset msg="removing endpoint because it's unhealthy or does not exist" address=10.130.2.14:10901 extLset="{prometheus=\"openshift-monitoring/k8s\", prometheus_replica=\"prometheus-k8s-1\"}"
2022-05-24T18:35:03.345697620Z level=warn ts=2022-05-24T18:35:03.345651482Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.130.2.14:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.130.2.14:10901: connect: connection refused\"" address=10.130.2.14:10901
2022-05-24T18:35:08.344483601Z level=warn ts=2022-05-24T18:35:08.344432773Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.130.2.14:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.130.2.14:10901: connect: connection refused\"" address=10.130.2.14:10901
2022-05-24T18:35:13.345887383Z level=warn ts=2022-05-24T18:35:13.345825338Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.130.2.14:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.130.2.14:10901: connect: connection refused\"" address=10.130.2.14:10901
2022-05-24T18:35:18.344610905Z level=warn ts=2022-05-24T18:35:18.344539619Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.130.2.14:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.130.2.14:10901: connect: connection refused\"" address=10.130.2.14:10901
2022-05-24T18:38:18.353885760Z level=error ts=2022-05-24T18:38:18.353833571Z caller=query.go:488 msg="failed to resolve addresses for storeAPIs" err="lookup IP addresses \"_grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local\": could not resolve \"10-129-2-37.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.\": all servers responded with errors to at least one search domain. Errs ;could not resolve 10-129-2-37.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for 10-129-2-37.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.: exchange: read udp 10.131.0.15:40705->172.30.0.10:53: read: connection refused"
2022-05-24T18:38:18.372308574Z level=error ts=2022-05-24T18:38:18.372268405Z caller=query.go:491 msg="failed to resolve addresses for rulesAPIs" err="2 errors: lookup IP addresses \"_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local\": could not resolve \"prometheus-k8s-0.prometheus-operated.openshift-monitoring.svc.cluster.local.\": all servers responded with errors to at least one search domain. Errs ;could not resolve prometheus-k8s-0.prometheus-operated.openshift-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for prometheus-k8s-0.prometheus-operated.openshift-monitoring.svc.cluster.local.: exchange: read udp 10.131.0.15:35477->172.30.0.10:53: read: connection refused; lookup SRV records \"_grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local\": could not resolve \"_grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local\": all servers responded with errors to at least one search domain. Errs ;could not resolve _grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for _grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.: exchange: read udp 10.131.0.15:57649->172.30.0.10:53: read: connection refused;could not resolve _grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for _grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.svc.cluster.local.: exchange: read udp 10.131.0.15:46014->172.30.0.10:53: read: connection refused"
2022-05-24T18:38:20.378752748Z level=error ts=2022-05-24T18:38:20.378689174Z caller=query.go:494 msg="failed to resolve addresses for targetsAPIs" err="2 errors: lookup IP addresses \"_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local\": could not resolve \"prometheus-k8s-0.prometheus-operated.openshift-monitoring.svc.cluster.local.\": all servers responded with errors to at least one search domain. Errs ;could not resolve prometheus-k8s-0.prometheus-operated.openshift-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for prometheus-k8s-0.prometheus-operated.openshift-monitoring.svc.cluster.local.: exchange: read udp 10.131.0.15:53175->172.30.0.10:53: read: connection refused; lookup SRV records \"_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local\": could not resolve \"_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local\": all servers responded with errors to at least one search domain. Errs ;could not resolve _grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for _grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local.: exchange: read udp 10.131.0.15:44139->172.30.0.10:53: i/o timeout"
2022-05-24T18:38:33.344867354Z level=warn ts=2022-05-24T18:38:33.344816724Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.131.0.19:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.131.0.19:10901: connect: connection refused\"" address=10.131.0.19:10901
2022-05-24T18:38:33.346173894Z level=info ts=2022-05-24T18:38:33.346145207Z caller=endpointset.go:348 component=endpointset msg="removing endpoint because it's unhealthy or does not exist" address=10.131.0.19:10901 extLset="{thanos_ruler_replica=\"thanos-ruler-user-workload-0\"}"
2022-05-24T18:38:38.344922473Z level=warn ts=2022-05-24T18:38:38.344870303Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.131.0.19:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.131.0.19:10901: connect: connection refused\"" address=10.131.0.19:10901
2022-05-24T18:38:43.350726795Z level=info ts=2022-05-24T18:38:43.350680802Z caller=endpointset.go:371 component=endpointset msg="adding new rule with [storeAPI rulesAPI]" address=10.131.0.19:10901 extLset="{thanos_ruler_replica=\"thanos-ruler-user-workload-0\"}"
2022-05-24T18:39:54.353045360Z level=error ts=2022-05-24T18:39:54.352990674Z caller=query.go:488 msg="failed to resolve addresses for storeAPIs" err="lookup IP addresses \"_grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local\": could not resolve \"10-129-2-37.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.\": all servers responded with errors to at least one search domain. Errs ;could not resolve 10-129-2-37.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for 10-129-2-37.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.: exchange: read udp 10.131.0.15:39212->172.30.0.10:53: i/o timeout"
2022-05-24T18:40:00.374314421Z level=error ts=2022-05-24T18:40:00.37425612Z caller=query.go:494 msg="failed to resolve addresses for targetsAPIs" err="2 errors: lookup SRV records \"_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local\": could not resolve \"_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local\": all servers responded with errors to at least one search domain. Errs ;could not resolve _grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for _grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local.: exchange: read udp 10.131.0.15:47640->172.30.0.10:53: i/o timeout; lookup SRV records \"_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local\": could not resolve \"_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local\": all servers responded with errors to at least one search domain. Errs ;could not resolve _grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for _grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local.: exchange: read udp 10.131.0.15:40588->172.30.0.10:53: i/o timeout"
2022-05-24T18:40:53.352400205Z level=info ts=2022-05-24T18:40:53.35234898Z caller=endpointset.go:371 component=endpointset msg="adding new sidecar with [storeAPI rulesAPI exemplarsAPI targetsAPI MetricMetadataAPI]" address=10.130.2.11:10901 extLset=
2022-05-24T18:41:03.824046702Z level=error ts=2022-05-24T18:41:03.823995327Z caller=proxy.go:314 component=proxy request="min_time:1653417363820 max_time:1653417663820 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mds_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:04.158440047Z level=error ts=2022-05-24T18:41:04.158389308Z caller=proxy.go:314 component=proxy request="min_time:1653417364153 max_time:1653417664153 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:04.158685209Z level=error ts=2022-05-24T18:41:04.158653708Z caller=proxy.go:314 component=proxy request="min_time:1653417364153 max_time:1653417664153 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:04.162093707Z level=error ts=2022-05-24T18:41:04.162053915Z caller=proxy.go:314 component=proxy request="min_time:1653417364153 max_time:1653417664153 matchers:<type:RE name:\"deployment\" value:\"rook-ceph-mgr-.*\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_deployment_spec_replicas\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.852939491Z level=error ts=2022-05-24T18:41:05.852893142Z caller=proxy.go:314 component=proxy request="min_time:1653417365846 max_time:1653417665846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.853330453Z level=error ts=2022-05-24T18:41:05.853303966Z caller=proxy.go:314 component=proxy request="min_time:1653417365846 max_time:1653417665846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.853738362Z level=error ts=2022-05-24T18:41:05.853712803Z caller=proxy.go:314 component=proxy request="min_time:1653417365846 max_time:1653417665846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.853808975Z level=error ts=2022-05-24T18:41:05.853787146Z caller=proxy.go:314 component=proxy request="min_time:1653417365846 max_time:1653417665846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_used_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.855076582Z level=error ts=2022-05-24T18:41:05.855050244Z caller=proxy.go:314 component=proxy request="min_time:1653417365846 max_time:1653417665846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.855105190Z level=error ts=2022-05-24T18:41:05.855087619Z caller=proxy.go:314 component=proxy request="min_time:1653417365846 max_time:1653417665846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_capacity_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.858293061Z level=error ts=2022-05-24T18:41:05.858257236Z caller=proxy.go:314 component=proxy request="min_time:1653417365846 max_time:1653417665846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.858840152Z level=error ts=2022-05-24T18:41:05.85881045Z caller=proxy.go:314 component=proxy request="min_time:1653417365846 max_time:1653417665846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.859166087Z level=error ts=2022-05-24T18:41:05.859142745Z caller=proxy.go:314 component=proxy request="min_time:1653417365846 max_time:1653417665846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_used_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.859359035Z level=error ts=2022-05-24T18:41:05.859337247Z caller=proxy.go:314 component=proxy request="min_time:1653417365846 max_time:1653417665846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.859996261Z level=error ts=2022-05-24T18:41:05.859969783Z caller=proxy.go:314 component=proxy request="min_time:1653417365846 max_time:1653417665846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_capacity_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.860698877Z level=error ts=2022-05-24T18:41:05.860670345Z caller=proxy.go:314 component=proxy request="min_time:1653417365846 max_time:1653417665846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.938605333Z level=error ts=2022-05-24T18:41:05.938552024Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.938685728Z level=error ts=2022-05-24T18:41:05.93866208Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes_used\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.938713918Z level=error ts=2022-05-24T18:41:05.938696996Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.942403703Z level=error ts=2022-05-24T18:41:05.942367558Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.951477510Z level=error ts=2022-05-24T18:41:05.951443514Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.951499689Z level=error ts=2022-05-24T18:41:05.95148038Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes_used\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.951524946Z level=error ts=2022-05-24T18:41:05.951508526Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.955210135Z level=error ts=2022-05-24T18:41:05.955175386Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.955236128Z level=error ts=2022-05-24T18:41:05.955216273Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.955261977Z level=error ts=2022-05-24T18:41:05.955243822Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_in\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.958762720Z level=error ts=2022-05-24T18:41:05.95872412Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.958843380Z level=error ts=2022-05-24T18:41:05.958820523Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_in\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.958945998Z level=error ts=2022-05-24T18:41:05.95891953Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.963088910Z level=error ts=2022-05-24T18:41:05.963058668Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_healthcheck_slow_ops\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.966123785Z level=error ts=2022-05-24T18:41:05.966091746Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pg_undersized\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:05.968998314Z level=error ts=2022-05-24T18:41:05.968963728Z caller=proxy.go:314 component=proxy request="min_time:1653417365935 max_time:1653417665935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pg_inconsistent\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:06.135042876Z level=error ts=2022-05-24T18:41:06.134994661Z caller=proxy.go:314 component=proxy request="min_time:1653417366131 max_time:1653417666131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_quorum_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:06.135219799Z level=error ts=2022-05-24T18:41:06.135196011Z caller=proxy.go:314 component=proxy request="min_time:1653417366131 max_time:1653417666131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:06.138702580Z level=error ts=2022-05-24T18:41:06.138666629Z caller=proxy.go:314 component=proxy request="min_time:1653417366131 max_time:1653417666131 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"phase\" value:\"Running|running\" > matchers:<type:RE name:\"pod\" value:\"rook-ceph-mon-.*\" > matchers:<name:\"__name__\" value:\"kube_pod_status_phase\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:06.142109842Z level=error ts=2022-05-24T18:41:06.142073405Z caller=proxy.go:314 component=proxy request="min_time:1653417366131 max_time:1653417666131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:06.142276280Z level=error ts=2022-05-24T18:41:06.142236893Z caller=proxy.go:314 component=proxy request="min_time:1653417366131 max_time:1653417666131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_num_elections\" > aggregates:COUNTER partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:07.980378817Z level=error ts=2022-05-24T18:41:07.980329388Z caller=proxy.go:314 component=proxy request="min_time:1653417367976 max_time:1653417667976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:07.980598398Z level=error ts=2022-05-24T18:41:07.980557797Z caller=proxy.go:314 component=proxy request="min_time:1653417367976 max_time:1653417667976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:07.984002873Z level=error ts=2022-05-24T18:41:07.983963363Z caller=proxy.go:314 component=proxy request="min_time:1653417367976 max_time:1653417667976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:07.984162705Z level=error ts=2022-05-24T18:41:07.984139492Z caller=proxy.go:314 component=proxy request="min_time:1653417367976 max_time:1653417667976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:07.990923831Z level=error ts=2022-05-24T18:41:07.990884245Z caller=proxy.go:314 component=proxy request="min_time:1653417367976 max_time:1653417667976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:07.990974560Z level=error ts=2022-05-24T18:41:07.990951845Z caller=proxy.go:314 component=proxy request="min_time:1653417367976 max_time:1653417667976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:10.730053017Z level=error ts=2022-05-24T18:41:10.729993416Z caller=proxy.go:314 component=proxy request="min_time:1653417370688 max_time:1653417670688 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"cluster:ceph_node_down:join_kube\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:12.586690572Z level=warn ts=2022-05-24T18:41:12.586630234Z caller=proxy.go:471 component=proxy request="min_time:1653417372574 max_time:1653417672574 matchers:<name:\"__name__\" value:\"etcd_server_leader_changes_seen_total\" > aggregates:COUNTER " err="receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable" msg="returning partial response"
2022-05-24T18:41:12.985872267Z level=error ts=2022-05-24T18:41:12.985822688Z caller=proxy.go:314 component=proxy request="min_time:1653417372981 max_time:1653417672981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:12.989535769Z level=error ts=2022-05-24T18:41:12.98949444Z caller=proxy.go:314 component=proxy request="min_time:1653417372981 max_time:1653417672981 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolume_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:12.989767338Z level=error ts=2022-05-24T18:41:12.989740239Z caller=proxy.go:314 component=proxy request="min_time:1653417372981 max_time:1653417672981 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:12.992910441Z level=error ts=2022-05-24T18:41:12.992872651Z caller=proxy.go:314 component=proxy request="min_time:1653417372981 max_time:1653417672981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_rd\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:12.993071231Z level=error ts=2022-05-24T18:41:12.993038871Z caller=proxy.go:314 component=proxy request="min_time:1653417372981 max_time:1653417672981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_wr\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:12.996216712Z level=error ts=2022-05-24T18:41:12.996180562Z caller=proxy.go:314 component=proxy request="min_time:1653417372981 max_time:1653417672981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_rd_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:12.996351033Z level=error ts=2022-05-24T18:41:12.996323067Z caller=proxy.go:314 component=proxy request="min_time:1653417372981 max_time:1653417672981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_wr_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:13.000028925Z level=error ts=2022-05-24T18:41:12.999990637Z caller=proxy.go:314 component=proxy request="min_time:1653417372981 max_time:1653417672981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_rgw_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:13.000434705Z level=error ts=2022-05-24T18:41:13.000407835Z caller=proxy.go:314 component=proxy request="min_time:1653417372981 max_time:1653417672981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:13.000544802Z level=error ts=2022-05-24T18:41:13.000518845Z caller=proxy.go:314 component=proxy request="min_time:1653417372981 max_time:1653417672981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mgr_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:13.000579363Z level=error ts=2022-05-24T18:41:13.000558825Z caller=proxy.go:314 component=proxy request="min_time:1653417372981 max_time:1653417672981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:13.001496998Z level=error ts=2022-05-24T18:41:13.001469989Z caller=proxy.go:314 component=proxy request="min_time:1653417372981 max_time:1653417672981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mds_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:14.308135881Z level=error ts=2022-05-24T18:41:14.308084125Z caller=proxy.go:314 component=proxy request="min_time:1653417374302 max_time:1653417674302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:14.308172981Z level=error ts=2022-05-24T18:41:14.308133123Z caller=proxy.go:314 component=proxy request="min_time:1653417374302 max_time:1653417674302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_stored_raw\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:14.308285810Z level=error ts=2022-05-24T18:41:14.308265647Z caller=proxy.go:314 component=proxy request="min_time:1653417374302 max_time:1653417674302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:14.308373314Z level=error ts=2022-05-24T18:41:14.308351537Z caller=proxy.go:314 component=proxy request="min_time:1653417374302 max_time:1653417674302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_quota_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:14.312285149Z level=error ts=2022-05-24T18:41:14.312243634Z caller=proxy.go:314 component=proxy request="min_time:1653417374302 max_time:1653417674302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_stored_raw\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:14.312448983Z level=error ts=2022-05-24T18:41:14.312417626Z caller=proxy.go:314 component=proxy request="min_time:1653417374302 max_time:1653417674302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:14.312482427Z level=error ts=2022-05-24T18:41:14.312461868Z caller=proxy.go:314 component=proxy request="min_time:1653417374302 max_time:1653417674302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:14.312513026Z level=error ts=2022-05-24T18:41:14.312493837Z caller=proxy.go:314 component=proxy request="min_time:1653417374302 max_time:1653417674302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_quota_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:15.146890153Z level=error ts=2022-05-24T18:41:15.146837804Z caller=proxy.go:314 component=proxy request="min_time:1653417375143 max_time:1653417675143 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_health_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:15.150226749Z level=error ts=2022-05-24T18:41:15.150185092Z caller=proxy.go:314 component=proxy request="min_time:1653417375143 max_time:1653417675143 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_health_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:15.153282893Z level=error ts=2022-05-24T18:41:15.153245099Z caller=proxy.go:314 component=proxy request="min_time:1653417375143 max_time:1653417675143 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:15.156369457Z level=error ts=2022-05-24T18:41:15.156331206Z caller=proxy.go:314 component=proxy request="min_time:1653417375143 max_time:1653417675143 matchers:<type:NEQ name:\"ceph_version\" > matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:15.474699023Z level=error ts=2022-05-24T18:41:15.474651717Z caller=proxy.go:314 component=proxy request="min_time:1653417375470 max_time:1653417675470 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:15.474751100Z level=error ts=2022-05-24T18:41:15.474727748Z caller=proxy.go:314 component=proxy request="min_time:1653417375470 max_time:1653417675470 matchers:<name:\"condition\" value:\"Ready\" > matchers:<name:\"job\" value:\"kube-state-metrics\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"status\" value:\"true\" > matchers:<name:\"__name__\" value:\"kube_node_status_condition\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:15.478978979Z level=error ts=2022-05-24T18:41:15.478931325Z caller=proxy.go:314 component=proxy request="min_time:1653417375470 max_time:1653417675470 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:15.479536197Z level=error ts=2022-05-24T18:41:15.479504163Z caller=proxy.go:314 component=proxy request="min_time:1653417615470 max_time:1653417675470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_read_time_seconds_total\" > aggregates:COUNTER partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:15.479575700Z level=error ts=2022-05-24T18:41:15.479554872Z caller=proxy.go:314 component=proxy request="min_time:1653417615470 max_time:1653417675470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_writes_completed_total\" > aggregates:COUNTER partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:15.479631242Z level=error ts=2022-05-24T18:41:15.479610089Z caller=proxy.go:314 component=proxy request="min_time:1653417615470 max_time:1653417675470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_write_time_seconds_total\" > aggregates:COUNTER partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:15.480529612Z level=error ts=2022-05-24T18:41:15.480504114Z caller=proxy.go:314 component=proxy request="min_time:1653417615470 max_time:1653417675470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_reads_completed_total\" > aggregates:COUNTER partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:18.824113120Z level=error ts=2022-05-24T18:41:18.824064624Z caller=proxy.go:314 component=proxy request="min_time:1653417378820 max_time:1653417678820 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mds_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:18.824293148Z level=error ts=2022-05-24T18:41:18.824265595Z caller=proxy.go:314 component=proxy request="min_time:1653417378820 max_time:1653417678820 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mds_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:19.158001326Z level=error ts=2022-05-24T18:41:19.157952456Z caller=proxy.go:314 component=proxy request="min_time:1653417379153 max_time:1653417679153 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:19.158146512Z level=error ts=2022-05-24T18:41:19.1581141Z caller=proxy.go:314 component=proxy request="min_time:1653417379153 max_time:1653417679153 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:19.159098256Z level=error ts=2022-05-24T18:41:19.159069472Z caller=proxy.go:314 component=proxy request="min_time:1653417379153 max_time:1653417679153 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:19.159381167Z level=error ts=2022-05-24T18:41:19.159358187Z caller=proxy.go:314 component=proxy request="min_time:1653417379153 max_time:1653417679153 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:19.161236846Z level=error ts=2022-05-24T18:41:19.161204896Z caller=proxy.go:314 component=proxy request="min_time:1653417379153 max_time:1653417679153 matchers:<type:RE name:\"deployment\" value:\"rook-ceph-mgr-.*\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_deployment_spec_replicas\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:19.162482008Z level=error ts=2022-05-24T18:41:19.162450591Z caller=proxy.go:314 component=proxy request="min_time:1653417379153 max_time:1653417679153 matchers:<type:RE name:\"deployment\" value:\"rook-ceph-mgr-.*\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_deployment_spec_replicas\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.851608687Z level=error ts=2022-05-24T18:41:20.851536339Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.851712971Z level=error ts=2022-05-24T18:41:20.85167669Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_used_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.851826441Z level=error ts=2022-05-24T18:41:20.851804765Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.852358444Z level=error ts=2022-05-24T18:41:20.85233264Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.853257041Z level=error ts=2022-05-24T18:41:20.853217496Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.853345583Z level=error ts=2022-05-24T18:41:20.853318762Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.853478629Z level=error ts=2022-05-24T18:41:20.853450292Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_used_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.853702683Z level=error ts=2022-05-24T18:41:20.853673214Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.858569333Z level=error ts=2022-05-24T18:41:20.858537665Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_capacity_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.860678141Z level=error ts=2022-05-24T18:41:20.860642381Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.865012514Z level=error ts=2022-05-24T18:41:20.864978852Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.865081587Z level=error ts=2022-05-24T18:41:20.86506233Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_used_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.865886696Z level=error ts=2022-05-24T18:41:20.865858528Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_used_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.865951976Z level=error ts=2022-05-24T18:41:20.865927362Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.866074491Z level=error ts=2022-05-24T18:41:20.866053173Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.866180986Z level=error ts=2022-05-24T18:41:20.866149731Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_capacity_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.866676173Z level=error ts=2022-05-24T18:41:20.866643057Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.866723031Z level=error ts=2022-05-24T18:41:20.86669788Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.867031724Z level=error ts=2022-05-24T18:41:20.86700208Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.867831544Z level=error ts=2022-05-24T18:41:20.867803583Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.867946234Z level=error ts=2022-05-24T18:41:20.867925901Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_capacity_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.867988450Z level=error ts=2022-05-24T18:41:20.867972023Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.868640188Z level=error ts=2022-05-24T18:41:20.868617244Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_capacity_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.868781666Z level=error ts=2022-05-24T18:41:20.868760999Z caller=proxy.go:314 component=proxy request="min_time:1653417380846 max_time:1653417680846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.938249537Z level=error ts=2022-05-24T18:41:20.938213751Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.938460542Z level=error ts=2022-05-24T18:41:20.938435468Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes_used\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.938652391Z level=error ts=2022-05-24T18:41:20.938629324Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.938862402Z level=error ts=2022-05-24T18:41:20.938841601Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.938894911Z level=error ts=2022-05-24T18:41:20.93887778Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.939065239Z level=error ts=2022-05-24T18:41:20.939028715Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes_used\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.941084172Z level=error ts=2022-05-24T18:41:20.941047794Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.942757893Z level=error ts=2022-05-24T18:41:20.942712124Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.943847997Z level=error ts=2022-05-24T18:41:20.943817478Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.943949592Z level=error ts=2022-05-24T18:41:20.943926558Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes_used\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.943981661Z level=error ts=2022-05-24T18:41:20.943964877Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.946893518Z level=error ts=2022-05-24T18:41:20.946860911Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes_used\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.946947484Z level=error ts=2022-05-24T18:41:20.946921512Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.947252180Z level=error ts=2022-05-24T18:41:20.947228168Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.947541304Z level=error ts=2022-05-24T18:41:20.947517862Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.947604822Z level=error ts=2022-05-24T18:41:20.947566555Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.947723362Z level=error ts=2022-05-24T18:41:20.947702372Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_in\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.951195029Z level=error ts=2022-05-24T18:41:20.951163805Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.951292286Z level=error ts=2022-05-24T18:41:20.951272527Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.951340045Z level=error ts=2022-05-24T18:41:20.951314522Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_in\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.951710074Z level=error ts=2022-05-24T18:41:20.951684757Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.951756207Z level=error ts=2022-05-24T18:41:20.951736629Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_in\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.951851416Z level=error ts=2022-05-24T18:41:20.951832739Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.953932663Z level=error ts=2022-05-24T18:41:20.953636941Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_healthcheck_slow_ops\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.956094885Z level=error ts=2022-05-24T18:41:20.956062685Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.956413575Z level=error ts=2022-05-24T18:41:20.956390733Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_in\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.956531376Z level=error ts=2022-05-24T18:41:20.956510153Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.956687349Z level=error ts=2022-05-24T18:41:20.956664865Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pg_undersized\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.958804443Z level=error ts=2022-05-24T18:41:20.958772204Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pg_inconsistent\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.959410340Z level=error ts=2022-05-24T18:41:20.959383542Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_healthcheck_slow_ops\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.962286764Z level=error ts=2022-05-24T18:41:20.962253575Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pg_undersized\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:20.965153928Z level=error ts=2022-05-24T18:41:20.965119679Z caller=proxy.go:314 component=proxy request="min_time:1653417380935 max_time:1653417680935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pg_inconsistent\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:21.135829518Z level=error ts=2022-05-24T18:41:21.135788866Z caller=proxy.go:314 component=proxy request="min_time:1653417381131 max_time:1653417681131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_quorum_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:21.135939032Z level=error ts=2022-05-24T18:41:21.135918129Z caller=proxy.go:314 component=proxy request="min_time:1653417381131 max_time:1653417681131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:21.136249716Z level=error ts=2022-05-24T18:41:21.136229207Z caller=proxy.go:314 component=proxy request="min_time:1653417381131 max_time:1653417681131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:21.136285411Z level=error ts=2022-05-24T18:41:21.136268585Z caller=proxy.go:314 component=proxy request="min_time:1653417381131 max_time:1653417681131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_quorum_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:21.139154339Z level=error ts=2022-05-24T18:41:21.139123401Z caller=proxy.go:314 component=proxy request="min_time:1653417381131 max_time:1653417681131 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"phase\" value:\"Running|running\" > matchers:<type:RE name:\"pod\" value:\"rook-ceph-mon-.*\" > matchers:<name:\"__name__\" value:\"kube_pod_status_phase\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:21.139825467Z level=error ts=2022-05-24T18:41:21.139790217Z caller=proxy.go:314 component=proxy request="min_time:1653417381131 max_time:1653417681131 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"phase\" value:\"Running|running\" > matchers:<type:RE name:\"pod\" value:\"rook-ceph-mon-.*\" > matchers:<name:\"__name__\" value:\"kube_pod_status_phase\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:21.142139459Z level=error ts=2022-05-24T18:41:21.142111409Z caller=proxy.go:314 component=proxy request="min_time:1653417381131 max_time:1653417681131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_num_elections\" > aggregates:COUNTER partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:21.142184952Z level=error ts=2022-05-24T18:41:21.142165774Z caller=proxy.go:314 component=proxy request="min_time:1653417381131 max_time:1653417681131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:21.143157103Z level=error ts=2022-05-24T18:41:21.143124816Z caller=proxy.go:314 component=proxy request="min_time:1653417381131 max_time:1653417681131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:21.143295196Z level=error ts=2022-05-24T18:41:21.143272978Z caller=proxy.go:314 component=proxy request="min_time:1653417381131 max_time:1653417681131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_num_elections\" > aggregates:COUNTER partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:22.980187036Z level=error ts=2022-05-24T18:41:22.980138619Z caller=proxy.go:314 component=proxy request="min_time:1653417382976 max_time:1653417682976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:22.980345048Z level=error ts=2022-05-24T18:41:22.980322683Z caller=proxy.go:314 component=proxy request="min_time:1653417382976 max_time:1653417682976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:22.981173928Z level=error ts=2022-05-24T18:41:22.981136998Z caller=proxy.go:314 component=proxy request="min_time:1653417382976 max_time:1653417682976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:22.981447924Z level=error ts=2022-05-24T18:41:22.98142191Z caller=proxy.go:314 component=proxy request="min_time:1653417382976 max_time:1653417682976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:22.983478986Z level=error ts=2022-05-24T18:41:22.983443833Z caller=proxy.go:314 component=proxy request="min_time:1653417382976 max_time:1653417682976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:22.983503251Z level=error ts=2022-05-24T18:41:22.983486778Z caller=proxy.go:314 component=proxy request="min_time:1653417382976 max_time:1653417682976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:22.985026332Z level=error ts=2022-05-24T18:41:22.984993578Z caller=proxy.go:314 component=proxy request="min_time:1653417382976 max_time:1653417682976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:22.985057179Z level=error ts=2022-05-24T18:41:22.985037003Z caller=proxy.go:314 component=proxy request="min_time:1653417382976 max_time:1653417682976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:22.990004846Z level=error ts=2022-05-24T18:41:22.989971092Z caller=proxy.go:314 component=proxy request="min_time:1653417382976 max_time:1653417682976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:22.990547449Z level=error ts=2022-05-24T18:41:22.990524088Z caller=proxy.go:314 component=proxy request="min_time:1653417382976 max_time:1653417682976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:22.992110795Z level=error ts=2022-05-24T18:41:22.992079965Z caller=proxy.go:314 component=proxy request="min_time:1653417382976 max_time:1653417682976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:22.992211855Z level=error ts=2022-05-24T18:41:22.99219258Z caller=proxy.go:314 component=proxy request="min_time:1653417382976 max_time:1653417682976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:25.692557483Z level=error ts=2022-05-24T18:41:25.692505715Z caller=proxy.go:314 component=proxy request="min_time:1653417385688 max_time:1653417685688 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"cluster:ceph_node_down:join_kube\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:25.699239835Z level=error ts=2022-05-24T18:41:25.699200693Z caller=proxy.go:314 component=proxy request="min_time:1653417385688 max_time:1653417685688 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"cluster:ceph_node_down:join_kube\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.985073094Z level=error ts=2022-05-24T18:41:27.985023566Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.986878647Z level=error ts=2022-05-24T18:41:27.986838689Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.988317334Z level=error ts=2022-05-24T18:41:27.988284456Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolume_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.989720714Z level=error ts=2022-05-24T18:41:27.989668188Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.990540212Z level=error ts=2022-05-24T18:41:27.990501595Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolume_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.990801394Z level=error ts=2022-05-24T18:41:27.99077637Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.991306614Z level=error ts=2022-05-24T18:41:27.991282047Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_rd\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.991460729Z level=error ts=2022-05-24T18:41:27.991437054Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_wr\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.993906379Z level=error ts=2022-05-24T18:41:27.99387137Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_rd\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.994027270Z level=error ts=2022-05-24T18:41:27.994006073Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_wr\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.994601569Z level=error ts=2022-05-24T18:41:27.994561938Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_wr_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.994638602Z level=error ts=2022-05-24T18:41:27.994619715Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_rd_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.997522080Z level=error ts=2022-05-24T18:41:27.997486166Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_wr_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.997562562Z level=error ts=2022-05-24T18:41:27.997534216Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_rd_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.998464257Z level=error ts=2022-05-24T18:41:27.998433553Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_rgw_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.998900978Z level=error ts=2022-05-24T18:41:27.99887334Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.998945663Z level=error ts=2022-05-24T18:41:27.998918095Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:27.999051077Z level=error ts=2022-05-24T18:41:27.999028877Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mgr_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:28.000462671Z level=error ts=2022-05-24T18:41:28.000431923Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mds_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:28.001743191Z level=error ts=2022-05-24T18:41:28.001711491Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_rgw_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:28.001821888Z level=error ts=2022-05-24T18:41:28.001801326Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mgr_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:28.001853722Z level=error ts=2022-05-24T18:41:28.001836989Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:28.002108986Z level=error ts=2022-05-24T18:41:28.002086817Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:28.003406198Z level=error ts=2022-05-24T18:41:28.003378237Z caller=proxy.go:314 component=proxy request="min_time:1653417387981 max_time:1653417687981 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mds_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.308048436Z level=error ts=2022-05-24T18:41:29.308002233Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.308110814Z level=error ts=2022-05-24T18:41:29.308091725Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.308156685Z level=error ts=2022-05-24T18:41:29.3081401Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_stored_raw\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.308292936Z level=error ts=2022-05-24T18:41:29.308274936Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_quota_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.308778560Z level=error ts=2022-05-24T18:41:29.308740914Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_stored_raw\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.308882260Z level=error ts=2022-05-24T18:41:29.308861267Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_quota_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.308921310Z level=error ts=2022-05-24T18:41:29.308905013Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.310177405Z level=error ts=2022-05-24T18:41:29.310135597Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.312289658Z level=error ts=2022-05-24T18:41:29.312254475Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.312405787Z level=error ts=2022-05-24T18:41:29.312377373Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_quota_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.312447805Z level=error ts=2022-05-24T18:41:29.31242557Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_stored_raw\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.312562372Z level=error ts=2022-05-24T18:41:29.312543023Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.313330150Z level=error ts=2022-05-24T18:41:29.313300484Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_quota_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.313416421Z level=error ts=2022-05-24T18:41:29.313395314Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.313487414Z level=error ts=2022-05-24T18:41:29.313463121Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:29.313541161Z level=error ts=2022-05-24T18:41:29.313518851Z caller=proxy.go:314 component=proxy request="min_time:1653417389302 max_time:1653417689302 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pool_stored_raw\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.146376346Z level=error ts=2022-05-24T18:41:30.146318568Z caller=proxy.go:314 component=proxy request="min_time:1653417390143 max_time:1653417690143 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_health_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.147134752Z level=error ts=2022-05-24T18:41:30.147101259Z caller=proxy.go:314 component=proxy request="min_time:1653417390143 max_time:1653417690143 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_health_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.149171495Z level=error ts=2022-05-24T18:41:30.149138157Z caller=proxy.go:314 component=proxy request="min_time:1653417390143 max_time:1653417690143 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_health_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.150408095Z level=error ts=2022-05-24T18:41:30.150375447Z caller=proxy.go:314 component=proxy request="min_time:1653417390143 max_time:1653417690143 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_health_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.151441347Z level=error ts=2022-05-24T18:41:30.151409236Z caller=proxy.go:314 component=proxy request="min_time:1653417390143 max_time:1653417690143 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.153660368Z level=error ts=2022-05-24T18:41:30.153624271Z caller=proxy.go:314 component=proxy request="min_time:1653417390143 max_time:1653417690143 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.154064088Z level=error ts=2022-05-24T18:41:30.154035472Z caller=proxy.go:314 component=proxy request="min_time:1653417390143 max_time:1653417690143 matchers:<type:NEQ name:\"ceph_version\" > matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.156788562Z level=error ts=2022-05-24T18:41:30.156756397Z caller=proxy.go:314 component=proxy request="min_time:1653417390143 max_time:1653417690143 matchers:<type:NEQ name:\"ceph_version\" > matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.476253645Z level=error ts=2022-05-24T18:41:30.47620759Z caller=proxy.go:314 component=proxy request="min_time:1653417390470 max_time:1653417690470 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.476452682Z level=error ts=2022-05-24T18:41:30.476429998Z caller=proxy.go:314 component=proxy request="min_time:1653417390470 max_time:1653417690470 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.476528532Z level=error ts=2022-05-24T18:41:30.476510115Z caller=proxy.go:314 component=proxy request="min_time:1653417390470 max_time:1653417690470 matchers:<name:\"condition\" value:\"Ready\" > matchers:<name:\"job\" value:\"kube-state-metrics\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"status\" value:\"true\" > matchers:<name:\"__name__\" value:\"kube_node_status_condition\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.477017106Z level=error ts=2022-05-24T18:41:30.476988045Z caller=proxy.go:314 component=proxy request="min_time:1653417390470 max_time:1653417690470 matchers:<name:\"condition\" value:\"Ready\" > matchers:<name:\"job\" value:\"kube-state-metrics\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"status\" value:\"true\" > matchers:<name:\"__name__\" value:\"kube_node_status_condition\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.483922003Z level=error ts=2022-05-24T18:41:30.483886082Z caller=proxy.go:314 component=proxy request="min_time:1653417630470 max_time:1653417690470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_writes_completed_total\" > aggregates:COUNTER partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.484342720Z level=error ts=2022-05-24T18:41:30.484318229Z caller=proxy.go:314 component=proxy request="min_time:1653417630470 max_time:1653417690470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_write_time_seconds_total\" > aggregates:COUNTER partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.484374339Z level=error ts=2022-05-24T18:41:30.484356814Z caller=proxy.go:314 component=proxy request="min_time:1653417630470 max_time:1653417690470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_write_time_seconds_total\" > aggregates:COUNTER partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.484433361Z level=error ts=2022-05-24T18:41:30.484416024Z caller=proxy.go:314 component=proxy request="min_time:1653417630470 max_time:1653417690470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_writes_completed_total\" > aggregates:COUNTER partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.484509488Z level=error ts=2022-05-24T18:41:30.484486214Z caller=proxy.go:314 component=proxy request="min_time:1653417630470 max_time:1653417690470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_read_time_seconds_total\" > aggregates:COUNTER partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.484887322Z level=error ts=2022-05-24T18:41:30.484862858Z caller=proxy.go:314 component=proxy request="min_time:1653417390470 max_time:1653417690470 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.484986780Z level=error ts=2022-05-24T18:41:30.484967369Z caller=proxy.go:314 component=proxy request="min_time:1653417390470 max_time:1653417690470 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.485356775Z level=error ts=2022-05-24T18:41:30.48530115Z caller=proxy.go:314 component=proxy request="min_time:1653417630470 max_time:1653417690470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_read_time_seconds_total\" > aggregates:COUNTER partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.485506039Z level=error ts=2022-05-24T18:41:30.485484232Z caller=proxy.go:314 component=proxy request="min_time:1653417630470 max_time:1653417690470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_reads_completed_total\" > aggregates:COUNTER partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:41:30.486232980Z level=error ts=2022-05-24T18:41:30.486209785Z caller=proxy.go:314 component=proxy request="min_time:1653417630470 max_time:1653417690470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_reads_completed_total\" > aggregates:COUNTER partial_response_disabled:true " err="Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: receive series from Addr: 10.130.2.11:10901 LabelSets:  Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unknown desc = query Prometheus: request failed with code 503 Service Unavailable; msg Service Unavailable"
2022-05-24T18:42:30.144574005Z level=error ts=2022-05-24T18:42:30.144514881Z caller=proxy.go:268 component=proxy request="min_time:1653417450143 max_time:1653417750143 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_health_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:42:30.144614874Z level=error ts=2022-05-24T18:42:30.144565691Z caller=proxy.go:314 component=proxy request="min_time:1653417450143 max_time:1653417750143 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_health_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\""
2022-05-24T18:42:30.145843814Z level=error ts=2022-05-24T18:42:30.145800521Z caller=proxy.go:268 component=proxy request="min_time:1653417450143 max_time:1653417750143 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_health_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:42:30.145931341Z level=error ts=2022-05-24T18:42:30.145908064Z caller=proxy.go:314 component=proxy request="min_time:1653417450143 max_time:1653417750143 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_health_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\""
2022-05-24T18:42:30.147068213Z level=error ts=2022-05-24T18:42:30.146977444Z caller=proxy.go:268 component=proxy request="min_time:1653417450143 max_time:1653417750143 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:42:30.147068213Z level=error ts=2022-05-24T18:42:30.147028097Z caller=proxy.go:314 component=proxy request="min_time:1653417450143 max_time:1653417750143 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\""
2022-05-24T18:42:30.148070914Z level=error ts=2022-05-24T18:42:30.148043667Z caller=proxy.go:268 component=proxy request="min_time:1653417450143 max_time:1653417750143 matchers:<type:NEQ name:\"ceph_version\" > matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:42:30.148182465Z level=error ts=2022-05-24T18:42:30.148161421Z caller=proxy.go:314 component=proxy request="min_time:1653417450143 max_time:1653417750143 matchers:<type:NEQ name:\"ceph_version\" > matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\""
2022-05-24T18:42:30.472629016Z level=error ts=2022-05-24T18:42:30.472558939Z caller=proxy.go:268 component=proxy request="min_time:1653417450470 max_time:1653417750470 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:42:30.472655664Z level=error ts=2022-05-24T18:42:30.472631756Z caller=proxy.go:314 component=proxy request="min_time:1653417450470 max_time:1653417750470 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\""
2022-05-24T18:42:30.472741993Z level=error ts=2022-05-24T18:42:30.472719842Z caller=proxy.go:268 component=proxy request="min_time:1653417450470 max_time:1653417750470 matchers:<name:\"condition\" value:\"Ready\" > matchers:<name:\"job\" value:\"kube-state-metrics\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"status\" value:\"true\" > matchers:<name:\"__name__\" value:\"kube_node_status_condition\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:42:30.472761514Z level=error ts=2022-05-24T18:42:30.472744709Z caller=proxy.go:314 component=proxy request="min_time:1653417450470 max_time:1653417750470 matchers:<name:\"condition\" value:\"Ready\" > matchers:<name:\"job\" value:\"kube-state-metrics\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"status\" value:\"true\" > matchers:<name:\"__name__\" value:\"kube_node_status_condition\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\""
2022-05-24T18:42:30.474089389Z level=error ts=2022-05-24T18:42:30.474055184Z caller=proxy.go:268 component=proxy request="min_time:1653417690470 max_time:1653417750470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_writes_completed_total\" > aggregates:COUNTER partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:42:30.474114834Z level=error ts=2022-05-24T18:42:30.474094833Z caller=proxy.go:314 component=proxy request="min_time:1653417690470 max_time:1653417750470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_writes_completed_total\" > aggregates:COUNTER partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\""
2022-05-24T18:42:30.474256633Z level=error ts=2022-05-24T18:42:30.47423391Z caller=proxy.go:268 component=proxy request="min_time:1653417450470 max_time:1653417750470 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:42:30.474345401Z level=error ts=2022-05-24T18:42:30.474325313Z caller=proxy.go:268 component=proxy request="min_time:1653417690470 max_time:1653417750470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_read_time_seconds_total\" > aggregates:COUNTER partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:42:30.474366944Z level=error ts=2022-05-24T18:42:30.474348436Z caller=proxy.go:314 component=proxy request="min_time:1653417690470 max_time:1653417750470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_read_time_seconds_total\" > aggregates:COUNTER partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\""
2022-05-24T18:42:30.474477967Z level=error ts=2022-05-24T18:42:30.47445785Z caller=proxy.go:268 component=proxy request="min_time:1653417690470 max_time:1653417750470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_write_time_seconds_total\" > aggregates:COUNTER partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:42:30.474616424Z level=error ts=2022-05-24T18:42:30.474595163Z caller=proxy.go:314 component=proxy request="min_time:1653417450470 max_time:1653417750470 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\""
2022-05-24T18:42:30.474782596Z level=error ts=2022-05-24T18:42:30.474758143Z caller=proxy.go:314 component=proxy request="min_time:1653417690470 max_time:1653417750470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_write_time_seconds_total\" > aggregates:COUNTER partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\""
2022-05-24T18:42:38.344874900Z level=warn ts=2022-05-24T18:42:38.344810737Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.129.2.37:10901: rpc error: code = DeadlineExceeded desc = latest connection error: connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.37:10901: connect: connection refused\"" address=10.129.2.37:10901
2022-05-24T18:42:38.344900595Z level=warn ts=2022-05-24T18:42:38.344877388Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.129.2.36:10901: rpc error: code = DeadlineExceeded desc = latest connection error: connection error: desc = \"transport: Error while dialing dial tcp 10.129.2.36:10901: connect: connection refused\"" address=10.129.2.36:10901
2022-05-24T18:42:38.344990680Z level=info ts=2022-05-24T18:42:38.344969061Z caller=endpointset.go:348 component=endpointset msg="removing endpoint because it's unhealthy or does not exist" address=10.129.2.36:10901 extLset="{prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"}"
2022-05-24T18:42:38.345019675Z level=info ts=2022-05-24T18:42:38.345000875Z caller=endpointset.go:348 component=endpointset msg="removing endpoint because it's unhealthy or does not exist" address=10.129.2.37:10901 extLset="{thanos_ruler_replica=\"thanos-ruler-user-workload-1\"}"
2022-05-24T18:42:38.345209790Z level=error ts=2022-05-24T18:42:38.345181964Z caller=proxy.go:268 component=proxy request="min_time:1653417457976 max_time:1653417757976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing" msg="partial response disabled; aborting request"
2022-05-24T18:42:38.345236319Z level=error ts=2022-05-24T18:42:38.345213304Z caller=proxy.go:314 component=proxy request="min_time:1653417457976 max_time:1653417757976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing"
2022-05-24T18:42:38.345446351Z level=error ts=2022-05-24T18:42:38.345404525Z caller=proxy.go:268 component=proxy request="min_time:1653417457976 max_time:1653417757976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing" msg="partial response disabled; aborting request"
2022-05-24T18:42:38.345470763Z level=error ts=2022-05-24T18:42:38.345434266Z caller=proxy.go:314 component=proxy request="min_time:1653417457976 max_time:1653417757976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing"
2022-05-24T18:42:38.345483396Z level=error ts=2022-05-24T18:42:38.345464768Z caller=proxy.go:268 component=proxy request="min_time:1653417456131 max_time:1653417756131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing" msg="partial response disabled; aborting request"
2022-05-24T18:42:38.345508698Z level=error ts=2022-05-24T18:42:38.345487452Z caller=proxy.go:314 component=proxy request="min_time:1653417456131 max_time:1653417756131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing"
2022-05-24T18:42:38.345542409Z level=error ts=2022-05-24T18:42:38.345520416Z caller=proxy.go:268 component=proxy request="min_time:1653417455935 max_time:1653417755935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes_used\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing" msg="partial response disabled; aborting request"
2022-05-24T18:42:38.345670904Z level=error ts=2022-05-24T18:42:38.345626903Z caller=proxy.go:314 component=proxy request="min_time:1653417455935 max_time:1653417755935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes_used\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing"
2022-05-24T18:42:38.345725924Z level=error ts=2022-05-24T18:42:38.345703737Z caller=proxy.go:268 component=proxy request="min_time:1653417455935 max_time:1653417755935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing" msg="partial response disabled; aborting request"
2022-05-24T18:42:38.345752408Z level=error ts=2022-05-24T18:42:38.345733575Z caller=proxy.go:314 component=proxy request="min_time:1653417455935 max_time:1653417755935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing"
2022-05-24T18:42:38.345925515Z level=error ts=2022-05-24T18:42:38.345902159Z caller=proxy.go:268 component=proxy request="min_time:1653417455935 max_time:1653417755935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing" msg="partial response disabled; aborting request"
2022-05-24T18:42:38.345961237Z level=error ts=2022-05-24T18:42:38.345933292Z caller=proxy.go:314 component=proxy request="min_time:1653417455935 max_time:1653417755935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing"
2022-05-24T18:42:38.346002336Z level=error ts=2022-05-24T18:42:38.34597506Z caller=proxy.go:268 component=proxy request="min_time:1653417455846 max_time:1653417755846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing" msg="partial response disabled; aborting request"
2022-05-24T18:42:38.346028074Z level=error ts=2022-05-24T18:42:38.346004459Z caller=proxy.go:314 component=proxy request="min_time:1653417455846 max_time:1653417755846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing"
2022-05-24T18:42:38.346123458Z level=error ts=2022-05-24T18:42:38.346101753Z caller=proxy.go:268 component=proxy request="min_time:1653417455846 max_time:1653417755846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing" msg="partial response disabled; aborting request"
2022-05-24T18:42:38.346141004Z level=error ts=2022-05-24T18:42:38.346120686Z caller=proxy.go:314 component=proxy request="min_time:1653417455846 max_time:1653417755846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing"
2022-05-24T18:42:38.346191106Z level=error ts=2022-05-24T18:42:38.346171152Z caller=proxy.go:268 component=proxy request="min_time:1653417455846 max_time:1653417755846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_used_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing" msg="partial response disabled; aborting request"
2022-05-24T18:42:38.346243179Z level=error ts=2022-05-24T18:42:38.346217976Z caller=proxy.go:268 component=proxy request="min_time:1653417455846 max_time:1653417755846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing" msg="partial response disabled; aborting request"
2022-05-24T18:42:38.346256465Z level=error ts=2022-05-24T18:42:38.346242827Z caller=proxy.go:314 component=proxy request="min_time:1653417455846 max_time:1653417755846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing"
2022-05-24T18:42:38.346283182Z level=error ts=2022-05-24T18:42:38.346264113Z caller=proxy.go:268 component=proxy request="min_time:1653417454153 max_time:1653417754153 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing" msg="partial response disabled; aborting request"
2022-05-24T18:42:38.346295654Z level=error ts=2022-05-24T18:42:38.346283063Z caller=proxy.go:314 component=proxy request="min_time:1653417454153 max_time:1653417754153 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing"
2022-05-24T18:42:38.346321095Z level=error ts=2022-05-24T18:42:38.346302396Z caller=proxy.go:268 component=proxy request="min_time:1653417453820 max_time:1653417753820 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mds_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing" msg="partial response disabled; aborting request"
2022-05-24T18:42:38.346344533Z level=error ts=2022-05-24T18:42:38.34632196Z caller=proxy.go:314 component=proxy request="min_time:1653417453820 max_time:1653417753820 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mds_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing"
2022-05-24T18:42:38.346523764Z level=error ts=2022-05-24T18:42:38.346497519Z caller=proxy.go:268 component=proxy request="min_time:1653417456131 max_time:1653417756131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_quorum_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.129.2.37:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417294716 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing" msg="partial response disabled; aborting request"
2022-05-24T18:42:38.346542099Z level=error ts=2022-05-24T18:42:38.34651627Z caller=proxy.go:314 component=proxy request="min_time:1653417456131 max_time:1653417756131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_quorum_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.129.2.37:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417294716 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing"
2022-05-24T18:42:38.346656414Z level=error ts=2022-05-24T18:42:38.346626476Z caller=proxy.go:268 component=proxy request="min_time:1653417454153 max_time:1653417754153 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.129.2.37:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417294716 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing" msg="partial response disabled; aborting request"
2022-05-24T18:42:38.346684982Z level=error ts=2022-05-24T18:42:38.346650084Z caller=proxy.go:314 component=proxy request="min_time:1653417454153 max_time:1653417754153 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.129.2.37:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417294716 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing"
2022-05-24T18:42:38.347608130Z level=error ts=2022-05-24T18:42:38.346770575Z caller=proxy.go:268 component=proxy request="min_time:1653417690470 max_time:1653417750470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_reads_completed_total\" > aggregates:COUNTER partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.129.2.37:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417294716 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing" msg="partial response disabled; aborting request"
2022-05-24T18:42:38.347608130Z level=error ts=2022-05-24T18:42:38.346795078Z caller=proxy.go:314 component=proxy request="min_time:1653417690470 max_time:1653417750470 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"node_disk_reads_completed_total\" > aggregates:COUNTER partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.129.2.37:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417294716 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing"
2022-05-24T18:42:38.347713909Z level=error ts=2022-05-24T18:42:38.347676672Z caller=proxy.go:314 component=proxy request="min_time:1653417455846 max_time:1653417755846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_used_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Addr: 10.129.2.36:10901 LabelSets: {prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"} Mint: -62167219200000 Maxt: 9223372036854775807: rpc error: code = Canceled desc = grpc: the client connection is closing"
2022-05-24T18:42:43.347932913Z level=warn ts=2022-05-24T18:42:43.347869501Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.129.2.37:10901: rpc error: code = DeadlineExceeded desc = context deadline exceeded" address=10.129.2.37:10901
2022-05-24T18:42:43.348002667Z level=warn ts=2022-05-24T18:42:43.347980625Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.129.2.36:10901: rpc error: code = DeadlineExceeded desc = context deadline exceeded" address=10.129.2.36:10901
2022-05-24T18:42:48.349085488Z level=warn ts=2022-05-24T18:42:48.349011402Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.129.2.37:10901: rpc error: code = DeadlineExceeded desc = context deadline exceeded" address=10.129.2.37:10901
2022-05-24T18:42:48.349171338Z level=warn ts=2022-05-24T18:42:48.349144658Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.129.2.36:10901: rpc error: code = DeadlineExceeded desc = context deadline exceeded" address=10.129.2.36:10901
2022-05-24T18:42:53.349964287Z level=warn ts=2022-05-24T18:42:53.349898192Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.129.2.37:10901: rpc error: code = DeadlineExceeded desc = context deadline exceeded" address=10.129.2.37:10901
2022-05-24T18:42:53.350055539Z level=warn ts=2022-05-24T18:42:53.350029102Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.129.2.36:10901: rpc error: code = DeadlineExceeded desc = context deadline exceeded" address=10.129.2.36:10901
2022-05-24T18:42:53.360082334Z level=info ts=2022-05-24T18:42:53.360036491Z caller=endpointset.go:371 component=endpointset msg="adding new rule with [storeAPI rulesAPI]" address=10.128.2.15:10901 extLset="{thanos_ruler_replica=\"thanos-ruler-user-workload-1\"}"
2022-05-24T18:43:23.353128794Z level=info ts=2022-05-24T18:43:23.353085257Z caller=endpointset.go:371 component=endpointset msg="adding new sidecar with [storeAPI rulesAPI exemplarsAPI targetsAPI MetricMetadataAPI]" address=10.128.2.17:10901 extLset="{prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"}"
2022-05-24T18:43:33.822933349Z level=error ts=2022-05-24T18:43:33.82287542Z caller=proxy.go:268 component=proxy request="min_time:1653417513820 max_time:1653417813820 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mds_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:33.823032417Z level=error ts=2022-05-24T18:43:33.823009105Z caller=proxy.go:314 component=proxy request="min_time:1653417513820 max_time:1653417813820 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mds_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:34.156772286Z level=error ts=2022-05-24T18:43:34.156707075Z caller=proxy.go:268 component=proxy request="min_time:1653417514153 max_time:1653417814153 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:34.156804255Z level=error ts=2022-05-24T18:43:34.156761885Z caller=proxy.go:314 component=proxy request="min_time:1653417514153 max_time:1653417814153 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:34.156854942Z level=error ts=2022-05-24T18:43:34.156831984Z caller=proxy.go:268 component=proxy request="min_time:1653417514153 max_time:1653417814153 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:34.156865625Z level=error ts=2022-05-24T18:43:34.156854693Z caller=proxy.go:314 component=proxy request="min_time:1653417514153 max_time:1653417814153 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:34.158074369Z level=error ts=2022-05-24T18:43:34.158031474Z caller=proxy.go:268 component=proxy request="min_time:1653417514153 max_time:1653417814153 matchers:<type:RE name:\"deployment\" value:\"rook-ceph-mgr-.*\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_deployment_spec_replicas\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:34.158184327Z level=error ts=2022-05-24T18:43:34.158164209Z caller=proxy.go:314 component=proxy request="min_time:1653417514153 max_time:1653417814153 matchers:<type:RE name:\"deployment\" value:\"rook-ceph-mgr-.*\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_deployment_spec_replicas\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.849424905Z level=error ts=2022-05-24T18:43:35.849369963Z caller=proxy.go:268 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.849455230Z level=error ts=2022-05-24T18:43:35.849417247Z caller=proxy.go:314 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.849557795Z level=error ts=2022-05-24T18:43:35.849535513Z caller=proxy.go:268 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_used_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.849725251Z level=error ts=2022-05-24T18:43:35.84970177Z caller=proxy.go:268 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.849853610Z level=error ts=2022-05-24T18:43:35.84983137Z caller=proxy.go:268 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.850059044Z level=error ts=2022-05-24T18:43:35.850037631Z caller=proxy.go:268 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_capacity_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.850114405Z level=error ts=2022-05-24T18:43:35.850095034Z caller=proxy.go:314 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_used_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.850203292Z level=error ts=2022-05-24T18:43:35.850183661Z caller=proxy.go:314 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.850252103Z level=error ts=2022-05-24T18:43:35.850233288Z caller=proxy.go:314 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.850332881Z level=error ts=2022-05-24T18:43:35.850315274Z caller=proxy.go:314 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_capacity_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.850532400Z level=error ts=2022-05-24T18:43:35.850508715Z caller=proxy.go:268 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.850542621Z level=error ts=2022-05-24T18:43:35.850529715Z caller=proxy.go:314 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.852002201Z level=error ts=2022-05-24T18:43:35.851959637Z caller=proxy.go:268 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.852105093Z level=error ts=2022-05-24T18:43:35.852079304Z caller=proxy.go:268 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_used_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.852122377Z level=error ts=2022-05-24T18:43:35.852109918Z caller=proxy.go:314 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_used_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.852224583Z level=error ts=2022-05-24T18:43:35.852205342Z caller=proxy.go:268 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.852252795Z level=error ts=2022-05-24T18:43:35.852231398Z caller=proxy.go:314 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.852323533Z level=error ts=2022-05-24T18:43:35.852301587Z caller=proxy.go:268 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.852340961Z level=error ts=2022-05-24T18:43:35.852322911Z caller=proxy.go:314 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.852443626Z level=error ts=2022-05-24T18:43:35.852425278Z caller=proxy.go:314 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"provisioner\" value:\"(.*rbd.csi.ceph.com)|(.*cephfs.csi.ceph.com)\" > matchers:<name:\"__name__\" value:\"kube_storageclass_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.852636850Z level=error ts=2022-05-24T18:43:35.852614561Z caller=proxy.go:268 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_capacity_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.852648242Z level=error ts=2022-05-24T18:43:35.85263379Z caller=proxy.go:314 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kubelet_volume_stats_capacity_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.852745821Z level=error ts=2022-05-24T18:43:35.852727413Z caller=proxy.go:268 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.852772832Z level=error ts=2022-05-24T18:43:35.852754701Z caller=proxy.go:314 component=proxy request="min_time:1653417515846 max_time:1653417815846 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"kube_persistentvolumeclaim_info\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.936688931Z level=error ts=2022-05-24T18:43:35.936646934Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.936720861Z level=error ts=2022-05-24T18:43:35.936685324Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.936754623Z level=error ts=2022-05-24T18:43:35.936734204Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.936775130Z level=error ts=2022-05-24T18:43:35.936750943Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.936945951Z level=error ts=2022-05-24T18:43:35.936916073Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes_used\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.936958835Z level=error ts=2022-05-24T18:43:35.936945362Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes_used\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.937787758Z level=error ts=2022-05-24T18:43:35.937761051Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.937802022Z level=error ts=2022-05-24T18:43:35.937791054Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.938777883Z level=error ts=2022-05-24T18:43:35.938744572Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.938794425Z level=error ts=2022-05-24T18:43:35.938777409Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.938893266Z level=error ts=2022-05-24T18:43:35.938871142Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.939047526Z level=error ts=2022-05-24T18:43:35.939025124Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes_used\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.939122930Z level=error ts=2022-05-24T18:43:35.939102879Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.939299187Z level=error ts=2022-05-24T18:43:35.939268343Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_stat_bytes_used\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.940234417Z level=error ts=2022-05-24T18:43:35.940206025Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.940308311Z level=error ts=2022-05-24T18:43:35.940288066Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_in\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.940317874Z level=error ts=2022-05-24T18:43:35.940307199Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_in\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.940447711Z level=error ts=2022-05-24T18:43:35.94042651Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.940457074Z level=error ts=2022-05-24T18:43:35.940446742Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.940498015Z level=error ts=2022-05-24T18:43:35.94047914Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.941400873Z level=error ts=2022-05-24T18:43:35.941375004Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.941424814Z level=error ts=2022-05-24T18:43:35.941407366Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_disk_occupation\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.941494895Z level=error ts=2022-05-24T18:43:35.941476927Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_in\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.941516184Z level=error ts=2022-05-24T18:43:35.941499416Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_in\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.941676626Z level=error ts=2022-05-24T18:43:35.941651192Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.941691149Z level=error ts=2022-05-24T18:43:35.941672889Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_osd_up\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.942356552Z level=error ts=2022-05-24T18:43:35.942331902Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_healthcheck_slow_ops\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.942367983Z level=error ts=2022-05-24T18:43:35.942354992Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_healthcheck_slow_ops\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.943189698Z level=error ts=2022-05-24T18:43:35.943164037Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pg_undersized\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.943213516Z level=error ts=2022-05-24T18:43:35.943196255Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pg_undersized\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:35.944182275Z level=error ts=2022-05-24T18:43:35.944151907Z caller=proxy.go:268 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pg_inconsistent\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:35.944340120Z level=error ts=2022-05-24T18:43:35.94431845Z caller=proxy.go:314 component=proxy request="min_time:1653417515935 max_time:1653417815935 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_pg_inconsistent\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:36.133795874Z level=error ts=2022-05-24T18:43:36.133753458Z caller=proxy.go:268 component=proxy request="min_time:1653417516131 max_time:1653417816131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:36.133950854Z level=error ts=2022-05-24T18:43:36.133927201Z caller=proxy.go:268 component=proxy request="min_time:1653417516131 max_time:1653417816131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_quorum_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:36.134086548Z level=error ts=2022-05-24T18:43:36.13406035Z caller=proxy.go:314 component=proxy request="min_time:1653417516131 max_time:1653417816131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:36.134140236Z level=error ts=2022-05-24T18:43:36.134120857Z caller=proxy.go:314 component=proxy request="min_time:1653417516131 max_time:1653417816131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_quorum_status\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:36.135335798Z level=error ts=2022-05-24T18:43:36.135300364Z caller=proxy.go:268 component=proxy request="min_time:1653417516131 max_time:1653417816131 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"phase\" value:\"Running|running\" > matchers:<type:RE name:\"pod\" value:\"rook-ceph-mon-.*\" > matchers:<name:\"__name__\" value:\"kube_pod_status_phase\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:36.135353495Z level=error ts=2022-05-24T18:43:36.135334222Z caller=proxy.go:314 component=proxy request="min_time:1653417516131 max_time:1653417816131 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<type:RE name:\"phase\" value:\"Running|running\" > matchers:<type:RE name:\"pod\" value:\"rook-ceph-mon-.*\" > matchers:<name:\"__name__\" value:\"kube_pod_status_phase\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:36.136358710Z level=error ts=2022-05-24T18:43:36.136324277Z caller=proxy.go:268 component=proxy request="min_time:1653417516131 max_time:1653417816131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_num_elections\" > aggregates:COUNTER partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:36.136486185Z level=error ts=2022-05-24T18:43:36.136463295Z caller=proxy.go:268 component=proxy request="min_time:1653417516131 max_time:1653417816131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:36.136539706Z level=error ts=2022-05-24T18:43:36.136519724Z caller=proxy.go:314 component=proxy request="min_time:1653417516131 max_time:1653417816131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_num_elections\" > aggregates:COUNTER partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:36.136613844Z level=error ts=2022-05-24T18:43:36.136574287Z caller=proxy.go:314 component=proxy request="min_time:1653417516131 max_time:1653417816131 matchers:<name:\"job\" value:\"rook-ceph-mgr\" > matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_mon_metadata\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:37.979724716Z level=error ts=2022-05-24T18:43:37.979675013Z caller=proxy.go:268 component=proxy request="min_time:1653417517976 max_time:1653417817976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:37.979765101Z level=error ts=2022-05-24T18:43:37.979721106Z caller=proxy.go:314 component=proxy request="min_time:1653417517976 max_time:1653417817976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:37.979836366Z level=error ts=2022-05-24T18:43:37.979816906Z caller=proxy.go:268 component=proxy request="min_time:1653417517976 max_time:1653417817976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:37.979929293Z level=error ts=2022-05-24T18:43:37.979909406Z caller=proxy.go:314 component=proxy request="min_time:1653417517976 max_time:1653417817976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:37.981245103Z level=error ts=2022-05-24T18:43:37.981211484Z caller=proxy.go:268 component=proxy request="min_time:1653417517976 max_time:1653417817976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:37.981421094Z level=error ts=2022-05-24T18:43:37.981399622Z caller=proxy.go:268 component=proxy request="min_time:1653417517976 max_time:1653417817976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:37.981525184Z level=error ts=2022-05-24T18:43:37.981506242Z caller=proxy.go:314 component=proxy request="min_time:1653417517976 max_time:1653417817976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:37.981645630Z level=error ts=2022-05-24T18:43:37.98162217Z caller=proxy.go:314 component=proxy request="min_time:1653417517976 max_time:1653417817976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:37.982690493Z level=error ts=2022-05-24T18:43:37.982655656Z caller=proxy.go:268 component=proxy request="min_time:1653417517976 max_time:1653417817976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:37.982708878Z level=error ts=2022-05-24T18:43:37.982690719Z caller=proxy.go:314 component=proxy request="min_time:1653417517976 max_time:1653417817976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:37.982778638Z level=error ts=2022-05-24T18:43:37.982759242Z caller=proxy.go:268 component=proxy request="min_time:1653417517976 max_time:1653417817976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" msg="partial response disabled; aborting request"
2022-05-24T18:43:37.982794715Z level=error ts=2022-05-24T18:43:37.982782931Z caller=proxy.go:314 component=proxy request="min_time:1653417517976 max_time:1653417817976 matchers:<name:\"namespace\" value:\"openshift-storage\" > matchers:<name:\"__name__\" value:\"ceph_cluster_total_used_raw_bytes\" > aggregates:COUNT aggregates:SUM partial_response_disabled:true " err="fetch series for {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Addr: 10.128.2.15:10901 LabelSets: {thanos_ruler_replica=\"thanos-ruler-user-workload-1\"} Mint: 1653417762981 Maxt: 9223372036854775807: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\""
2022-05-24T18:43:38.344488389Z level=warn ts=2022-05-24T18:43:38.344432443Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.128.2.15:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" address=10.128.2.15:10901
2022-05-24T18:43:38.345848704Z level=info ts=2022-05-24T18:43:38.345819343Z caller=endpointset.go:348 component=endpointset msg="removing endpoint because it's unhealthy or does not exist" address=10.128.2.15:10901 extLset="{thanos_ruler_replica=\"thanos-ruler-user-workload-1\"}"
2022-05-24T18:43:43.345408966Z level=warn ts=2022-05-24T18:43:43.34536166Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.128.2.15:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" address=10.128.2.15:10901
2022-05-24T18:43:48.344822366Z level=warn ts=2022-05-24T18:43:48.344774982Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.128.2.15:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" address=10.128.2.15:10901
2022-05-24T18:44:23.352726350Z level=info ts=2022-05-24T18:44:23.352683772Z caller=endpointset.go:371 component=endpointset msg="adding new rule with [storeAPI rulesAPI]" address=10.128.2.15:10901 extLset="{thanos_ruler_replica=\"thanos-ruler-user-workload-1\"}"
