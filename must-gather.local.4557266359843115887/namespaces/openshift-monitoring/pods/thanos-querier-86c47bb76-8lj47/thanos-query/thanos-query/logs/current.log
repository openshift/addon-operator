2022-05-24T18:42:33.795485493Z level=info ts=2022-05-24T18:42:33.795415268Z caller=client.go:55 msg="enabling client to server TLS"
2022-05-24T18:42:33.795568341Z level=info ts=2022-05-24T18:42:33.795549531Z caller=options.go:115 msg="TLS client using provided certificate pool"
2022-05-24T18:42:33.795580008Z level=info ts=2022-05-24T18:42:33.795564832Z caller=options.go:148 msg="TLS client authentication enabled"
2022-05-24T18:42:33.796851862Z ts=2022-05-24T18:42:33.796804349Z caller=log.go:168 level=debug msg="Lookback delta is zero, setting to default value" value=5m0s
2022-05-24T18:42:33.797921858Z level=info ts=2022-05-24T18:42:33.797886762Z caller=options.go:27 protocol=gRPC msg="disabled TLS, key and cert must be set to enable"
2022-05-24T18:42:33.798300635Z level=info ts=2022-05-24T18:42:33.798271736Z caller=query.go:618 msg="starting query node"
2022-05-24T18:42:33.798815432Z level=info ts=2022-05-24T18:42:33.798774795Z caller=intrumentation.go:60 msg="changing probe status" status=healthy
2022-05-24T18:42:33.798815432Z level=info ts=2022-05-24T18:42:33.798803519Z caller=http.go:63 service=http/server component=query msg="listening for requests and metrics" address=127.0.0.1:9090
2022-05-24T18:42:33.799095007Z ts=2022-05-24T18:42:33.799055735Z caller=log.go:168 service=http/server component=query level=info msg="TLS is disabled." http2=false
2022-05-24T18:42:33.799136949Z level=info ts=2022-05-24T18:42:33.799121166Z caller=intrumentation.go:48 msg="changing probe status" status=ready
2022-05-24T18:42:33.799242669Z level=info ts=2022-05-24T18:42:33.79921094Z caller=grpc.go:127 service=gRPC/server component=query msg="listening for serving gRPC" address=127.0.0.1:10901
2022-05-24T18:42:35.817630368Z level=error ts=2022-05-24T18:42:35.817572392Z caller=query.go:488 msg="failed to resolve addresses for storeAPIs" err="lookup SRV records \"_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local\": could not resolve \"_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local\": all servers responded with errors to at least one search domain. Errs ;could not resolve _grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for _grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local.: exchange: read udp 10.128.2.16:59259->172.30.0.10:53: i/o timeout"
2022-05-24T18:42:38.818078220Z level=info ts=2022-05-24T18:42:38.818032893Z caller=endpointset.go:371 component=endpointset msg="adding new rule with [storeAPI rulesAPI]" address=10.131.0.19:10901 extLset="{thanos_ruler_replica=\"thanos-ruler-user-workload-0\"}"
2022-05-24T18:42:38.818078220Z level=info ts=2022-05-24T18:42:38.818065308Z caller=endpointset.go:371 component=endpointset msg="adding new sidecar with [storeAPI rulesAPI exemplarsAPI targetsAPI MetricMetadataAPI]" address=10.131.0.17:10901 extLset="{prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-0\"}"
2022-05-24T18:42:38.818113720Z level=info ts=2022-05-24T18:42:38.818078307Z caller=endpointset.go:371 component=endpointset msg="adding new rule with [storeAPI rulesAPI]" address=10.128.2.15:10901 extLset="{thanos_ruler_replica=\"thanos-ruler-user-workload-1\"}"
2022-05-24T18:42:38.818113720Z level=info ts=2022-05-24T18:42:38.818090046Z caller=endpointset.go:371 component=endpointset msg="adding new sidecar with [storeAPI rulesAPI exemplarsAPI targetsAPI MetricMetadataAPI]" address=10.131.2.8:10901 extLset="{prometheus=\"openshift-monitoring/k8s\", prometheus_replica=\"prometheus-k8s-0\"}"
2022-05-24T18:42:38.818113720Z level=info ts=2022-05-24T18:42:38.818101586Z caller=endpointset.go:371 component=endpointset msg="adding new sidecar with [storeAPI rulesAPI exemplarsAPI targetsAPI MetricMetadataAPI]" address=10.130.2.11:10901 extLset="{prometheus=\"openshift-monitoring/k8s\", prometheus_replica=\"prometheus-k8s-1\"}"
2022-05-24T18:43:08.805520139Z level=info ts=2022-05-24T18:43:08.805475476Z caller=endpointset.go:371 component=endpointset msg="adding new sidecar with [storeAPI rulesAPI exemplarsAPI targetsAPI MetricMetadataAPI]" address=10.128.2.17:10901 extLset="{prometheus=\"openshift-user-workload-monitoring/user-workload\", prometheus_replica=\"prometheus-user-workload-1\"}"
2022-05-24T18:43:33.811199970Z level=error ts=2022-05-24T18:43:33.811148813Z caller=query.go:488 msg="failed to resolve addresses for storeAPIs" err="lookup IP addresses \"_grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local\": could not resolve \"10-131-0-19.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.\": all servers responded with errors to at least one search domain. Errs ;could not resolve 10-131-0-19.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for 10-131-0-19.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local.: exchange: read udp 10.128.2.16:39350->172.30.0.10:53: read: connection refused"
2022-05-24T18:43:35.827209590Z level=error ts=2022-05-24T18:43:35.827113318Z caller=query.go:494 msg="failed to resolve addresses for targetsAPIs" err="lookup SRV records \"_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local\": could not resolve \"_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local\": all servers responded with errors to at least one search domain. Errs ;could not resolve _grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for _grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local.: exchange: read udp 10.128.2.16:41685->172.30.0.10:53: read: connection refused;could not resolve _grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local.openshift-monitoring.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for _grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local.openshift-monitoring.svc.cluster.local.: exchange: read udp 10.128.2.16:42066->172.30.0.10:53: i/o timeout;could not resolve _grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local.svc.cluster.local.: no servers returned a viable answer. Errs ;resolution against server 172.30.0.10 for _grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local.svc.cluster.local.: exchange: read udp 10.128.2.16:41345->172.30.0.10:53: read: connection refused"
2022-05-24T18:43:38.799785776Z level=warn ts=2022-05-24T18:43:38.799736007Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.128.2.15:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" address=10.128.2.15:10901
2022-05-24T18:43:38.801284656Z level=info ts=2022-05-24T18:43:38.801252233Z caller=endpointset.go:348 component=endpointset msg="removing endpoint because it's unhealthy or does not exist" address=10.128.2.15:10901 extLset="{thanos_ruler_replica=\"thanos-ruler-user-workload-1\"}"
2022-05-24T18:43:43.800200232Z level=warn ts=2022-05-24T18:43:43.800147989Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.128.2.15:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" address=10.128.2.15:10901
2022-05-24T18:43:48.802158120Z level=warn ts=2022-05-24T18:43:48.80210089Z caller=endpointset.go:525 component=endpointset msg="update of node failed" err="getting metadata: fallback fetching info from 10.128.2.15:10901: rpc error: code = Unavailable desc = connection error: desc = \"transport: Error while dialing dial tcp 10.128.2.15:10901: connect: connection refused\"" address=10.128.2.15:10901
2022-05-24T18:43:53.804844947Z level=info ts=2022-05-24T18:43:53.804795221Z caller=endpointset.go:371 component=endpointset msg="adding new rule with [storeAPI rulesAPI]" address=10.128.2.15:10901 extLset="{thanos_ruler_replica=\"thanos-ruler-user-workload-1\"}"
