---
apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.130.2.12"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.130.2.12"
            ],
            "default": true,
            "dns": {}
        }]
      kubectl.kubernetes.io/default-container: alertmanager
      openshift.io/scc: nonroot
    creationTimestamp: "2022-05-24T18:35:00Z"
    generateName: alertmanager-main-
    labels:
      alertmanager: main
      app.kubernetes.io/component: alert-router
      app.kubernetes.io/instance: main
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 0.23.0
      controller-revision-hash: alertmanager-main-58c6f857b4
      statefulset.kubernetes.io/pod-name: alertmanager-main-0
    name: alertmanager-main-0
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: alertmanager-main
      uid: 252a0be3-2c19-4173-82e8-dae4cfb40e00
    resourceVersion: "70656"
    uid: bb4730a0-7d76-4634-a38c-f2f14d12b386
  spec:
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/component: alert-router
              app.kubernetes.io/instance: main
              app.kubernetes.io/name: alertmanager
              app.kubernetes.io/part-of: openshift-monitoring
          namespaces:
          - openshift-monitoring
          topologyKey: kubernetes.io/hostname
    containers:
    - args:
      - --config.file=/etc/alertmanager/config/alertmanager.yaml
      - --storage.path=/alertmanager
      - --data.retention=120h
      - --cluster.listen-address=[$(POD_IP)]:9094
      - --web.listen-address=127.0.0.1:9093
      - --web.external-url=https:/console-openshift-console.apps.odf-service.dif5.p1.openshiftapps.com/monitoring
      - --web.route-prefix=/
      - --cluster.peer=alertmanager-main-0.alertmanager-operated:9094
      - --cluster.peer=alertmanager-main-1.alertmanager-operated:9094
      - --cluster.reconnect-timeout=5m
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:21780af60acd852880a5b19eb1d3597e83fd2d4e3854c48f7763f04100756a36
      imagePullPolicy: IfNotPresent
      name: alertmanager
      ports:
      - containerPort: 9094
        name: mesh-tcp
        protocol: TCP
      - containerPort: 9094
        name: mesh-udp
        protocol: UDP
      resources:
        requests:
          cpu: 4m
          memory: 40Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
      - mountPath: /etc/alertmanager/certs
        name: tls-assets
        readOnly: true
      - mountPath: /alertmanager
        name: alertmanager-data
        subPath: alertmanager-db
      - mountPath: /etc/alertmanager/secrets/alertmanager-main-tls
        name: secret-alertmanager-main-tls
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-main-proxy
        name: secret-alertmanager-main-proxy
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-kube-rbac-proxy
        name: secret-alertmanager-kube-rbac-proxy
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-kube-rbac-proxy-metric
        name: secret-alertmanager-kube-rbac-proxy-metric
        readOnly: true
      - mountPath: /etc/pki/ca-trust/extracted/pem/
        name: alertmanager-trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8p948
        readOnly: true
    - args:
      - --listen-address=localhost:8080
      - --reload-url=http://localhost:9093/-/reload
      - --watched-dir=/etc/alertmanager/config
      - --watched-dir=/etc/alertmanager/secrets/alertmanager-main-tls
      - --watched-dir=/etc/alertmanager/secrets/alertmanager-main-proxy
      - --watched-dir=/etc/alertmanager/secrets/alertmanager-kube-rbac-proxy
      - --watched-dir=/etc/alertmanager/secrets/alertmanager-kube-rbac-proxy-metric
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      imagePullPolicy: IfNotPresent
      name: config-reloader
      resources:
        requests:
          cpu: 1m
          memory: 10Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-main-tls
        name: secret-alertmanager-main-tls
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-main-proxy
        name: secret-alertmanager-main-proxy
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-kube-rbac-proxy
        name: secret-alertmanager-kube-rbac-proxy
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-kube-rbac-proxy-metric
        name: secret-alertmanager-kube-rbac-proxy-metric
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8p948
        readOnly: true
    - args:
      - -provider=openshift
      - -https-address=:9095
      - -http-address=
      - -email-domain=*
      - -upstream=http://localhost:9093
      - '-openshift-sar=[{"resource": "namespaces", "verb": "get"}, {"resource": "alertmanagers",
        "resourceAPIGroup": "monitoring.coreos.com", "namespace": "openshift-monitoring",
        "verb": "patch", "resourceName": "non-existant"}]'
      - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"},
        "/": {"resource":"alertmanagers", "group": "monitoring.coreos.com", "namespace":
        "openshift-monitoring", "verb": "patch", "name": "non-existant"}}'
      - -tls-cert=/etc/tls/private/tls.crt
      - -tls-key=/etc/tls/private/tls.key
      - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
      - -cookie-secret-file=/etc/proxy/secrets/session_secret
      - -openshift-service-account=alertmanager-main
      - -openshift-ca=/etc/pki/tls/cert.pem
      - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      env:
      - name: HTTP_PROXY
      - name: HTTPS_PROXY
      - name: NO_PROXY
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      imagePullPolicy: IfNotPresent
      name: alertmanager-proxy
      ports:
      - containerPort: 9095
        name: web
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 20Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-alertmanager-main-tls
      - mountPath: /etc/proxy/secrets
        name: secret-alertmanager-main-proxy
      - mountPath: /etc/pki/ca-trust/extracted/pem/
        name: alertmanager-trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8p948
        readOnly: true
    - args:
      - --secure-listen-address=0.0.0.0:9092
      - --upstream=http://127.0.0.1:9096
      - --config-file=/etc/kube-rbac-proxy/config.yaml
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --logtostderr=true
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9092
        name: tenancy
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/kube-rbac-proxy
        name: secret-alertmanager-kube-rbac-proxy
      - mountPath: /etc/tls/private
        name: secret-alertmanager-main-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8p948
        readOnly: true
    - args:
      - --secure-listen-address=0.0.0.0:9097
      - --upstream=http://127.0.0.1:9093
      - --config-file=/etc/kube-rbac-proxy/config.yaml
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --logtostderr=true
      - --allow-paths=/metrics
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-metric
      ports:
      - containerPort: 9097
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/kube-rbac-proxy
        name: secret-alertmanager-kube-rbac-proxy-metric
        readOnly: true
      - mountPath: /etc/tls/private
        name: secret-alertmanager-main-tls
        readOnly: true
      - mountPath: /etc/tls/client
        name: metrics-client-ca
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8p948
        readOnly: true
    - args:
      - --insecure-listen-address=127.0.0.1:9096
      - --upstream=http://127.0.0.1:9093
      - --label=namespace
      - --error-on-replace
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c3e8963d0e5dbce2e30dc0341c7453c30a42395622905b718a8fe9974da41ab
      imagePullPolicy: IfNotPresent
      name: prom-label-proxy
      resources:
        requests:
          cpu: 1m
          memory: 20Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8p948
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: alertmanager-main-0
    imagePullSecrets:
    - name: alertmanager-main-dockercfg-wgqwb
    nodeName: ip-10-0-140-240.ec2.internal
    nodeSelector:
      node-role.kubernetes.io/infra: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: alertmanager-main
    serviceAccountName: alertmanager-main
    subdomain: alertmanager-operated
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - name: alertmanager-data
      persistentVolumeClaim:
        claimName: alertmanager-data-alertmanager-main-0
    - name: config-volume
      secret:
        defaultMode: 420
        secretName: alertmanager-main-generated
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: alertmanager-main-tls-assets-0
    - name: secret-alertmanager-main-tls
      secret:
        defaultMode: 420
        secretName: alertmanager-main-tls
    - name: secret-alertmanager-main-proxy
      secret:
        defaultMode: 420
        secretName: alertmanager-main-proxy
    - name: secret-alertmanager-kube-rbac-proxy
      secret:
        defaultMode: 420
        secretName: alertmanager-kube-rbac-proxy
    - name: secret-alertmanager-kube-rbac-proxy-metric
      secret:
        defaultMode: 420
        secretName: alertmanager-kube-rbac-proxy-metric
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: alertmanager-trusted-ca-bundle-2rsonso43rc5p
        optional: true
      name: alertmanager-trusted-ca-bundle
    - name: kube-api-access-8p948
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:09Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:25Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:25Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:09Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://a099dfe40a2230c58bb2573a5d13a1ddec51fe96d97439568536006833ed3107
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:21780af60acd852880a5b19eb1d3597e83fd2d4e3854c48f7763f04100756a36
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:21780af60acd852880a5b19eb1d3597e83fd2d4e3854c48f7763f04100756a36
      lastState: {}
      name: alertmanager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:23Z"
    - containerID: cri-o://9323e0135d8ec3a9eb54fd0f725841ff2ed4bfa032bb107b1d5e94dc139f20f8
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      lastState: {}
      name: alertmanager-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:24Z"
    - containerID: cri-o://6e23c172b5e4fb664e751a10935fb0af79bc26e5d49217871c656ae7ea79eb4b
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      lastState: {}
      name: config-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:24Z"
    - containerID: cri-o://f62cbb1cf24cf54d65ac282b030a7919767aa428e606d1fec92f8a28ab50e28e
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:24Z"
    - containerID: cri-o://05765c94759dfd946ebd8a1623864a9bec463b3b6d01c023aae929c6e7ff04e7
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy-metric
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:25Z"
    - containerID: cri-o://13bf9904bd06176d642444bab7f09fde4ea2e56f03e41e39595bed4414e2c87d
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c3e8963d0e5dbce2e30dc0341c7453c30a42395622905b718a8fe9974da41ab
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c3e8963d0e5dbce2e30dc0341c7453c30a42395622905b718a8fe9974da41ab
      lastState: {}
      name: prom-label-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:25Z"
    hostIP: 10.0.140.240
    phase: Running
    podIP: 10.130.2.12
    podIPs:
    - ip: 10.130.2.12
    qosClass: Burstable
    startTime: "2022-05-24T18:40:09Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.7"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.7"
            ],
            "default": true,
            "dns": {}
        }]
      kubectl.kubernetes.io/default-container: alertmanager
      openshift.io/scc: nonroot
    creationTimestamp: "2022-05-24T18:28:25Z"
    generateName: alertmanager-main-
    labels:
      alertmanager: main
      app.kubernetes.io/component: alert-router
      app.kubernetes.io/instance: main
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 0.23.0
      controller-revision-hash: alertmanager-main-58c6f857b4
      statefulset.kubernetes.io/pod-name: alertmanager-main-1
    name: alertmanager-main-1
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: alertmanager-main
      uid: 252a0be3-2c19-4173-82e8-dae4cfb40e00
    resourceVersion: "56938"
    uid: 7f8db3de-ab08-42b9-90ff-bedde5b59d6a
  spec:
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/component: alert-router
              app.kubernetes.io/instance: main
              app.kubernetes.io/name: alertmanager
              app.kubernetes.io/part-of: openshift-monitoring
          namespaces:
          - openshift-monitoring
          topologyKey: kubernetes.io/hostname
    containers:
    - args:
      - --config.file=/etc/alertmanager/config/alertmanager.yaml
      - --storage.path=/alertmanager
      - --data.retention=120h
      - --cluster.listen-address=[$(POD_IP)]:9094
      - --web.listen-address=127.0.0.1:9093
      - --web.external-url=https:/console-openshift-console.apps.odf-service.dif5.p1.openshiftapps.com/monitoring
      - --web.route-prefix=/
      - --cluster.peer=alertmanager-main-0.alertmanager-operated:9094
      - --cluster.peer=alertmanager-main-1.alertmanager-operated:9094
      - --cluster.reconnect-timeout=5m
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:21780af60acd852880a5b19eb1d3597e83fd2d4e3854c48f7763f04100756a36
      imagePullPolicy: IfNotPresent
      name: alertmanager
      ports:
      - containerPort: 9094
        name: mesh-tcp
        protocol: TCP
      - containerPort: 9094
        name: mesh-udp
        protocol: UDP
      resources:
        requests:
          cpu: 4m
          memory: 40Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
      - mountPath: /etc/alertmanager/certs
        name: tls-assets
        readOnly: true
      - mountPath: /alertmanager
        name: alertmanager-data
        subPath: alertmanager-db
      - mountPath: /etc/alertmanager/secrets/alertmanager-main-tls
        name: secret-alertmanager-main-tls
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-main-proxy
        name: secret-alertmanager-main-proxy
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-kube-rbac-proxy
        name: secret-alertmanager-kube-rbac-proxy
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-kube-rbac-proxy-metric
        name: secret-alertmanager-kube-rbac-proxy-metric
        readOnly: true
      - mountPath: /etc/pki/ca-trust/extracted/pem/
        name: alertmanager-trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8pj6z
        readOnly: true
    - args:
      - --listen-address=localhost:8080
      - --reload-url=http://localhost:9093/-/reload
      - --watched-dir=/etc/alertmanager/config
      - --watched-dir=/etc/alertmanager/secrets/alertmanager-main-tls
      - --watched-dir=/etc/alertmanager/secrets/alertmanager-main-proxy
      - --watched-dir=/etc/alertmanager/secrets/alertmanager-kube-rbac-proxy
      - --watched-dir=/etc/alertmanager/secrets/alertmanager-kube-rbac-proxy-metric
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      imagePullPolicy: IfNotPresent
      name: config-reloader
      resources:
        requests:
          cpu: 1m
          memory: 10Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-main-tls
        name: secret-alertmanager-main-tls
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-main-proxy
        name: secret-alertmanager-main-proxy
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-kube-rbac-proxy
        name: secret-alertmanager-kube-rbac-proxy
        readOnly: true
      - mountPath: /etc/alertmanager/secrets/alertmanager-kube-rbac-proxy-metric
        name: secret-alertmanager-kube-rbac-proxy-metric
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8pj6z
        readOnly: true
    - args:
      - -provider=openshift
      - -https-address=:9095
      - -http-address=
      - -email-domain=*
      - -upstream=http://localhost:9093
      - '-openshift-sar=[{"resource": "namespaces", "verb": "get"}, {"resource": "alertmanagers",
        "resourceAPIGroup": "monitoring.coreos.com", "namespace": "openshift-monitoring",
        "verb": "patch", "resourceName": "non-existant"}]'
      - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"},
        "/": {"resource":"alertmanagers", "group": "monitoring.coreos.com", "namespace":
        "openshift-monitoring", "verb": "patch", "name": "non-existant"}}'
      - -tls-cert=/etc/tls/private/tls.crt
      - -tls-key=/etc/tls/private/tls.key
      - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
      - -cookie-secret-file=/etc/proxy/secrets/session_secret
      - -openshift-service-account=alertmanager-main
      - -openshift-ca=/etc/pki/tls/cert.pem
      - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      env:
      - name: HTTP_PROXY
      - name: HTTPS_PROXY
      - name: NO_PROXY
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      imagePullPolicy: IfNotPresent
      name: alertmanager-proxy
      ports:
      - containerPort: 9095
        name: web
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 20Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-alertmanager-main-tls
      - mountPath: /etc/proxy/secrets
        name: secret-alertmanager-main-proxy
      - mountPath: /etc/pki/ca-trust/extracted/pem/
        name: alertmanager-trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8pj6z
        readOnly: true
    - args:
      - --secure-listen-address=0.0.0.0:9092
      - --upstream=http://127.0.0.1:9096
      - --config-file=/etc/kube-rbac-proxy/config.yaml
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --logtostderr=true
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9092
        name: tenancy
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/kube-rbac-proxy
        name: secret-alertmanager-kube-rbac-proxy
      - mountPath: /etc/tls/private
        name: secret-alertmanager-main-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8pj6z
        readOnly: true
    - args:
      - --secure-listen-address=0.0.0.0:9097
      - --upstream=http://127.0.0.1:9093
      - --config-file=/etc/kube-rbac-proxy/config.yaml
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --logtostderr=true
      - --allow-paths=/metrics
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-metric
      ports:
      - containerPort: 9097
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/kube-rbac-proxy
        name: secret-alertmanager-kube-rbac-proxy-metric
        readOnly: true
      - mountPath: /etc/tls/private
        name: secret-alertmanager-main-tls
        readOnly: true
      - mountPath: /etc/tls/client
        name: metrics-client-ca
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8pj6z
        readOnly: true
    - args:
      - --insecure-listen-address=127.0.0.1:9096
      - --upstream=http://127.0.0.1:9093
      - --label=namespace
      - --error-on-replace
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c3e8963d0e5dbce2e30dc0341c7453c30a42395622905b718a8fe9974da41ab
      imagePullPolicy: IfNotPresent
      name: prom-label-proxy
      resources:
        requests:
          cpu: 1m
          memory: 20Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8pj6z
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: alertmanager-main-1
    imagePullSecrets:
    - name: alertmanager-main-dockercfg-wgqwb
    nodeName: ip-10-0-166-35.ec2.internal
    nodeSelector:
      node-role.kubernetes.io/infra: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: alertmanager-main
    serviceAccountName: alertmanager-main
    subdomain: alertmanager-operated
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - name: alertmanager-data
      persistentVolumeClaim:
        claimName: alertmanager-data-alertmanager-main-1
    - name: config-volume
      secret:
        defaultMode: 420
        secretName: alertmanager-main-generated
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: alertmanager-main-tls-assets-0
    - name: secret-alertmanager-main-tls
      secret:
        defaultMode: 420
        secretName: alertmanager-main-tls
    - name: secret-alertmanager-main-proxy
      secret:
        defaultMode: 420
        secretName: alertmanager-main-proxy
    - name: secret-alertmanager-kube-rbac-proxy
      secret:
        defaultMode: 420
        secretName: alertmanager-kube-rbac-proxy
    - name: secret-alertmanager-kube-rbac-proxy-metric
      secret:
        defaultMode: 420
        secretName: alertmanager-kube-rbac-proxy-metric
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: alertmanager-trusted-ca-bundle-2rsonso43rc5p
        optional: true
      name: alertmanager-trusted-ca-bundle
    - name: kube-api-access-8pj6z
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:32:29Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:32:40Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:32:40Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:32:29Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://3c471cab0bbaade74142d75cf97f073dfe8cb2a1d4aad8475900543a6209628d
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:21780af60acd852880a5b19eb1d3597e83fd2d4e3854c48f7763f04100756a36
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:21780af60acd852880a5b19eb1d3597e83fd2d4e3854c48f7763f04100756a36
      lastState: {}
      name: alertmanager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:32:37Z"
    - containerID: cri-o://e5619c675a6d84b2196d70dc37bddabbcb3cc84b4a7d91c40b985d103b306480
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      lastState: {}
      name: alertmanager-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:32:38Z"
    - containerID: cri-o://385e2377e4498a6cd94e3f2c8447a0316ba8d532a3e18fda23f22f3e668d847c
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      lastState: {}
      name: config-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:32:38Z"
    - containerID: cri-o://7ce1e3b4f58001be4c6264122c02c70420bd06d68b8d5c5af95f94d8376dac22
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:32:38Z"
    - containerID: cri-o://32e9d91fed7aa47e242a6c851102cbfe4e6ceb40a50b548f71d64ba4d2c75dd4
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy-metric
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:32:38Z"
    - containerID: cri-o://df8c1c34acfe629309ee05a5a37a064f12b18b094ca5ef57d5282fe2abaa47ff
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c3e8963d0e5dbce2e30dc0341c7453c30a42395622905b718a8fe9974da41ab
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c3e8963d0e5dbce2e30dc0341c7453c30a42395622905b718a8fe9974da41ab
      lastState: {}
      name: prom-label-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:32:40Z"
    hostIP: 10.0.166.35
    phase: Running
    podIP: 10.131.2.7
    podIPs:
    - ip: 10.131.2.7
    qosClass: Burstable
    startTime: "2022-05-24T18:32:29Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.130.0.27"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.130.0.27"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:36:40Z"
    generateName: cluster-monitoring-operator-d9db9df7c-
    labels:
      app: cluster-monitoring-operator
      app.kubernetes.io/name: cluster-monitoring-operator
      pod-template-hash: d9db9df7c
    name: cluster-monitoring-operator-d9db9df7c-qmlf8
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: cluster-monitoring-operator-d9db9df7c
      uid: 002361d0-e9a3-4085-b178-d2e038158cb2
    resourceVersion: "63978"
    uid: 64d901d8-db08-49e5-a74a-e8a30ed41eb2
  spec:
    containers:
    - args:
      - --logtostderr
      - --secure-listen-address=:8443
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
      - --upstream=http://127.0.0.1:8080/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 8443
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 20Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: cluster-monitoring-operator-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ddgj5
        readOnly: true
    - args:
      - -namespace=openshift-monitoring
      - -namespace-user-workload=openshift-user-workload-monitoring
      - -configmap=cluster-monitoring-config
      - -release-version=$(RELEASE_VERSION)
      - -logtostderr=true
      - -v=2
      - -images=prometheus-operator=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:6332f67ddb8aaba08639689ea91e5a0075e07dbfaea704a8a2b4cb7645281136
      - -images=prometheus-config-reloader=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      - -images=configmap-reloader=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:29383a4e84dc026ecc9d313b83b8eef1280674a42e4447f5cf3b6f045a3a4f10
      - -images=prometheus=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:727fe0f3dcdad60f8beee58590b33815345e12d86f9526af81b45de17fb28f59
      - -images=alertmanager=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:21780af60acd852880a5b19eb1d3597e83fd2d4e3854c48f7763f04100756a36
      - -images=grafana=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:39594b0dd96744cb8fa31cf0485f7bee06159dc08e489edbacba3b3062efbb68
      - -images=oauth-proxy=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      - -images=node-exporter=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      - -images=kube-state-metrics=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:3b2f92612cf6a35edaade46270a961653eb53152a1217fa74be685ac3cfa8b71
      - -images=openshift-state-metrics=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:e52032d4e2993366d3b3e6fc81837b2cd79f1a8be5638b9cf409a9aa7547495a
      - -images=kube-rbac-proxy=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      - -images=telemeter-client=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:3cd352ab6f82a1f5f762b6283f9644e653d37dcdbab27e1fae3d5a82a76d2a9f
      - -images=prom-label-proxy=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c3e8963d0e5dbce2e30dc0341c7453c30a42395622905b718a8fe9974da41ab
      - -images=k8s-prometheus-adapter=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:750e142e941a9b9e1822c52bc671d01ebcb5bf479b42fab978b76c44b17685b5
      - -images=thanos=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8a5a316dec56c12072bd11525534dc01cad163fd44766be4e1fb3406796e662d
      env:
      - name: RELEASE_VERSION
        value: 4.10.13
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5ae10a5aa60a664893a010afadb0d02833826980d0148f22497fc947c1fb142e
      imagePullPolicy: IfNotPresent
      name: cluster-monitoring-operator
      resources:
        requests:
          cpu: 10m
          memory: 75Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/cluster-monitoring-operator/telemetry
        name: telemetry-config
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ddgj5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: cluster-monitoring-operator-dockercfg-fcb7z
    nodeName: ip-10-0-138-197.ec2.internal
    nodeSelector:
      kubernetes.io/os: linux
      node-role.kubernetes.io/master: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: cluster-monitoring-operator
    serviceAccountName: cluster-monitoring-operator
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 120
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 120
    volumes:
    - configMap:
        defaultMode: 420
        name: telemetry-config
      name: telemetry-config
    - name: cluster-monitoring-operator-tls
      secret:
        defaultMode: 420
        secretName: cluster-monitoring-operator-tls
    - name: kube-api-access-ddgj5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:36:40Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:36:46Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:36:46Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:36:40Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://2b636a24d95bfd8e3bafacdc1c48f8e419b36fe6cb4decd1bcf8586f2e4171dd
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5ae10a5aa60a664893a010afadb0d02833826980d0148f22497fc947c1fb142e
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5ae10a5aa60a664893a010afadb0d02833826980d0148f22497fc947c1fb142e
      lastState: {}
      name: cluster-monitoring-operator
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:36:46Z"
    - containerID: cri-o://b59e112b8ea3834a82eabf10743bcf76acda41d3dc3f93841d8999fa40830cfb
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:36:43Z"
    hostIP: 10.0.138.197
    phase: Running
    podIP: 10.130.0.27
    podIPs:
    - ip: 10.130.0.27
    qosClass: Burstable
    startTime: "2022-05-24T18:36:40Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      categories: A list of comma separated categories that your operator falls under.
      certified: "false"
      containerImage: ""
      createdAt: "2022-03-25T05:30:08Z"
      description: OpenShift cluster provisioning and management at scale.
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.19"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.19"
            ],
            "default": true,
            "dns": {}
        }]
      olm.operatorGroup: openshift-cluster-monitoring
      olm.operatorNamespace: openshift-monitoring
      olm.targetNamespaces: openshift-addon-operator,openshift-apiserver,openshift-apiserver-operator,openshift-authentication,openshift-authentication-operator,openshift-build-test,openshift-cloud-controller-manager,openshift-cloud-controller-manager-operator,openshift-cloud-credential-operator,openshift-cloud-network-config-controller,openshift-cluster-csi-drivers,openshift-cluster-machine-approver,openshift-cluster-node-tuning-operator,openshift-cluster-samples-operator,openshift-cluster-storage-operator,openshift-cluster-version,openshift-codeready-workspaces,openshift-config-operator,openshift-console,openshift-console-operator,openshift-controller-manager,openshift-controller-manager-operator,openshift-custom-domains-operator,openshift-dns,openshift-dns-operator,openshift-etcd-operator,openshift-image-registry,openshift-ingress,openshift-ingress-operator,openshift-insights,openshift-kube-apiserver,openshift-kube-apiserver-operator,openshift-kube-controller-manager,openshift-kube-controller-manager-operator,openshift-kube-scheduler,openshift-kube-scheduler-operator,openshift-kube-storage-version-migrator,openshift-kube-storage-version-migrator-operator,openshift-machine-api,openshift-machine-config-operator,openshift-managed-node-metadata-operator,openshift-managed-upgrade-operator,openshift-marketplace,openshift-monitoring,openshift-multus,openshift-must-gather-operator,openshift-network-diagnostics,openshift-oauth-apiserver,openshift-ocm-agent-operator,openshift-operator-lifecycle-manager,openshift-osd-metrics,openshift-rbac-permissions,openshift-route-monitor-operator,openshift-sdn,openshift-service-ca-operator,openshift-user-workload-monitoring,openshift-validation-webhook,openshift-velero
      openshift.io/scc: restricted
      operatorframework.io/properties: '{"properties":[{"type":"olm.package","value":{"packageName":"configure-alertmanager-operator","version":"0.1.418-9e79f67"}}]}'
      support: OSD SRE
    creationTimestamp: "2022-05-24T18:38:55Z"
    generateName: configure-alertmanager-operator-6bf57f7cbc-
    labels:
      name: configure-alertmanager-operator
      pod-template-hash: 6bf57f7cbc
    name: configure-alertmanager-operator-6bf57f7cbc-4sfxv
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: configure-alertmanager-operator-6bf57f7cbc
      uid: 89df1660-86d7-4a73-a017-a1c89270e062
    resourceVersion: "70387"
    uid: ab03f3e5-82f2-4bec-bd0f-6ac6df7820c3
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/infra
              operator: Exists
          weight: 1
    containers:
    - command:
      - configure-alertmanager-operator
      env:
      - name: WATCH_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: OPERATOR_NAME
        value: configure-alertmanager-operator
      - name: FEDRAMP
        value: "false"
      - name: OPERATOR_IMAGE
        value: quay.io/app-sre/configure-alertmanager-operator@sha256:2253fe906430e59544adaa5a84ecfbfc18801ebc9856d759fb965ef9fbd46a4e
      - name: OPERATOR_CONDITION_NAME
        value: configure-alertmanager-operator.v0.1.418-9e79f67
      image: quay.io/app-sre/configure-alertmanager-operator@sha256:2253fe906430e59544adaa5a84ecfbfc18801ebc9856d759fb965ef9fbd46a4e
      imagePullPolicy: Always
      name: configure-alertmanager-operator
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rb7lp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: configure-alertmanager-operator-dockercfg-4dbd4
    nodeName: ip-10-0-166-35.ec2.internal
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: configure-alertmanager-operator
    serviceAccountName: configure-alertmanager-operator
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-rb7lp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:09Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:19Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:19Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:09Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://5d6ed5111d98b70e23d07530ad1ae1e94b965059be08edd4dc06caefd02c5f18
      image: quay.io/app-sre/configure-alertmanager-operator@sha256:2253fe906430e59544adaa5a84ecfbfc18801ebc9856d759fb965ef9fbd46a4e
      imageID: quay.io/app-sre/configure-alertmanager-operator@sha256:2253fe906430e59544adaa5a84ecfbfc18801ebc9856d759fb965ef9fbd46a4e
      lastState: {}
      name: configure-alertmanager-operator
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:19Z"
    hostIP: 10.0.166.35
    phase: Running
    podIP: 10.131.2.19
    podIPs:
    - ip: 10.131.2.19
    qosClass: BestEffort
    startTime: "2022-05-24T18:40:09Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.0.49"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.0.49"
            ],
            "default": true,
            "dns": {}
        }]
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"operators.coreos.com/v1alpha1","kind":"CatalogSource","metadata":{"annotations":{},"labels":{"hive.openshift.io/managed":"true","opsrc-datastore":"true","opsrc-provider":"redhat"},"name":"configure-alertmanager-operator-registry","namespace":"openshift-monitoring"},"spec":{"affinity":{"nodeAffinity":{"preferredDuringSchedulingIgnoredDuringExecution":[{"preference":{"matchExpressions":[{"key":"node-role.kubernetes.io/infra","operator":"Exists"}]},"weight":1}]}},"displayName":"Configure Alertmanager Operator","icon":{"base64data":"","mediatype":""},"image":"quay.io/app-sre/configure-alertmanager-operator-registry@sha256:650a457e673ee1a1b82621d886083e868a458bbb047dc6f110da2dc3edd25aa6","publisher":"Red Hat","sourceType":"grpc","tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/infra","operator":"Exists"}]}}
      openshift.io/scc: anyuid
    creationTimestamp: "2022-05-24T18:42:32Z"
    generateName: configure-alertmanager-operator-registry-
    labels:
      olm.catalogSource: configure-alertmanager-operator-registry
      olm.pod-spec-hash: 6ccb8f9985
    name: configure-alertmanager-operator-registry-5rlkg
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: operators.coreos.com/v1alpha1
      blockOwnerDeletion: false
      controller: false
      kind: CatalogSource
      name: configure-alertmanager-operator-registry
      uid: 3791c25c-4418-45bd-b05e-06f4c9e8f671
    resourceVersion: "76285"
    uid: 832e302e-afc2-4ad1-a08b-610597c4bdd7
  spec:
    containers:
    - image: quay.io/app-sre/configure-alertmanager-operator-registry@sha256:650a457e673ee1a1b82621d886083e868a458bbb047dc6f110da2dc3edd25aa6
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - grpc_health_probe
          - -addr=:50051
        failureThreshold: 3
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: registry-server
      ports:
      - containerPort: 50051
        name: grpc
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - grpc_health_probe
          - -addr=:50051
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        requests:
          cpu: 10m
          memory: 50Mi
      securityContext:
        capabilities:
          drop:
          - MKNOD
        readOnlyRootFilesystem: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-l4vmp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: configure-alertmanager-operator-registry-dockercfg-9ptbl
    nodeName: ip-10-0-128-34.ec2.internal
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: configure-alertmanager-operator-registry
    serviceAccountName: configure-alertmanager-operator-registry
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - name: kube-api-access-l4vmp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:33Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:50Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:50Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:33Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://fa2b3d6cc505ccff3d447b7686365c506584fd964f8319b67423e13cecf8ff98
      image: quay.io/app-sre/configure-alertmanager-operator-registry@sha256:650a457e673ee1a1b82621d886083e868a458bbb047dc6f110da2dc3edd25aa6
      imageID: quay.io/app-sre/configure-alertmanager-operator-registry@sha256:650a457e673ee1a1b82621d886083e868a458bbb047dc6f110da2dc3edd25aa6
      lastState: {}
      name: registry-server
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:42:37Z"
    hostIP: 10.0.128.34
    phase: Running
    podIP: 10.131.0.49
    podIPs:
    - ip: 10.131.0.49
    qosClass: Burstable
    startTime: "2022-05-24T18:42:33Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/grafana-config: 28b9b36ac4d235c1c5f2f9ca81714d1c
      checksum/grafana-dashboardproviders: 9ac0e8fe144a3a59f7ab62b4e733f22d
      checksum/grafana-datasources: 58dfbb3df9951f2ac8acf4c625c7173c
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.10"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.10"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:34:57Z"
    generateName: grafana-56c5499d4d-
    labels:
      app.kubernetes.io/component: grafana
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: grafana
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 8.3.4
      pod-template-hash: 56c5499d4d
    name: grafana-56c5499d4d-lkgqn
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: grafana-56c5499d4d
      uid: f6179ea5-e2d0-42ac-9f68-cee627677321
    resourceVersion: "60594"
    uid: 4ca96914-f3cc-4968-a952-ef71cc530161
  spec:
    containers:
    - args:
      - -config=/etc/grafana/grafana.ini
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:39594b0dd96744cb8fa31cf0485f7bee06159dc08e489edbacba3b3062efbb68
      imagePullPolicy: IfNotPresent
      name: grafana
      ports:
      - containerPort: 3001
        name: http
        protocol: TCP
      resources:
        requests:
          cpu: 4m
          memory: 64Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/grafana
        name: grafana-storage
      - mountPath: /etc/grafana/provisioning/datasources
        name: grafana-datasources
      - mountPath: /etc/grafana/provisioning/dashboards
        name: grafana-dashboards
      - mountPath: /grafana-dashboard-definitions/0/cluster-total
        name: grafana-dashboard-cluster-total
      - mountPath: /grafana-dashboard-definitions/0/etcd
        name: grafana-dashboard-etcd
      - mountPath: /grafana-dashboard-definitions/0/k8s-resources-cluster
        name: grafana-dashboard-k8s-resources-cluster
      - mountPath: /grafana-dashboard-definitions/0/k8s-resources-namespace
        name: grafana-dashboard-k8s-resources-namespace
      - mountPath: /grafana-dashboard-definitions/0/k8s-resources-node
        name: grafana-dashboard-k8s-resources-node
      - mountPath: /grafana-dashboard-definitions/0/k8s-resources-pod
        name: grafana-dashboard-k8s-resources-pod
      - mountPath: /grafana-dashboard-definitions/0/k8s-resources-workload
        name: grafana-dashboard-k8s-resources-workload
      - mountPath: /grafana-dashboard-definitions/0/k8s-resources-workloads-namespace
        name: grafana-dashboard-k8s-resources-workloads-namespace
      - mountPath: /grafana-dashboard-definitions/0/namespace-by-pod
        name: grafana-dashboard-namespace-by-pod
      - mountPath: /grafana-dashboard-definitions/0/node-cluster-rsrc-use
        name: grafana-dashboard-node-cluster-rsrc-use
      - mountPath: /grafana-dashboard-definitions/0/node-rsrc-use
        name: grafana-dashboard-node-rsrc-use
      - mountPath: /grafana-dashboard-definitions/0/pod-total
        name: grafana-dashboard-pod-total
      - mountPath: /grafana-dashboard-definitions/0/prometheus
        name: grafana-dashboard-prometheus
      - mountPath: /etc/grafana
        name: grafana-config
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-7n5nr
        readOnly: true
    - args:
      - -provider=openshift
      - -https-address=:3000
      - -http-address=
      - -email-domain=*
      - -upstream=http://localhost:3001
      - '-openshift-sar={"resource": "namespaces", "verb": "get"}'
      - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}}'
      - -tls-cert=/etc/tls/private/tls.crt
      - -tls-key=/etc/tls/private/tls.key
      - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
      - -cookie-secret-file=/etc/proxy/secrets/session_secret
      - -openshift-service-account=grafana
      - -openshift-ca=/etc/pki/tls/cert.pem
      - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      env:
      - name: HTTP_PROXY
      - name: HTTPS_PROXY
      - name: NO_PROXY
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      imagePullPolicy: IfNotPresent
      name: grafana-proxy
      ports:
      - containerPort: 3000
        name: https
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /oauth/healthz
          port: https
          scheme: HTTPS
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 1m
          memory: 20Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-grafana-tls
      - mountPath: /etc/proxy/secrets
        name: secret-grafana-proxy
      - mountPath: /etc/pki/ca-trust/extracted/pem/
        name: grafana-trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-7n5nr
        readOnly: true
    - args:
      - --secure-listen-address=0.0.0.0:3002
      - --upstream=http://127.0.0.1:3001
      - --config-file=/etc/kube-rbac-proxy/config.yaml
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --logtostderr=true
      - --allow-paths=/metrics
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-metrics
      ports:
      - containerPort: 3002
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/kube-rbac-proxy
        name: secret-grafana-kube-rbac-proxy-metric
        readOnly: true
      - mountPath: /etc/tls/private
        name: secret-grafana-tls
        readOnly: true
      - mountPath: /etc/tls/client
        name: metrics-client-ca
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-7n5nr
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: grafana-dockercfg-6fbk4
    nodeName: ip-10-0-166-35.ec2.internal
    nodeSelector:
      node-role.kubernetes.io/infra: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: grafana
    serviceAccountName: grafana
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - emptyDir: {}
      name: grafana-storage
    - name: grafana-datasources
      secret:
        defaultMode: 420
        secretName: grafana-datasources-v2
    - configMap:
        defaultMode: 420
        name: grafana-dashboards
      name: grafana-dashboards
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-cluster-total
      name: grafana-dashboard-cluster-total
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-etcd
      name: grafana-dashboard-etcd
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-k8s-resources-cluster
      name: grafana-dashboard-k8s-resources-cluster
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-k8s-resources-namespace
      name: grafana-dashboard-k8s-resources-namespace
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-k8s-resources-node
      name: grafana-dashboard-k8s-resources-node
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-k8s-resources-pod
      name: grafana-dashboard-k8s-resources-pod
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-k8s-resources-workload
      name: grafana-dashboard-k8s-resources-workload
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-k8s-resources-workloads-namespace
      name: grafana-dashboard-k8s-resources-workloads-namespace
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-namespace-by-pod
      name: grafana-dashboard-namespace-by-pod
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-node-cluster-rsrc-use
      name: grafana-dashboard-node-cluster-rsrc-use
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-node-rsrc-use
      name: grafana-dashboard-node-rsrc-use
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-pod-total
      name: grafana-dashboard-pod-total
    - configMap:
        defaultMode: 420
        name: grafana-dashboard-prometheus
      name: grafana-dashboard-prometheus
    - name: grafana-config
      secret:
        defaultMode: 420
        secretName: grafana-config
    - name: secret-grafana-tls
      secret:
        defaultMode: 420
        secretName: grafana-tls
    - name: secret-grafana-kube-rbac-proxy-metric
      secret:
        defaultMode: 420
        secretName: grafana-kube-rbac-proxy-metric
    - name: secret-grafana-proxy
      secret:
        defaultMode: 420
        secretName: grafana-proxy
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: grafana-trusted-ca-bundle-2rsonso43rc5p
        optional: true
      name: grafana-trusted-ca-bundle
    - name: kube-api-access-7n5nr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:34:57Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:35:06Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:35:06Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:34:57Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://6497270c2e05041d01b88f535f77d6defcc26d097807efb841f25188b700d7fe
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:39594b0dd96744cb8fa31cf0485f7bee06159dc08e489edbacba3b3062efbb68
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:39594b0dd96744cb8fa31cf0485f7bee06159dc08e489edbacba3b3062efbb68
      lastState: {}
      name: grafana
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:35:05Z"
    - containerID: cri-o://14171e7839f1b8324c15e6ebd91218bff3d3a01128e722b7ce0b56707ab98114
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      lastState: {}
      name: grafana-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:35:05Z"
    - containerID: cri-o://890a0f712ff8670262fb84dba1630a85ac8e83afe052d576132f9ac0ecea152b
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy-metrics
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:35:05Z"
    hostIP: 10.0.166.35
    phase: Running
    podIP: 10.131.2.10
    podIPs:
    - ip: 10.131.2.10
    qosClass: Burstable
    startTime: "2022-05-24T18:34:57Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.13"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.13"
            ],
            "default": true,
            "dns": {}
        }]
      kubectl.kubernetes.io/default-container: kube-state-metrics
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:34:57Z"
    generateName: kube-state-metrics-597568c675-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 2.3.0
      pod-template-hash: 597568c675
    name: kube-state-metrics-597568c675-kx4sc
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kube-state-metrics-597568c675
      uid: 4720d6f1-62d0-4db8-a3ae-d327ac9e11ee
    resourceVersion: "60508"
    uid: e48e31ee-977a-4818-a90f-bcbe7e1a2215
  spec:
    containers:
    - args:
      - --host=127.0.0.1
      - --port=8081
      - --telemetry-host=127.0.0.1
      - --telemetry-port=8082
      - --metric-denylist=kube_secret_labels,kube_.*_annotations
      - --metric-labels-allowlist=pods=[*],nodes=[*],namespaces=[*],persistentvolumes=[*],persistentvolumeclaims=[*],poddisruptionbudgets=[*],poddisruptionbudget=[*]
      - |
        --metric-denylist=
        kube_.+_created,
        kube_.+_metadata_resource_version,
        kube_replicaset_metadata_generation,
        kube_replicaset_status_observed_generation,
        kube_pod_restart_policy,
        kube_pod_init_container_status_terminated,
        kube_pod_init_container_status_running,
        kube_pod_container_status_terminated,
        kube_pod_container_status_running,
        kube_pod_completion_time,
        kube_pod_status_scheduled
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:3b2f92612cf6a35edaade46270a961653eb53152a1217fa74be685ac3cfa8b71
      imagePullPolicy: IfNotPresent
      name: kube-state-metrics
      resources:
        requests:
          cpu: 2m
          memory: 80Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: volume-directive-shadow
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bs649
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=:8443
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --upstream=http://127.0.0.1:8081/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --config-file=/etc/kube-rbac-policy/config.yaml
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-main
      ports:
      - containerPort: 8443
        name: https-main
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: kube-state-metrics-tls
      - mountPath: /etc/tls/client
        name: metrics-client-ca
      - mountPath: /etc/kube-rbac-policy
        name: kube-state-metrics-kube-rbac-proxy-config
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bs649
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=:9443
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --upstream=http://127.0.0.1:8082/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --config-file=/etc/kube-rbac-policy/config.yaml
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-self
      ports:
      - containerPort: 9443
        name: https-self
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: kube-state-metrics-tls
      - mountPath: /etc/tls/client
        name: metrics-client-ca
      - mountPath: /etc/kube-rbac-policy
        name: kube-state-metrics-kube-rbac-proxy-config
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bs649
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: kube-state-metrics-dockercfg-whtmp
    nodeName: ip-10-0-166-35.ec2.internal
    nodeSelector:
      node-role.kubernetes.io/infra: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: kube-state-metrics
    serviceAccountName: kube-state-metrics
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - emptyDir: {}
      name: volume-directive-shadow
    - name: kube-state-metrics-tls
      secret:
        defaultMode: 420
        secretName: kube-state-metrics-tls
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - name: kube-state-metrics-kube-rbac-proxy-config
      secret:
        defaultMode: 420
        secretName: kube-state-metrics-kube-rbac-proxy-config
    - name: kube-api-access-bs649
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:34:57Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:35:03Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:35:03Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:34:57Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://b6618747756ed5cea7c35ffa99f097a76fe60a3a7d8b9922e0fdb40ad3603041
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy-main
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:35:02Z"
    - containerID: cri-o://04455a1ad46bb8a1376c09db29fbf80c68d20ee34df84166fe6889fd0fd286fa
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy-self
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:35:03Z"
    - containerID: cri-o://2da62aa49b7ea9b695b051322e1080f0689db2270d4e6ebe4b3823a39eb36eb7
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:3b2f92612cf6a35edaade46270a961653eb53152a1217fa74be685ac3cfa8b71
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:3b2f92612cf6a35edaade46270a961653eb53152a1217fa74be685ac3cfa8b71
      lastState: {}
      name: kube-state-metrics
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:35:02Z"
    hostIP: 10.0.166.35
    phase: Running
    podIP: 10.131.2.13
    podIPs:
    - ip: 10.131.2.13
    qosClass: Burstable
    startTime: "2022-05-24T18:34:57Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: node-exporter
      openshift.io/scc: node-exporter
    creationTimestamp: "2022-05-24T18:13:01Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 68d496cfbd
      pod-template-generation: "1"
    name: node-exporter-bv4n2
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: e8272b26-830f-410c-8fb6-22e0b2292a4d
    resourceVersion: "69691"
    uid: 847c4846-499a-4a85-9c43-c89aaa138d3a
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-164-190.ec2.internal
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run/k3s/containerd/.+|var/lib/docker/.+|var/lib/kubelet/pods/.+)($|/)
      - --collector.netclass.ignored-devices=^(veth.*|[a-f0-9]{15})$
      - --collector.netdev.device-exclude=^(veth.*|[a-f0-9]{15})$
      - --collector.cpu.info
      - --collector.textfile.directory=/var/node_exporter/textfile
      - --no-collector.cpufreq
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        requests:
          cpu: 8m
          memory: 32Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /host/sys
        mountPropagation: HostToContainer
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bf7rq
        readOnly: true
      workingDir: /var/node_exporter/textfile
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --upstream=http://127.0.0.1:9100/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --config-file=/etc/kube-rbac-policy/config.yaml
      - --tls-min-version=VersionTLS12
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /etc/tls/client
        name: metrics-client-ca
      - mountPath: /etc/kube-rbac-policy
        name: node-exporter-kube-rbac-proxy-config
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bf7rq
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    initContainers:
    - command:
      - /bin/sh
      - -c
      - '[[ ! -d /node_exporter/collectors/init ]] || find /node_exporter/collectors/init
        -perm /111 -type f -exec {} \;'
      env:
      - name: TMPDIR
        value: /tmp
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: init-textfile
      resources:
        requests:
          cpu: 1m
          memory: 1Mi
      securityContext:
        privileged: true
        runAsUser: 0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
      - mountPath: /var/log/wtmp
        name: node-exporter-wtmp
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bf7rq
        readOnly: true
      workingDir: /var/node_exporter/textfile
    nodeName: ip-10-0-164-190.ec2.internal
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - emptyDir: {}
      name: node-exporter-textfile
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - hostPath:
        path: /var/log/wtmp
        type: File
      name: node-exporter-wtmp
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - name: node-exporter-kube-rbac-proxy-config
      secret:
        defaultMode: 420
        secretName: node-exporter-kube-rbac-proxy-config
    - name: kube-api-access-bf7rq
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:13:03Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:03Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:03Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:13:01Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://62d14ef43a09b1f3f5977bdae04d8201ed6b976586360f6b4f1e67e38db036e8
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:02Z"
    - containerID: cri-o://5d07b137950383beae96c5e541dd63de2efdd1ad1333a4588d087b1495398c7d
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: node-exporter
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:02Z"
    hostIP: 10.0.164.190
    initContainerStatuses:
    - containerID: cri-o://fbe6e9d405a486475dbc3138001691088eb5f22f449ca8b026af46aaab7afb2b
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: init-textfile
      ready: true
      restartCount: 1
      state:
        terminated:
          containerID: cri-o://fbe6e9d405a486475dbc3138001691088eb5f22f449ca8b026af46aaab7afb2b
          exitCode: 0
          finishedAt: "2022-05-24T18:40:01Z"
          reason: Completed
          startedAt: "2022-05-24T18:40:01Z"
    phase: Running
    podIP: 10.0.164.190
    podIPs:
    - ip: 10.0.164.190
    qosClass: Burstable
    startTime: "2022-05-24T18:13:01Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: node-exporter
      openshift.io/scc: node-exporter
    creationTimestamp: "2022-05-24T18:08:56Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 68d496cfbd
      pod-template-generation: "1"
    name: node-exporter-cg6mn
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: e8272b26-830f-410c-8fb6-22e0b2292a4d
    resourceVersion: "52862"
    uid: d3761468-1de0-435e-841f-7978c5529793
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-169-205.ec2.internal
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run/k3s/containerd/.+|var/lib/docker/.+|var/lib/kubelet/pods/.+)($|/)
      - --collector.netclass.ignored-devices=^(veth.*|[a-f0-9]{15})$
      - --collector.netdev.device-exclude=^(veth.*|[a-f0-9]{15})$
      - --collector.cpu.info
      - --collector.textfile.directory=/var/node_exporter/textfile
      - --no-collector.cpufreq
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        requests:
          cpu: 8m
          memory: 32Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /host/sys
        mountPropagation: HostToContainer
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-wsptp
        readOnly: true
      workingDir: /var/node_exporter/textfile
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --upstream=http://127.0.0.1:9100/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --config-file=/etc/kube-rbac-policy/config.yaml
      - --tls-min-version=VersionTLS12
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /etc/tls/client
        name: metrics-client-ca
      - mountPath: /etc/kube-rbac-policy
        name: node-exporter-kube-rbac-proxy-config
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-wsptp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    initContainers:
    - command:
      - /bin/sh
      - -c
      - '[[ ! -d /node_exporter/collectors/init ]] || find /node_exporter/collectors/init
        -perm /111 -type f -exec {} \;'
      env:
      - name: TMPDIR
        value: /tmp
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: init-textfile
      resources:
        requests:
          cpu: 1m
          memory: 1Mi
      securityContext:
        privileged: true
        runAsUser: 0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
      - mountPath: /var/log/wtmp
        name: node-exporter-wtmp
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-wsptp
        readOnly: true
      workingDir: /var/node_exporter/textfile
    nodeName: ip-10-0-169-205.ec2.internal
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - emptyDir: {}
      name: node-exporter-textfile
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - hostPath:
        path: /var/log/wtmp
        type: File
      name: node-exporter-wtmp
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - name: node-exporter-kube-rbac-proxy-config
      secret:
        defaultMode: 420
        secretName: node-exporter-kube-rbac-proxy-config
    - name: kube-api-access-wsptp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:08:59Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:31:25Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:31:25Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:08:56Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://51f8be98a15a3cc017bd9223714d3e1fa444920e13f079a67487669683fa06b9
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:31:25Z"
    - containerID: cri-o://057eb5a4b897ae2e919a6282fcb982a31be5219d67459458639732ad2b136597
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: node-exporter
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:31:24Z"
    hostIP: 10.0.169.205
    initContainerStatuses:
    - containerID: cri-o://932c2232b10ecca544ef20254b8db84ca4932b227f339817e0fb0a1d03a0ab40
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: init-textfile
      ready: true
      restartCount: 1
      state:
        terminated:
          containerID: cri-o://932c2232b10ecca544ef20254b8db84ca4932b227f339817e0fb0a1d03a0ab40
          exitCode: 0
          finishedAt: "2022-05-24T18:31:21Z"
          reason: Completed
          startedAt: "2022-05-24T18:31:21Z"
    phase: Running
    podIP: 10.0.169.205
    podIPs:
    - ip: 10.0.169.205
    qosClass: Burstable
    startTime: "2022-05-24T18:08:56Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: node-exporter
      openshift.io/scc: node-exporter
    creationTimestamp: "2022-05-24T18:08:56Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 68d496cfbd
      pod-template-generation: "1"
    name: node-exporter-h57gk
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: e8272b26-830f-410c-8fb6-22e0b2292a4d
    resourceVersion: "61537"
    uid: 522b6910-c8e5-4f44-ad4e-27c3755ed625
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-138-197.ec2.internal
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run/k3s/containerd/.+|var/lib/docker/.+|var/lib/kubelet/pods/.+)($|/)
      - --collector.netclass.ignored-devices=^(veth.*|[a-f0-9]{15})$
      - --collector.netdev.device-exclude=^(veth.*|[a-f0-9]{15})$
      - --collector.cpu.info
      - --collector.textfile.directory=/var/node_exporter/textfile
      - --no-collector.cpufreq
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        requests:
          cpu: 8m
          memory: 32Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /host/sys
        mountPropagation: HostToContainer
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xgswf
        readOnly: true
      workingDir: /var/node_exporter/textfile
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --upstream=http://127.0.0.1:9100/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --config-file=/etc/kube-rbac-policy/config.yaml
      - --tls-min-version=VersionTLS12
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /etc/tls/client
        name: metrics-client-ca
      - mountPath: /etc/kube-rbac-policy
        name: node-exporter-kube-rbac-proxy-config
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xgswf
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    initContainers:
    - command:
      - /bin/sh
      - -c
      - '[[ ! -d /node_exporter/collectors/init ]] || find /node_exporter/collectors/init
        -perm /111 -type f -exec {} \;'
      env:
      - name: TMPDIR
        value: /tmp
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: init-textfile
      resources:
        requests:
          cpu: 1m
          memory: 1Mi
      securityContext:
        privileged: true
        runAsUser: 0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
      - mountPath: /var/log/wtmp
        name: node-exporter-wtmp
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xgswf
        readOnly: true
      workingDir: /var/node_exporter/textfile
    nodeName: ip-10-0-138-197.ec2.internal
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - emptyDir: {}
      name: node-exporter-textfile
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - hostPath:
        path: /var/log/wtmp
        type: File
      name: node-exporter-wtmp
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - name: node-exporter-kube-rbac-proxy-config
      secret:
        defaultMode: 420
        secretName: node-exporter-kube-rbac-proxy-config
    - name: kube-api-access-xgswf
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:08:58Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:35:59Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:35:59Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:08:56Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://eccf0eb53cd61d6035a3b649eaa36da76d76ed5422bab425bac92415b245e4c7
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:35:58Z"
    - containerID: cri-o://8cc1f4f5d79387491e6d6edd1bec934f1b520831ed1bc7fd7a89656d776afd0b
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: node-exporter
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:35:57Z"
    hostIP: 10.0.138.197
    initContainerStatuses:
    - containerID: cri-o://7a331fcfb236088dae5d7214b1c75d74c23db999b83e79ac121a359f76f23b54
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: init-textfile
      ready: true
      restartCount: 1
      state:
        terminated:
          containerID: cri-o://7a331fcfb236088dae5d7214b1c75d74c23db999b83e79ac121a359f76f23b54
          exitCode: 0
          finishedAt: "2022-05-24T18:35:56Z"
          reason: Completed
          startedAt: "2022-05-24T18:35:55Z"
    phase: Running
    podIP: 10.0.138.197
    podIPs:
    - ip: 10.0.138.197
    qosClass: Burstable
    startTime: "2022-05-24T18:08:56Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: node-exporter
      openshift.io/scc: node-exporter
    creationTimestamp: "2022-05-24T18:27:57Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 68d496cfbd
      pod-template-generation: "1"
    name: node-exporter-hm9fq
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: e8272b26-830f-410c-8fb6-22e0b2292a4d
    resourceVersion: "56279"
    uid: 99bcbabb-315f-4d30-bfa9-ba26ab599e98
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-166-35.ec2.internal
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run/k3s/containerd/.+|var/lib/docker/.+|var/lib/kubelet/pods/.+)($|/)
      - --collector.netclass.ignored-devices=^(veth.*|[a-f0-9]{15})$
      - --collector.netdev.device-exclude=^(veth.*|[a-f0-9]{15})$
      - --collector.cpu.info
      - --collector.textfile.directory=/var/node_exporter/textfile
      - --no-collector.cpufreq
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        requests:
          cpu: 8m
          memory: 32Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /host/sys
        mountPropagation: HostToContainer
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xk97d
        readOnly: true
      workingDir: /var/node_exporter/textfile
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --upstream=http://127.0.0.1:9100/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --config-file=/etc/kube-rbac-policy/config.yaml
      - --tls-min-version=VersionTLS12
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /etc/tls/client
        name: metrics-client-ca
      - mountPath: /etc/kube-rbac-policy
        name: node-exporter-kube-rbac-proxy-config
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xk97d
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: node-exporter-dockercfg-gkz4h
    initContainers:
    - command:
      - /bin/sh
      - -c
      - '[[ ! -d /node_exporter/collectors/init ]] || find /node_exporter/collectors/init
        -perm /111 -type f -exec {} \;'
      env:
      - name: TMPDIR
        value: /tmp
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: init-textfile
      resources:
        requests:
          cpu: 1m
          memory: 1Mi
      securityContext:
        privileged: true
        runAsUser: 0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
      - mountPath: /var/log/wtmp
        name: node-exporter-wtmp
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xk97d
        readOnly: true
      workingDir: /var/node_exporter/textfile
    nodeName: ip-10-0-166-35.ec2.internal
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - emptyDir: {}
      name: node-exporter-textfile
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - hostPath:
        path: /var/log/wtmp
        type: File
      name: node-exporter-wtmp
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - name: node-exporter-kube-rbac-proxy-config
      secret:
        defaultMode: 420
        secretName: node-exporter-kube-rbac-proxy-config
    - name: kube-api-access-xk97d
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:32:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:32:25Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:32:25Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:27:57Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://ecbc9b37f0c567914343cb060fa66f25524818dd18c1c4a7f1a6d8d35b6a6bdc
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:32:24Z"
    - containerID: cri-o://fe7d88fea45d73df25f038a4ae753f4ed87523f7a2c4c695493728d45bbdb1ac
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: node-exporter
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:32:24Z"
    hostIP: 10.0.166.35
    initContainerStatuses:
    - containerID: cri-o://4138b5ffc361913115b0080dab5107ab8426b667d737db2e96d74404f88707ac
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: init-textfile
      ready: true
      restartCount: 1
      state:
        terminated:
          containerID: cri-o://4138b5ffc361913115b0080dab5107ab8426b667d737db2e96d74404f88707ac
          exitCode: 0
          finishedAt: "2022-05-24T18:32:23Z"
          reason: Completed
          startedAt: "2022-05-24T18:32:22Z"
    phase: Running
    podIP: 10.0.166.35
    podIPs:
    - ip: 10.0.166.35
    qosClass: Burstable
    startTime: "2022-05-24T18:27:58Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: node-exporter
      openshift.io/scc: node-exporter
    creationTimestamp: "2022-05-24T18:12:06Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 68d496cfbd
      pod-template-generation: "1"
    name: node-exporter-l8wzk
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: e8272b26-830f-410c-8fb6-22e0b2292a4d
    resourceVersion: "37412"
    uid: 3a80f979-4bf0-4f0b-abde-401cad850ba1
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-128-34.ec2.internal
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run/k3s/containerd/.+|var/lib/docker/.+|var/lib/kubelet/pods/.+)($|/)
      - --collector.netclass.ignored-devices=^(veth.*|[a-f0-9]{15})$
      - --collector.netdev.device-exclude=^(veth.*|[a-f0-9]{15})$
      - --collector.cpu.info
      - --collector.textfile.directory=/var/node_exporter/textfile
      - --no-collector.cpufreq
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        requests:
          cpu: 8m
          memory: 32Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /host/sys
        mountPropagation: HostToContainer
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xd4w4
        readOnly: true
      workingDir: /var/node_exporter/textfile
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --upstream=http://127.0.0.1:9100/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --config-file=/etc/kube-rbac-policy/config.yaml
      - --tls-min-version=VersionTLS12
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /etc/tls/client
        name: metrics-client-ca
      - mountPath: /etc/kube-rbac-policy
        name: node-exporter-kube-rbac-proxy-config
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xd4w4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    initContainers:
    - command:
      - /bin/sh
      - -c
      - '[[ ! -d /node_exporter/collectors/init ]] || find /node_exporter/collectors/init
        -perm /111 -type f -exec {} \;'
      env:
      - name: TMPDIR
        value: /tmp
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: init-textfile
      resources:
        requests:
          cpu: 1m
          memory: 1Mi
      securityContext:
        privileged: true
        runAsUser: 0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
      - mountPath: /var/log/wtmp
        name: node-exporter-wtmp
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xd4w4
        readOnly: true
      workingDir: /var/node_exporter/textfile
    nodeName: ip-10-0-128-34.ec2.internal
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - emptyDir: {}
      name: node-exporter-textfile
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - hostPath:
        path: /var/log/wtmp
        type: File
      name: node-exporter-wtmp
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - name: node-exporter-kube-rbac-proxy-config
      secret:
        defaultMode: 420
        secretName: node-exporter-kube-rbac-proxy-config
    - name: kube-api-access-xd4w4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:12:08Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:27:31Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:27:31Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:12:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://a98fb11d7a0c4a1535538f836a3096acdebd05e2e896c68bee3be93fd20b0633
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:27:31Z"
    - containerID: cri-o://7c030b09ebfee2b89f80fff79b6951a1fdb0a1abd470c53b595a442f31d1ea95
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: node-exporter
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:27:31Z"
    hostIP: 10.0.128.34
    initContainerStatuses:
    - containerID: cri-o://70df0de61e0ac0af12763e21c0a124009c8baf20562f6260221aa90b5f0067be
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: init-textfile
      ready: true
      restartCount: 1
      state:
        terminated:
          containerID: cri-o://70df0de61e0ac0af12763e21c0a124009c8baf20562f6260221aa90b5f0067be
          exitCode: 0
          finishedAt: "2022-05-24T18:27:30Z"
          reason: Completed
          startedAt: "2022-05-24T18:27:30Z"
    phase: Running
    podIP: 10.0.128.34
    podIPs:
    - ip: 10.0.128.34
    qosClass: Burstable
    startTime: "2022-05-24T18:12:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: node-exporter
      openshift.io/scc: node-exporter
    creationTimestamp: "2022-05-24T18:28:12Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 68d496cfbd
      pod-template-generation: "1"
    name: node-exporter-mfj78
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: e8272b26-830f-410c-8fb6-22e0b2292a4d
    resourceVersion: "74551"
    uid: 7d324770-2658-450f-b4ab-bd19e5259c05
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-148-123.ec2.internal
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run/k3s/containerd/.+|var/lib/docker/.+|var/lib/kubelet/pods/.+)($|/)
      - --collector.netclass.ignored-devices=^(veth.*|[a-f0-9]{15})$
      - --collector.netdev.device-exclude=^(veth.*|[a-f0-9]{15})$
      - --collector.cpu.info
      - --collector.textfile.directory=/var/node_exporter/textfile
      - --no-collector.cpufreq
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        requests:
          cpu: 8m
          memory: 32Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /host/sys
        mountPropagation: HostToContainer
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-gcqk4
        readOnly: true
      workingDir: /var/node_exporter/textfile
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --upstream=http://127.0.0.1:9100/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --config-file=/etc/kube-rbac-policy/config.yaml
      - --tls-min-version=VersionTLS12
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /etc/tls/client
        name: metrics-client-ca
      - mountPath: /etc/kube-rbac-policy
        name: node-exporter-kube-rbac-proxy-config
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-gcqk4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: node-exporter-dockercfg-gkz4h
    initContainers:
    - command:
      - /bin/sh
      - -c
      - '[[ ! -d /node_exporter/collectors/init ]] || find /node_exporter/collectors/init
        -perm /111 -type f -exec {} \;'
      env:
      - name: TMPDIR
        value: /tmp
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: init-textfile
      resources:
        requests:
          cpu: 1m
          memory: 1Mi
      securityContext:
        privileged: true
        runAsUser: 0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
      - mountPath: /var/log/wtmp
        name: node-exporter-wtmp
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-gcqk4
        readOnly: true
      workingDir: /var/node_exporter/textfile
    nodeName: ip-10-0-148-123.ec2.internal
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - emptyDir: {}
      name: node-exporter-textfile
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - hostPath:
        path: /var/log/wtmp
        type: File
      name: node-exporter-wtmp
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - name: node-exporter-kube-rbac-proxy-config
      secret:
        defaultMode: 420
        secretName: node-exporter-kube-rbac-proxy-config
    - name: kube-api-access-gcqk4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:28:24Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:06Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:06Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:28:12Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://55fe8e281fa3a4969844aceb73df14a658800ecf6503855b2b1e1047a480a6db
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:42:06Z"
    - containerID: cri-o://1631863c85c47c7b65bc6a2d8d3a18edd79c303bd69487e1dc8ec69df281999b
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: node-exporter
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:42:06Z"
    hostIP: 10.0.148.123
    initContainerStatuses:
    - containerID: cri-o://c3f7f7f9242ab76c36342c7b51e03309d87c971afba39642b01d7583472b01ca
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: init-textfile
      ready: true
      restartCount: 1
      state:
        terminated:
          containerID: cri-o://c3f7f7f9242ab76c36342c7b51e03309d87c971afba39642b01d7583472b01ca
          exitCode: 0
          finishedAt: "2022-05-24T18:42:05Z"
          reason: Completed
          startedAt: "2022-05-24T18:42:05Z"
    phase: Running
    podIP: 10.0.148.123
    podIPs:
    - ip: 10.0.148.123
    qosClass: Burstable
    startTime: "2022-05-24T18:28:12Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: node-exporter
      openshift.io/scc: node-exporter
    creationTimestamp: "2022-05-24T18:08:56Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 68d496cfbd
      pod-template-generation: "1"
    name: node-exporter-nb9bq
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: e8272b26-830f-410c-8fb6-22e0b2292a4d
    resourceVersion: "71179"
    uid: ccf8003a-e466-4d2f-8620-363e82c904c2
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-149-121.ec2.internal
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run/k3s/containerd/.+|var/lib/docker/.+|var/lib/kubelet/pods/.+)($|/)
      - --collector.netclass.ignored-devices=^(veth.*|[a-f0-9]{15})$
      - --collector.netdev.device-exclude=^(veth.*|[a-f0-9]{15})$
      - --collector.cpu.info
      - --collector.textfile.directory=/var/node_exporter/textfile
      - --no-collector.cpufreq
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        requests:
          cpu: 8m
          memory: 32Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /host/sys
        mountPropagation: HostToContainer
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lvbxs
        readOnly: true
      workingDir: /var/node_exporter/textfile
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --upstream=http://127.0.0.1:9100/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --config-file=/etc/kube-rbac-policy/config.yaml
      - --tls-min-version=VersionTLS12
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /etc/tls/client
        name: metrics-client-ca
      - mountPath: /etc/kube-rbac-policy
        name: node-exporter-kube-rbac-proxy-config
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lvbxs
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    initContainers:
    - command:
      - /bin/sh
      - -c
      - '[[ ! -d /node_exporter/collectors/init ]] || find /node_exporter/collectors/init
        -perm /111 -type f -exec {} \;'
      env:
      - name: TMPDIR
        value: /tmp
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: init-textfile
      resources:
        requests:
          cpu: 1m
          memory: 1Mi
      securityContext:
        privileged: true
        runAsUser: 0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
      - mountPath: /var/log/wtmp
        name: node-exporter-wtmp
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lvbxs
        readOnly: true
      workingDir: /var/node_exporter/textfile
    nodeName: ip-10-0-149-121.ec2.internal
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - emptyDir: {}
      name: node-exporter-textfile
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - hostPath:
        path: /var/log/wtmp
        type: File
      name: node-exporter-wtmp
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - name: node-exporter-kube-rbac-proxy-config
      secret:
        defaultMode: 420
        secretName: node-exporter-kube-rbac-proxy-config
    - name: kube-api-access-lvbxs
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:29Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:34Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:34Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:08:56Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://a275da34d28df7981ffa49fd52a12d498f85c585bb744b14d753cf9ed6a85361
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:34Z"
    - containerID: cri-o://4c929c142df847b73bb0c62ae822df21c18c60669a136e10f96041b5c2401bfc
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: node-exporter
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:32Z"
    hostIP: 10.0.149.121
    initContainerStatuses:
    - containerID: cri-o://2aae2e8dc4a9b5e2c72dde5b31e3a5d33d814f905f3ecf7fdc5ad5a479337e75
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: init-textfile
      ready: true
      restartCount: 1
      state:
        terminated:
          containerID: cri-o://2aae2e8dc4a9b5e2c72dde5b31e3a5d33d814f905f3ecf7fdc5ad5a479337e75
          exitCode: 0
          finishedAt: "2022-05-24T18:40:28Z"
          reason: Completed
          startedAt: "2022-05-24T18:40:27Z"
    phase: Running
    podIP: 10.0.149.121
    podIPs:
    - ip: 10.0.149.121
    qosClass: Burstable
    startTime: "2022-05-24T18:08:56Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: node-exporter
      openshift.io/scc: node-exporter
    creationTimestamp: "2022-05-24T18:27:39Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 68d496cfbd
      pod-template-generation: "1"
    name: node-exporter-r24x9
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: e8272b26-830f-410c-8fb6-22e0b2292a4d
    resourceVersion: "67116"
    uid: 55f89fd1-07e1-44aa-9bd0-46fcfe22d5ff
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-140-240.ec2.internal
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run/k3s/containerd/.+|var/lib/docker/.+|var/lib/kubelet/pods/.+)($|/)
      - --collector.netclass.ignored-devices=^(veth.*|[a-f0-9]{15})$
      - --collector.netdev.device-exclude=^(veth.*|[a-f0-9]{15})$
      - --collector.cpu.info
      - --collector.textfile.directory=/var/node_exporter/textfile
      - --no-collector.cpufreq
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        requests:
          cpu: 8m
          memory: 32Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /host/sys
        mountPropagation: HostToContainer
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-w7xjw
        readOnly: true
      workingDir: /var/node_exporter/textfile
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --upstream=http://127.0.0.1:9100/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --config-file=/etc/kube-rbac-policy/config.yaml
      - --tls-min-version=VersionTLS12
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /etc/tls/client
        name: metrics-client-ca
      - mountPath: /etc/kube-rbac-policy
        name: node-exporter-kube-rbac-proxy-config
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-w7xjw
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: node-exporter-dockercfg-gkz4h
    initContainers:
    - command:
      - /bin/sh
      - -c
      - '[[ ! -d /node_exporter/collectors/init ]] || find /node_exporter/collectors/init
        -perm /111 -type f -exec {} \;'
      env:
      - name: TMPDIR
        value: /tmp
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: init-textfile
      resources:
        requests:
          cpu: 1m
          memory: 1Mi
      securityContext:
        privileged: true
        runAsUser: 0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
      - mountPath: /var/log/wtmp
        name: node-exporter-wtmp
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-w7xjw
        readOnly: true
      workingDir: /var/node_exporter/textfile
    nodeName: ip-10-0-140-240.ec2.internal
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - emptyDir: {}
      name: node-exporter-textfile
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - hostPath:
        path: /var/log/wtmp
        type: File
      name: node-exporter-wtmp
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - name: node-exporter-kube-rbac-proxy-config
      secret:
        defaultMode: 420
        secretName: node-exporter-kube-rbac-proxy-config
    - name: kube-api-access-w7xjw
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:27:46Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:38:32Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:38:32Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:27:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://fa57fd707148e29e9959eddd28158a171b7e00ee5a7035510ea21f45735df9ca
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:38:32Z"
    - containerID: cri-o://83360529b2f1a367a3dc5c75d04d7d4457c2102656007adfde073e536b788d61
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: node-exporter
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:38:32Z"
    hostIP: 10.0.140.240
    initContainerStatuses:
    - containerID: cri-o://b7a2c691f4bf7a8d81dda6c2390a2222d7812e3cfa8fe0f3f883e15114770d3b
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: init-textfile
      ready: true
      restartCount: 1
      state:
        terminated:
          containerID: cri-o://b7a2c691f4bf7a8d81dda6c2390a2222d7812e3cfa8fe0f3f883e15114770d3b
          exitCode: 0
          finishedAt: "2022-05-24T18:38:31Z"
          reason: Completed
          startedAt: "2022-05-24T18:38:31Z"
    phase: Running
    podIP: 10.0.140.240
    podIPs:
    - ip: 10.0.140.240
    qosClass: Burstable
    startTime: "2022-05-24T18:27:39Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: node-exporter
      openshift.io/scc: node-exporter
    creationTimestamp: "2022-05-24T18:15:39Z"
    generateName: node-exporter-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 1.3.1
      controller-revision-hash: 68d496cfbd
      pod-template-generation: "1"
    name: node-exporter-w5bdx
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-exporter
      uid: e8272b26-830f-410c-8fb6-22e0b2292a4d
    resourceVersion: "78548"
    uid: 445beb6f-6f68-4fb0-bc6b-c679820903e9
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-145-179.ec2.internal
    containers:
    - args:
      - --web.listen-address=127.0.0.1:9100
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --no-collector.wifi
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run/k3s/containerd/.+|var/lib/docker/.+|var/lib/kubelet/pods/.+)($|/)
      - --collector.netclass.ignored-devices=^(veth.*|[a-f0-9]{15})$
      - --collector.netdev.device-exclude=^(veth.*|[a-f0-9]{15})$
      - --collector.cpu.info
      - --collector.textfile.directory=/var/node_exporter/textfile
      - --no-collector.cpufreq
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: node-exporter
      resources:
        requests:
          cpu: 8m
          memory: 32Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /host/sys
        mountPropagation: HostToContainer
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-42p69
        readOnly: true
      workingDir: /var/node_exporter/textfile
    - args:
      - --logtostderr
      - --secure-listen-address=[$(IP)]:9100
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --upstream=http://127.0.0.1:9100/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --config-file=/etc/kube-rbac-policy/config.yaml
      - --tls-min-version=VersionTLS12
      env:
      - name: IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        runAsGroup: 65532
        runAsNonRoot: true
        runAsUser: 65532
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: node-exporter-tls
      - mountPath: /etc/tls/client
        name: metrics-client-ca
      - mountPath: /etc/kube-rbac-policy
        name: node-exporter-kube-rbac-proxy-config
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-42p69
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: node-exporter-dockercfg-gkz4h
    initContainers:
    - command:
      - /bin/sh
      - -c
      - '[[ ! -d /node_exporter/collectors/init ]] || find /node_exporter/collectors/init
        -perm /111 -type f -exec {} \;'
      env:
      - name: TMPDIR
        value: /tmp
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imagePullPolicy: IfNotPresent
      name: init-textfile
      resources:
        requests:
          cpu: 1m
          memory: 1Mi
      securityContext:
        privileged: true
        runAsUser: 0
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/node_exporter/textfile
        name: node-exporter-textfile
      - mountPath: /var/log/wtmp
        name: node-exporter-wtmp
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-42p69
        readOnly: true
      workingDir: /var/node_exporter/textfile
    nodeName: ip-10-0-145-179.ec2.internal
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-exporter
    serviceAccountName: node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
    - emptyDir: {}
      name: node-exporter-textfile
    - name: node-exporter-tls
      secret:
        defaultMode: 420
        secretName: node-exporter-tls
    - hostPath:
        path: /var/log/wtmp
        type: File
      name: node-exporter-wtmp
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - name: node-exporter-kube-rbac-proxy-config
      secret:
        defaultMode: 420
        secretName: node-exporter-kube-rbac-proxy-config
    - name: kube-api-access-42p69
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:16:02Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:44:16Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:44:16Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:15:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://e3a587429a5aba38c7945562f7160bb441932cf5227e4ce434689530ebce7bbd
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:44:15Z"
    - containerID: cri-o://355ba45685b25d016e3ddfe7de71d7061ce9a3231e4c6dfe08fce21eb8e10139
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: node-exporter
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:44:15Z"
    hostIP: 10.0.145.179
    initContainerStatuses:
    - containerID: cri-o://6585a7aa3d694e97f9fc2228f12a3510114a7c8947ff050474c17ec2829837f1
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:957a2dc20cc01a3f2fbaa836927aa6833699322657915846e9a84c191fa25bb7
      lastState: {}
      name: init-textfile
      ready: true
      restartCount: 1
      state:
        terminated:
          containerID: cri-o://6585a7aa3d694e97f9fc2228f12a3510114a7c8947ff050474c17ec2829837f1
          exitCode: 0
          finishedAt: "2022-05-24T18:44:14Z"
          reason: Completed
          startedAt: "2022-05-24T18:44:14Z"
    phase: Running
    podIP: 10.0.145.179
    podIPs:
    - ip: 10.0.145.179
    qosClass: Burstable
    startTime: "2022-05-24T18:15:42Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.14"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.14"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:34:57Z"
    generateName: openshift-state-metrics-559868fdcc-
    labels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: openshift-state-metrics
      app.kubernetes.io/part-of: openshift-monitoring
      pod-template-hash: 559868fdcc
    name: openshift-state-metrics-559868fdcc-kh5bc
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: openshift-state-metrics-559868fdcc
      uid: 7b87b2cf-d20c-4c0b-b57a-ed02045f6c85
    resourceVersion: "60524"
    uid: 740cb88f-2bdd-4319-907b-533d6dc24fc3
  spec:
    containers:
    - args:
      - --logtostderr
      - --secure-listen-address=:8443
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --upstream=http://127.0.0.1:8081/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --config-file=/etc/kube-rbac-policy/config.yaml
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-main
      ports:
      - containerPort: 8443
        name: https-main
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 20Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: openshift-state-metrics-tls
      - mountPath: /etc/kube-rbac-policy
        name: openshift-state-metrics-kube-rbac-proxy-config
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4twt6
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=:9443
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --upstream=http://127.0.0.1:8082/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --config-file=/etc/kube-rbac-policy/config.yaml
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-self
      ports:
      - containerPort: 9443
        name: https-self
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 20Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: openshift-state-metrics-tls
      - mountPath: /etc/kube-rbac-policy
        name: openshift-state-metrics-kube-rbac-proxy-config
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4twt6
        readOnly: true
    - args:
      - --host=127.0.0.1
      - --port=8081
      - --telemetry-host=127.0.0.1
      - --telemetry-port=8082
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:e52032d4e2993366d3b3e6fc81837b2cd79f1a8be5638b9cf409a9aa7547495a
      imagePullPolicy: IfNotPresent
      name: openshift-state-metrics
      resources:
        requests:
          cpu: 1m
          memory: 32Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4twt6
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: openshift-state-metrics-dockercfg-xlgnn
    nodeName: ip-10-0-166-35.ec2.internal
    nodeSelector:
      node-role.kubernetes.io/infra: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: openshift-state-metrics
    serviceAccountName: openshift-state-metrics
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - name: openshift-state-metrics-tls
      secret:
        defaultMode: 420
        secretName: openshift-state-metrics-tls
    - name: openshift-state-metrics-kube-rbac-proxy-config
      secret:
        defaultMode: 420
        secretName: openshift-state-metrics-kube-rbac-proxy-config
    - name: kube-api-access-4twt6
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:34:57Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:35:03Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:35:03Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:34:57Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://1b61a1cb943c145bae7d9da625fd37ca87c83596241b42840dfdfa6eb31e1607
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy-main
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:34:59Z"
    - containerID: cri-o://81eeaf06b9826d3841e4cec4f1d21444bfcee047e85239a641901d125695e77d
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy-self
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:35:00Z"
    - containerID: cri-o://525b0c95ef2f0dc7941e9755a674c16791da95e0a2507d01b9a01309fe408127
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:e52032d4e2993366d3b3e6fc81837b2cd79f1a8be5638b9cf409a9aa7547495a
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:e52032d4e2993366d3b3e6fc81837b2cd79f1a8be5638b9cf409a9aa7547495a
      lastState: {}
      name: openshift-state-metrics
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:35:03Z"
    hostIP: 10.0.166.35
    phase: Running
    podIP: 10.131.2.14
    podIPs:
    - ip: 10.131.2.14
    qosClass: Burstable
    startTime: "2022-05-24T18:34:57Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.0.47"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.0.47"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:42:31Z"
    generateName: osd-cluster-ready-
    labels:
      controller-uid: 4730ac38-ba20-437f-88c4-85794e648bd2
      job-name: osd-cluster-ready
      managed.openshift.io/version: v0.1.81-33838ec
    name: osd-cluster-ready-726v4
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: osd-cluster-ready
      uid: 4730ac38-ba20-437f-88c4-85794e648bd2
    resourceVersion: "318815"
    uid: 5de9fbd6-76c4-4583-9686-0328d6beb4ea
  spec:
    containers:
    - command:
      - /root/main
      image: quay.io/app-sre/osd-cluster-ready@sha256:c5064d58b8697f9793f7cd7b169393f3c078d40650613660520a51fab75e8716
      imagePullPolicy: IfNotPresent
      name: osd-cluster-ready
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-cqkwf
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: osd-cluster-ready-dockercfg-85rhv
    nodeName: ip-10-0-128-34.ec2.internal
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: osd-cluster-ready
    serviceAccountName: osd-cluster-ready
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-cqkwf
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:31Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T23:44:40Z"
      message: 'containers with unready status: [osd-cluster-ready]'
      reason: ContainersNotReady
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T23:44:40Z"
      message: 'containers with unready status: [osd-cluster-ready]'
      reason: ContainersNotReady
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:31Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://8a0e314b3663c7e1770c81c93ca739945a0778d29c7489ae1dff055bdcbb344e
      image: quay.io/app-sre/osd-cluster-ready@sha256:c5064d58b8697f9793f7cd7b169393f3c078d40650613660520a51fab75e8716
      imageID: quay.io/app-sre/osd-cluster-ready@sha256:c5064d58b8697f9793f7cd7b169393f3c078d40650613660520a51fab75e8716
      lastState:
        terminated:
          containerID: cri-o://8a0e314b3663c7e1770c81c93ca739945a0778d29c7489ae1dff055bdcbb344e
          exitCode: 1
          finishedAt: "2022-05-24T23:44:39Z"
          reason: Error
          startedAt: "2022-05-24T23:44:38Z"
      name: osd-cluster-ready
      ready: false
      restartCount: 64
      started: false
      state:
        waiting:
          message: back-off 5m0s restarting failed container=osd-cluster-ready pod=osd-cluster-ready-726v4_openshift-monitoring(5de9fbd6-76c4-4583-9686-0328d6beb4ea)
          reason: CrashLoopBackOff
    hostIP: 10.0.128.34
    phase: Running
    podIP: 10.131.0.47
    podIPs:
    - ip: 10.131.0.47
    qosClass: BestEffort
    startTime: "2022-05-24T18:42:31Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.4.89"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.4.89"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T23:15:00Z"
    generateName: osd-rebalance-infra-nodes-27557235-
    labels:
      controller-uid: 965a462d-c1b4-4987-974a-4cd94c2b88ab
      job-name: osd-rebalance-infra-nodes-27557235
    name: osd-rebalance-infra-nodes-27557235-z6v2w
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: osd-rebalance-infra-nodes-27557235
      uid: 965a462d-c1b4-4987-974a-4cd94c2b88ab
    resourceVersion: "295476"
    uid: aafb146e-294a-4c36-97be-4deba3d30cbf
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/infra
              operator: Exists
          weight: 1
    containers:
    - command:
      - /bin/sh
      - -c
      - /etc/config/entrypoint
      image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest
      imagePullPolicy: Always
      name: osd-rebalance-infra-nodes
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: osd-rebalance-infra-nodes
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lq6x2
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: osd-rebalance-infra-nodes-dockercfg-swnfb
    nodeName: ip-10-0-148-123.ec2.internal
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Never
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: osd-rebalance-infra-nodes
    serviceAccountName: osd-rebalance-infra-nodes
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 493
        name: osd-rebalance-infra-nodes
      name: osd-rebalance-infra-nodes
    - name: kube-api-access-lq6x2
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T23:15:00Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T23:15:04Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T23:15:04Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T23:15:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://156ef64484e242a2dc9d16d14545e58e96468c64c3f49abb3219f55e72787ad7
      image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest
      imageID: image-registry.openshift-image-registry.svc:5000/openshift/cli@sha256:5cb8eed4d9713a7a3da331026e21773c76d52feef9a591921807ccf217f66757
      lastState: {}
      name: osd-rebalance-infra-nodes
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: cri-o://156ef64484e242a2dc9d16d14545e58e96468c64c3f49abb3219f55e72787ad7
          exitCode: 0
          finishedAt: "2022-05-24T23:15:03Z"
          reason: Completed
          startedAt: "2022-05-24T23:15:02Z"
    hostIP: 10.0.148.123
    phase: Succeeded
    podIP: 10.128.4.89
    podIPs:
    - ip: 10.128.4.89
    qosClass: BestEffort
    startTime: "2022-05-24T23:15:00Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.4.92"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.4.92"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T23:30:00Z"
    generateName: osd-rebalance-infra-nodes-27557250-
    labels:
      controller-uid: 17e12fb5-15ed-4fbd-882c-31eaaa4ab4c2
      job-name: osd-rebalance-infra-nodes-27557250
    name: osd-rebalance-infra-nodes-27557250-557l4
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: osd-rebalance-infra-nodes-27557250
      uid: 17e12fb5-15ed-4fbd-882c-31eaaa4ab4c2
    resourceVersion: "307245"
    uid: 42de9d24-1055-424e-b38a-1c0ddefb1a5f
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/infra
              operator: Exists
          weight: 1
    containers:
    - command:
      - /bin/sh
      - -c
      - /etc/config/entrypoint
      image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest
      imagePullPolicy: Always
      name: osd-rebalance-infra-nodes
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: osd-rebalance-infra-nodes
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lbg5h
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: osd-rebalance-infra-nodes-dockercfg-swnfb
    nodeName: ip-10-0-148-123.ec2.internal
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Never
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: osd-rebalance-infra-nodes
    serviceAccountName: osd-rebalance-infra-nodes
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 493
        name: osd-rebalance-infra-nodes
      name: osd-rebalance-infra-nodes
    - name: kube-api-access-lbg5h
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T23:30:00Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T23:30:04Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T23:30:04Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T23:30:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://87d64b1f8b54be4fea295e619932cdecd1642b4097ce4d8aa85d475e4f61a496
      image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest
      imageID: image-registry.openshift-image-registry.svc:5000/openshift/cli@sha256:5cb8eed4d9713a7a3da331026e21773c76d52feef9a591921807ccf217f66757
      lastState: {}
      name: osd-rebalance-infra-nodes
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: cri-o://87d64b1f8b54be4fea295e619932cdecd1642b4097ce4d8aa85d475e4f61a496
          exitCode: 0
          finishedAt: "2022-05-24T23:30:03Z"
          reason: Completed
          startedAt: "2022-05-24T23:30:02Z"
    hostIP: 10.0.148.123
    phase: Succeeded
    podIP: 10.128.4.92
    podIPs:
    - ip: 10.128.4.92
    qosClass: BestEffort
    startTime: "2022-05-24T23:30:00Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.4.96"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.4.96"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T23:45:00Z"
    generateName: osd-rebalance-infra-nodes-27557265-
    labels:
      controller-uid: f9ba7886-508f-41c8-b683-872a8ad003f3
      job-name: osd-rebalance-infra-nodes-27557265
    name: osd-rebalance-infra-nodes-27557265-q26vk
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: osd-rebalance-infra-nodes-27557265
      uid: f9ba7886-508f-41c8-b683-872a8ad003f3
    resourceVersion: "319052"
    uid: cf42eab9-a670-48a8-9b5d-ae7a04159a62
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/infra
              operator: Exists
          weight: 1
    containers:
    - command:
      - /bin/sh
      - -c
      - /etc/config/entrypoint
      image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest
      imagePullPolicy: Always
      name: osd-rebalance-infra-nodes
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: osd-rebalance-infra-nodes
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-kr5tx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: osd-rebalance-infra-nodes-dockercfg-swnfb
    nodeName: ip-10-0-148-123.ec2.internal
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Never
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: osd-rebalance-infra-nodes
    serviceAccountName: osd-rebalance-infra-nodes
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 493
        name: osd-rebalance-infra-nodes
      name: osd-rebalance-infra-nodes
    - name: kube-api-access-kr5tx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T23:45:00Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T23:45:04Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T23:45:04Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T23:45:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://ce43f0d85dab6f24076d93e79612c43b4c107bd5c5d600ea6a9b9ed3b84532f3
      image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest
      imageID: image-registry.openshift-image-registry.svc:5000/openshift/cli@sha256:5cb8eed4d9713a7a3da331026e21773c76d52feef9a591921807ccf217f66757
      lastState: {}
      name: osd-rebalance-infra-nodes
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: cri-o://ce43f0d85dab6f24076d93e79612c43b4c107bd5c5d600ea6a9b9ed3b84532f3
          exitCode: 0
          finishedAt: "2022-05-24T23:45:03Z"
          reason: Completed
          startedAt: "2022-05-24T23:45:02Z"
    hostIP: 10.0.148.123
    phase: Succeeded
    podIP: 10.128.4.96
    podIPs:
    - ip: 10.128.4.96
    qosClass: BestEffort
    startTime: "2022-05-24T23:45:00Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.12"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.12"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:34:57Z"
    generateName: prometheus-adapter-58f5b7f7c-
    labels:
      app.kubernetes.io/component: metrics-adapter
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: prometheus-adapter
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 0.9.1
      pod-template-hash: 58f5b7f7c
    name: prometheus-adapter-58f5b7f7c-f9k8f
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-adapter-58f5b7f7c
      uid: ce4afd94-9551-4818-b292-7da2676afaf4
    resourceVersion: "60357"
    uid: f92ebdfd-7bfa-4c18-bef1-7df0d4b91a2d
  spec:
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/component: metrics-adapter
              app.kubernetes.io/name: prometheus-adapter
              app.kubernetes.io/part-of: openshift-monitoring
          namespaces:
          - openshift-monitoring
          topologyKey: kubernetes.io/hostname
    containers:
    - args:
      - --prometheus-auth-config=/etc/prometheus-config/prometheus-config.yaml
      - --config=/etc/adapter/config.yaml
      - --logtostderr=true
      - --metrics-relist-interval=1m
      - --prometheus-url=https://thanos-querier.openshift-monitoring.svc:9091
      - --secure-port=6443
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --client-ca-file=/etc/tls/private/client-ca-file
      - --requestheader-client-ca-file=/etc/tls/private/requestheader-client-ca-file
      - --requestheader-allowed-names=kube-apiserver-proxy,system:kube-apiserver-proxy,system:openshift-aggregator
      - --requestheader-extra-headers-prefix=X-Remote-Extra-
      - --requestheader-group-headers=X-Remote-Group
      - --requestheader-username-headers=X-Remote-User
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --audit-policy-file=/etc/audit/metadata-profile.yaml
      - --audit-log-path=/var/log/adapter/audit.log
      - --audit-log-maxsize=100
      - --audit-log-maxbackup=5
      - --audit-log-compress=true
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:750e142e941a9b9e1822c52bc671d01ebcb5bf479b42fab978b76c44b17685b5
      imagePullPolicy: IfNotPresent
      name: prometheus-adapter
      ports:
      - containerPort: 6443
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 40Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /tmp
        name: tmpfs
      - mountPath: /etc/adapter
        name: config
      - mountPath: /etc/prometheus-config
        name: prometheus-adapter-prometheus-config
      - mountPath: /etc/ssl/certs
        name: serving-certs-ca-bundle
      - mountPath: /etc/audit
        name: prometheus-adapter-audit-profiles
        readOnly: true
      - mountPath: /var/log/adapter
        name: audit-log
      - mountPath: /etc/tls/private
        name: tls
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zrbxj
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: prometheus-adapter-dockercfg-cg8pf
    nodeName: ip-10-0-166-35.ec2.internal
    nodeSelector:
      node-role.kubernetes.io/infra: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: prometheus-adapter
    serviceAccountName: prometheus-adapter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - emptyDir: {}
      name: tmpfs
    - configMap:
        defaultMode: 420
        name: adapter-config
      name: config
    - configMap:
        defaultMode: 420
        name: prometheus-adapter-prometheus-config
      name: prometheus-adapter-prometheus-config
    - configMap:
        defaultMode: 420
        items:
        - key: service-ca.crt
          path: service-ca.crt
        name: serving-certs-ca-bundle
      name: serving-certs-ca-bundle
    - emptyDir: {}
      name: audit-log
    - configMap:
        defaultMode: 420
        name: prometheus-adapter-audit-profiles
      name: prometheus-adapter-audit-profiles
    - name: tls
      secret:
        defaultMode: 420
        secretName: prometheus-adapter-cggn4tgrdm7bp
    - name: kube-api-access-zrbxj
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:34:57Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:34:59Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:34:59Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:34:57Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://613a5248a19b300f370f4b9a140fc85cbd56b3c228222a2fdc0e769f9c2eb222
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:750e142e941a9b9e1822c52bc671d01ebcb5bf479b42fab978b76c44b17685b5
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:750e142e941a9b9e1822c52bc671d01ebcb5bf479b42fab978b76c44b17685b5
      lastState: {}
      name: prometheus-adapter
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:34:59Z"
    hostIP: 10.0.166.35
    phase: Running
    podIP: 10.131.2.12
    podIPs:
    - ip: 10.131.2.12
    qosClass: Burstable
    startTime: "2022-05-24T18:34:57Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.130.2.13"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.130.2.13"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:40:15Z"
    generateName: prometheus-adapter-58f5b7f7c-
    labels:
      app.kubernetes.io/component: metrics-adapter
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: prometheus-adapter
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 0.9.1
      pod-template-hash: 58f5b7f7c
    name: prometheus-adapter-58f5b7f7c-lmrdw
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-adapter-58f5b7f7c
      uid: ce4afd94-9551-4818-b292-7da2676afaf4
    resourceVersion: "70592"
    uid: c0e8fe1d-5e7e-4e65-bd2c-3163f8385cc2
  spec:
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/component: metrics-adapter
              app.kubernetes.io/name: prometheus-adapter
              app.kubernetes.io/part-of: openshift-monitoring
          namespaces:
          - openshift-monitoring
          topologyKey: kubernetes.io/hostname
    containers:
    - args:
      - --prometheus-auth-config=/etc/prometheus-config/prometheus-config.yaml
      - --config=/etc/adapter/config.yaml
      - --logtostderr=true
      - --metrics-relist-interval=1m
      - --prometheus-url=https://thanos-querier.openshift-monitoring.svc:9091
      - --secure-port=6443
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --client-ca-file=/etc/tls/private/client-ca-file
      - --requestheader-client-ca-file=/etc/tls/private/requestheader-client-ca-file
      - --requestheader-allowed-names=kube-apiserver-proxy,system:kube-apiserver-proxy,system:openshift-aggregator
      - --requestheader-extra-headers-prefix=X-Remote-Extra-
      - --requestheader-group-headers=X-Remote-Group
      - --requestheader-username-headers=X-Remote-User
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --audit-policy-file=/etc/audit/metadata-profile.yaml
      - --audit-log-path=/var/log/adapter/audit.log
      - --audit-log-maxsize=100
      - --audit-log-maxbackup=5
      - --audit-log-compress=true
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:750e142e941a9b9e1822c52bc671d01ebcb5bf479b42fab978b76c44b17685b5
      imagePullPolicy: IfNotPresent
      name: prometheus-adapter
      ports:
      - containerPort: 6443
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 40Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /tmp
        name: tmpfs
      - mountPath: /etc/adapter
        name: config
      - mountPath: /etc/prometheus-config
        name: prometheus-adapter-prometheus-config
      - mountPath: /etc/ssl/certs
        name: serving-certs-ca-bundle
      - mountPath: /etc/audit
        name: prometheus-adapter-audit-profiles
        readOnly: true
      - mountPath: /var/log/adapter
        name: audit-log
      - mountPath: /etc/tls/private
        name: tls
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jpcjm
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: prometheus-adapter-dockercfg-cg8pf
    nodeName: ip-10-0-140-240.ec2.internal
    nodeSelector:
      node-role.kubernetes.io/infra: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: prometheus-adapter
    serviceAccountName: prometheus-adapter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - emptyDir: {}
      name: tmpfs
    - configMap:
        defaultMode: 420
        name: adapter-config
      name: config
    - configMap:
        defaultMode: 420
        name: prometheus-adapter-prometheus-config
      name: prometheus-adapter-prometheus-config
    - configMap:
        defaultMode: 420
        items:
        - key: service-ca.crt
          path: service-ca.crt
        name: serving-certs-ca-bundle
      name: serving-certs-ca-bundle
    - emptyDir: {}
      name: audit-log
    - configMap:
        defaultMode: 420
        name: prometheus-adapter-audit-profiles
      name: prometheus-adapter-audit-profiles
    - name: tls
      secret:
        defaultMode: 420
        secretName: prometheus-adapter-cggn4tgrdm7bp
    - name: kube-api-access-jpcjm
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:15Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:24Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:24Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:15Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://3e6d4a24e510b99582315509c7f61cfcbef613fe90851f8f875a0842dcafa415
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:750e142e941a9b9e1822c52bc671d01ebcb5bf479b42fab978b76c44b17685b5
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:750e142e941a9b9e1822c52bc671d01ebcb5bf479b42fab978b76c44b17685b5
      lastState: {}
      name: prometheus-adapter
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:24Z"
    hostIP: 10.0.140.240
    phase: Running
    podIP: 10.130.2.13
    podIPs:
    - ip: 10.130.2.13
    qosClass: Burstable
    startTime: "2022-05-24T18:40:15Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.8"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.8"
            ],
            "default": true,
            "dns": {}
        }]
      kubectl.kubernetes.io/default-container: prometheus
      openshift.io/scc: nonroot
    creationTimestamp: "2022-05-24T18:30:32Z"
    generateName: prometheus-k8s-
    labels:
      app.kubernetes.io/component: prometheus
      app.kubernetes.io/instance: k8s
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 2.32.1
      controller-revision-hash: prometheus-k8s-74467b9dd7
      operator.prometheus.io/name: k8s
      operator.prometheus.io/shard: "0"
      prometheus: k8s
      statefulset.kubernetes.io/pod-name: prometheus-k8s-0
    name: prometheus-k8s-0
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: prometheus-k8s
      uid: 2b7a4847-dfd9-4426-8923-3f216037d8d2
    resourceVersion: "57203"
    uid: 12c60ccb-0df7-4bc4-9b53-aca70f1e4f4c
  spec:
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/component: prometheus
              app.kubernetes.io/instance: k8s
              app.kubernetes.io/name: prometheus
              app.kubernetes.io/part-of: openshift-monitoring
          namespaces:
          - openshift-monitoring
          topologyKey: kubernetes.io/hostname
    containers:
    - args:
      - --web.console.templates=/etc/prometheus/consoles
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
      - --storage.tsdb.path=/prometheus
      - --storage.tsdb.retention.time=11d
      - --web.enable-lifecycle
      - --web.external-url=https://prometheus-k8s-openshift-monitoring.apps.odf-service.dif5.p1.openshiftapps.com/
      - --web.route-prefix=/
      - --web.listen-address=127.0.0.1:9090
      - --web.config.file=/etc/prometheus/web_config/web-config.yaml
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:727fe0f3dcdad60f8beee58590b33815345e12d86f9526af81b45de17fb28f59
      imagePullPolicy: IfNotPresent
      name: prometheus
      readinessProbe:
        exec:
          command:
          - sh
          - -c
          - if [ -x "$(command -v curl)" ]; then exec curl http://localhost:9090/-/ready;
            elif [ -x "$(command -v wget)" ]; then exec wget -q -O /dev/null http://localhost:9090/-/ready;
            else exit 1; fi
        failureThreshold: 3
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        requests:
          cpu: 70m
          memory: 1Gi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      startupProbe:
        exec:
          command:
          - sh
          - -c
          - if [ -x "$(command -v curl)" ]; then exec curl http://localhost:9090/-/ready;
            elif [ -x "$(command -v wget)" ]; then exec wget -q -O /dev/null http://localhost:9090/-/ready;
            else exit 1; fi
        failureThreshold: 60
        periodSeconds: 15
        successThreshold: 1
        timeoutSeconds: 3
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/ca-trust/extracted/pem/
        name: prometheus-trusted-ca-bundle
        readOnly: true
      - mountPath: /etc/prometheus/config_out
        name: config-out
        readOnly: true
      - mountPath: /etc/prometheus/certs
        name: tls-assets
        readOnly: true
      - mountPath: /prometheus
        name: prometheus-data
        subPath: prometheus-db
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /etc/prometheus/web_config/web-config.yaml
        name: web-config
        readOnly: true
        subPath: web-config.yaml
      - mountPath: /etc/prometheus/secrets/kube-etcd-client-certs
        name: secret-kube-etcd-client-certs
        readOnly: true
      - mountPath: /etc/prometheus/secrets/prometheus-k8s-tls
        name: secret-prometheus-k8s-tls
        readOnly: true
      - mountPath: /etc/prometheus/secrets/prometheus-k8s-proxy
        name: secret-prometheus-k8s-proxy
        readOnly: true
      - mountPath: /etc/prometheus/secrets/prometheus-k8s-thanos-sidecar-tls
        name: secret-prometheus-k8s-thanos-sidecar-tls
        readOnly: true
      - mountPath: /etc/prometheus/secrets/kube-rbac-proxy
        name: secret-kube-rbac-proxy
        readOnly: true
      - mountPath: /etc/prometheus/secrets/metrics-client-certs
        name: secret-metrics-client-certs
        readOnly: true
      - mountPath: /etc/prometheus/configmaps/serving-certs-ca-bundle
        name: configmap-serving-certs-ca-bundle
        readOnly: true
      - mountPath: /etc/prometheus/configmaps/kubelet-serving-ca-bundle
        name: configmap-kubelet-serving-ca-bundle
        readOnly: true
      - mountPath: /etc/prometheus/configmaps/metrics-client-ca
        name: configmap-metrics-client-ca
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pwj7w
        readOnly: true
    - args:
      - --listen-address=localhost:8080
      - --reload-url=http://localhost:9090/-/reload
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-k8s-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      imagePullPolicy: IfNotPresent
      name: config-reloader
      resources:
        requests:
          cpu: 1m
          memory: 10Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pwj7w
        readOnly: true
    - args:
      - sidecar
      - --prometheus.url=http://localhost:9090/
      - --tsdb.path=/prometheus
      - --http-address=127.0.0.1:10902
      - --grpc-server-tls-cert=/etc/tls/grpc/server.crt
      - --grpc-server-tls-key=/etc/tls/grpc/server.key
      - --grpc-server-tls-client-ca=/etc/tls/grpc/ca.crt
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8a5a316dec56c12072bd11525534dc01cad163fd44766be4e1fb3406796e662d
      imagePullPolicy: IfNotPresent
      name: thanos-sidecar
      ports:
      - containerPort: 10902
        name: http
        protocol: TCP
      - containerPort: 10901
        name: grpc
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 25Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/grpc
        name: secret-grpc-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pwj7w
        readOnly: true
    - args:
      - -provider=openshift
      - -https-address=:9091
      - -http-address=
      - -email-domain=*
      - -upstream=http://localhost:9090
      - -openshift-service-account=prometheus-k8s
      - '-openshift-sar={"resource": "namespaces", "verb": "get"}'
      - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}}'
      - -tls-cert=/etc/tls/private/tls.crt
      - -tls-key=/etc/tls/private/tls.key
      - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
      - -cookie-secret-file=/etc/proxy/secrets/session_secret
      - -openshift-ca=/etc/pki/tls/cert.pem
      - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      - -htpasswd-file=/etc/proxy/htpasswd/auth
      env:
      - name: HTTP_PROXY
      - name: HTTPS_PROXY
      - name: NO_PROXY
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      imagePullPolicy: IfNotPresent
      name: prometheus-proxy
      ports:
      - containerPort: 9091
        name: web
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 20Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-prometheus-k8s-tls
      - mountPath: /etc/proxy/secrets
        name: secret-prometheus-k8s-proxy
      - mountPath: /etc/proxy/htpasswd
        name: secret-prometheus-k8s-htpasswd
      - mountPath: /etc/pki/ca-trust/extracted/pem/
        name: prometheus-trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pwj7w
        readOnly: true
    - args:
      - --secure-listen-address=0.0.0.0:9092
      - --upstream=http://127.0.0.1:9090
      - --allow-paths=/metrics
      - --config-file=/etc/kube-rbac-proxy/config.yaml
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --logtostderr=true
      - --v=10
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9092
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-prometheus-k8s-tls
      - mountPath: /etc/tls/client
        name: configmap-metrics-client-ca
        readOnly: true
      - mountPath: /etc/kube-rbac-proxy
        name: secret-kube-rbac-proxy
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pwj7w
        readOnly: true
    - args:
      - --secure-listen-address=[$(POD_IP)]:10902
      - --upstream=http://127.0.0.1:10902
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --config-file=/etc/kube-rbac-proxy/config.yaml
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --allow-paths=/metrics
      - --logtostderr=true
      - --tls-min-version=VersionTLS12
      - --client-ca-file=/etc/tls/client/client-ca.crt
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-thanos
      ports:
      - containerPort: 10902
        name: thanos-proxy
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 10Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-prometheus-k8s-thanos-sidecar-tls
      - mountPath: /etc/kube-rbac-proxy
        name: secret-kube-rbac-proxy
      - mountPath: /etc/tls/client
        name: metrics-client-ca
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pwj7w
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: prometheus-k8s-0
    imagePullSecrets:
    - name: prometheus-k8s-dockercfg-kk472
    initContainers:
    - args:
      - --watch-interval=0
      - --listen-address=:8080
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-k8s-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      imagePullPolicy: IfNotPresent
      name: init-config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pwj7w
        readOnly: true
    nodeName: ip-10-0-166-35.ec2.internal
    nodeSelector:
      node-role.kubernetes.io/infra: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: prometheus-k8s
    serviceAccountName: prometheus-k8s
    subdomain: prometheus-operated
    terminationGracePeriodSeconds: 600
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - name: prometheus-data
      persistentVolumeClaim:
        claimName: prometheus-data-prometheus-k8s-0
    - name: config
      secret:
        defaultMode: 420
        secretName: prometheus-k8s
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: prometheus-k8s-tls-assets-0
    - emptyDir: {}
      name: config-out
    - configMap:
        defaultMode: 420
        name: prometheus-k8s-rulefiles-0
      name: prometheus-k8s-rulefiles-0
    - name: web-config
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-web-config
    - name: secret-kube-etcd-client-certs
      secret:
        defaultMode: 420
        secretName: kube-etcd-client-certs
    - name: secret-prometheus-k8s-tls
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-tls
    - name: secret-prometheus-k8s-proxy
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-proxy
    - name: secret-prometheus-k8s-thanos-sidecar-tls
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-thanos-sidecar-tls
    - name: secret-kube-rbac-proxy
      secret:
        defaultMode: 420
        secretName: kube-rbac-proxy
    - name: secret-metrics-client-certs
      secret:
        defaultMode: 420
        secretName: metrics-client-certs
    - configMap:
        defaultMode: 420
        name: serving-certs-ca-bundle
      name: configmap-serving-certs-ca-bundle
    - configMap:
        defaultMode: 420
        name: kubelet-serving-ca-bundle
      name: configmap-kubelet-serving-ca-bundle
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: configmap-metrics-client-ca
    - name: secret-prometheus-k8s-htpasswd
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-htpasswd
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - name: secret-grpc-tls
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-grpc-tls-bbs2h7k8eiaor
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: prometheus-trusted-ca-bundle-2rsonso43rc5p
        optional: true
      name: prometheus-trusted-ca-bundle
    - name: kube-api-access-pwj7w
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:32:39Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:32:49Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:32:49Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:32:29Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://51be3d3f804bb3ba5c61ee1854c91949fb67589f84a0fa3c861f540ff917d107
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      lastState: {}
      name: config-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:32:41Z"
    - containerID: cri-o://e8f90c7dea4ce1fb2dc9c6105ecc7f5c758b3be947671e3b2c0abede4cc34820
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:32:43Z"
    - containerID: cri-o://993b6311fb0e9b8a6a1123672fcf6494573b1b1f9d4b7c74079595509215c2ab
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy-thanos
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:32:44Z"
    - containerID: cri-o://81ed79b0c87285fbc3ad99aa23b70d61e87010d9874ec2fdc221e64581c01f26
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:727fe0f3dcdad60f8beee58590b33815345e12d86f9526af81b45de17fb28f59
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:727fe0f3dcdad60f8beee58590b33815345e12d86f9526af81b45de17fb28f59
      lastState: {}
      name: prometheus
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:32:41Z"
    - containerID: cri-o://690f6d768854f0399955ab2cba127c329c38d208a0934515a37233f4890e95b1
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      lastState: {}
      name: prometheus-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:32:43Z"
    - containerID: cri-o://dce4a45ef679492f1436e324f7d7022f84bdfa12a3a01b3869e9489302713ccf
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8a5a316dec56c12072bd11525534dc01cad163fd44766be4e1fb3406796e662d
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8a5a316dec56c12072bd11525534dc01cad163fd44766be4e1fb3406796e662d
      lastState: {}
      name: thanos-sidecar
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:32:43Z"
    hostIP: 10.0.166.35
    initContainerStatuses:
    - containerID: cri-o://79e8d8f526e07bfda829cb222cbc73afad2bad9cb458e414b32606ffcb9d4954
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      lastState: {}
      name: init-config-reloader
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: cri-o://79e8d8f526e07bfda829cb222cbc73afad2bad9cb458e414b32606ffcb9d4954
          exitCode: 0
          finishedAt: "2022-05-24T18:32:38Z"
          reason: Completed
          startedAt: "2022-05-24T18:32:38Z"
    phase: Running
    podIP: 10.131.2.8
    podIPs:
    - ip: 10.131.2.8
    qosClass: Burstable
    startTime: "2022-05-24T18:32:29Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.130.2.11"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.130.2.11"
            ],
            "default": true,
            "dns": {}
        }]
      kubectl.kubernetes.io/default-container: prometheus
      openshift.io/scc: nonroot
    creationTimestamp: "2022-05-24T18:36:58Z"
    generateName: prometheus-k8s-
    labels:
      app.kubernetes.io/component: prometheus
      app.kubernetes.io/instance: k8s
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 2.32.1
      controller-revision-hash: prometheus-k8s-74467b9dd7
      operator.prometheus.io/name: k8s
      operator.prometheus.io/shard: "0"
      prometheus: k8s
      statefulset.kubernetes.io/pod-name: prometheus-k8s-1
    name: prometheus-k8s-1
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: prometheus-k8s
      uid: 2b7a4847-dfd9-4426-8923-3f216037d8d2
    resourceVersion: "71612"
    uid: a3afc701-19d8-4029-8203-ee3d48dfaca8
  spec:
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/component: prometheus
              app.kubernetes.io/instance: k8s
              app.kubernetes.io/name: prometheus
              app.kubernetes.io/part-of: openshift-monitoring
          namespaces:
          - openshift-monitoring
          topologyKey: kubernetes.io/hostname
    containers:
    - args:
      - --web.console.templates=/etc/prometheus/consoles
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
      - --storage.tsdb.path=/prometheus
      - --storage.tsdb.retention.time=11d
      - --web.enable-lifecycle
      - --web.external-url=https://prometheus-k8s-openshift-monitoring.apps.odf-service.dif5.p1.openshiftapps.com/
      - --web.route-prefix=/
      - --web.listen-address=127.0.0.1:9090
      - --web.config.file=/etc/prometheus/web_config/web-config.yaml
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:727fe0f3dcdad60f8beee58590b33815345e12d86f9526af81b45de17fb28f59
      imagePullPolicy: IfNotPresent
      name: prometheus
      readinessProbe:
        exec:
          command:
          - sh
          - -c
          - if [ -x "$(command -v curl)" ]; then exec curl http://localhost:9090/-/ready;
            elif [ -x "$(command -v wget)" ]; then exec wget -q -O /dev/null http://localhost:9090/-/ready;
            else exit 1; fi
        failureThreshold: 3
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        requests:
          cpu: 70m
          memory: 1Gi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      startupProbe:
        exec:
          command:
          - sh
          - -c
          - if [ -x "$(command -v curl)" ]; then exec curl http://localhost:9090/-/ready;
            elif [ -x "$(command -v wget)" ]; then exec wget -q -O /dev/null http://localhost:9090/-/ready;
            else exit 1; fi
        failureThreshold: 60
        periodSeconds: 15
        successThreshold: 1
        timeoutSeconds: 3
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/ca-trust/extracted/pem/
        name: prometheus-trusted-ca-bundle
        readOnly: true
      - mountPath: /etc/prometheus/config_out
        name: config-out
        readOnly: true
      - mountPath: /etc/prometheus/certs
        name: tls-assets
        readOnly: true
      - mountPath: /prometheus
        name: prometheus-data
        subPath: prometheus-db
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /etc/prometheus/web_config/web-config.yaml
        name: web-config
        readOnly: true
        subPath: web-config.yaml
      - mountPath: /etc/prometheus/secrets/kube-etcd-client-certs
        name: secret-kube-etcd-client-certs
        readOnly: true
      - mountPath: /etc/prometheus/secrets/prometheus-k8s-tls
        name: secret-prometheus-k8s-tls
        readOnly: true
      - mountPath: /etc/prometheus/secrets/prometheus-k8s-proxy
        name: secret-prometheus-k8s-proxy
        readOnly: true
      - mountPath: /etc/prometheus/secrets/prometheus-k8s-thanos-sidecar-tls
        name: secret-prometheus-k8s-thanos-sidecar-tls
        readOnly: true
      - mountPath: /etc/prometheus/secrets/kube-rbac-proxy
        name: secret-kube-rbac-proxy
        readOnly: true
      - mountPath: /etc/prometheus/secrets/metrics-client-certs
        name: secret-metrics-client-certs
        readOnly: true
      - mountPath: /etc/prometheus/configmaps/serving-certs-ca-bundle
        name: configmap-serving-certs-ca-bundle
        readOnly: true
      - mountPath: /etc/prometheus/configmaps/kubelet-serving-ca-bundle
        name: configmap-kubelet-serving-ca-bundle
        readOnly: true
      - mountPath: /etc/prometheus/configmaps/metrics-client-ca
        name: configmap-metrics-client-ca
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bfwpx
        readOnly: true
    - args:
      - --listen-address=localhost:8080
      - --reload-url=http://localhost:9090/-/reload
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-k8s-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      imagePullPolicy: IfNotPresent
      name: config-reloader
      resources:
        requests:
          cpu: 1m
          memory: 10Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bfwpx
        readOnly: true
    - args:
      - sidecar
      - --prometheus.url=http://localhost:9090/
      - --tsdb.path=/prometheus
      - --http-address=127.0.0.1:10902
      - --grpc-server-tls-cert=/etc/tls/grpc/server.crt
      - --grpc-server-tls-key=/etc/tls/grpc/server.key
      - --grpc-server-tls-client-ca=/etc/tls/grpc/ca.crt
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8a5a316dec56c12072bd11525534dc01cad163fd44766be4e1fb3406796e662d
      imagePullPolicy: IfNotPresent
      name: thanos-sidecar
      ports:
      - containerPort: 10902
        name: http
        protocol: TCP
      - containerPort: 10901
        name: grpc
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 25Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/grpc
        name: secret-grpc-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bfwpx
        readOnly: true
    - args:
      - -provider=openshift
      - -https-address=:9091
      - -http-address=
      - -email-domain=*
      - -upstream=http://localhost:9090
      - -openshift-service-account=prometheus-k8s
      - '-openshift-sar={"resource": "namespaces", "verb": "get"}'
      - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}}'
      - -tls-cert=/etc/tls/private/tls.crt
      - -tls-key=/etc/tls/private/tls.key
      - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
      - -cookie-secret-file=/etc/proxy/secrets/session_secret
      - -openshift-ca=/etc/pki/tls/cert.pem
      - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      - -htpasswd-file=/etc/proxy/htpasswd/auth
      env:
      - name: HTTP_PROXY
      - name: HTTPS_PROXY
      - name: NO_PROXY
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      imagePullPolicy: IfNotPresent
      name: prometheus-proxy
      ports:
      - containerPort: 9091
        name: web
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 20Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-prometheus-k8s-tls
      - mountPath: /etc/proxy/secrets
        name: secret-prometheus-k8s-proxy
      - mountPath: /etc/proxy/htpasswd
        name: secret-prometheus-k8s-htpasswd
      - mountPath: /etc/pki/ca-trust/extracted/pem/
        name: prometheus-trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bfwpx
        readOnly: true
    - args:
      - --secure-listen-address=0.0.0.0:9092
      - --upstream=http://127.0.0.1:9090
      - --allow-paths=/metrics
      - --config-file=/etc/kube-rbac-proxy/config.yaml
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --logtostderr=true
      - --v=10
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9092
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-prometheus-k8s-tls
      - mountPath: /etc/tls/client
        name: configmap-metrics-client-ca
        readOnly: true
      - mountPath: /etc/kube-rbac-proxy
        name: secret-kube-rbac-proxy
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bfwpx
        readOnly: true
    - args:
      - --secure-listen-address=[$(POD_IP)]:10902
      - --upstream=http://127.0.0.1:10902
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --config-file=/etc/kube-rbac-proxy/config.yaml
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --allow-paths=/metrics
      - --logtostderr=true
      - --tls-min-version=VersionTLS12
      - --client-ca-file=/etc/tls/client/client-ca.crt
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-thanos
      ports:
      - containerPort: 10902
        name: thanos-proxy
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 10Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-prometheus-k8s-thanos-sidecar-tls
      - mountPath: /etc/kube-rbac-proxy
        name: secret-kube-rbac-proxy
      - mountPath: /etc/tls/client
        name: metrics-client-ca
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bfwpx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: prometheus-k8s-1
    imagePullSecrets:
    - name: prometheus-k8s-dockercfg-kk472
    initContainers:
    - args:
      - --watch-interval=0
      - --listen-address=:8080
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-k8s-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      imagePullPolicy: IfNotPresent
      name: init-config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources:
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-k8s-rulefiles-0
        name: prometheus-k8s-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bfwpx
        readOnly: true
    nodeName: ip-10-0-140-240.ec2.internal
    nodeSelector:
      node-role.kubernetes.io/infra: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: prometheus-k8s
    serviceAccountName: prometheus-k8s
    subdomain: prometheus-operated
    terminationGracePeriodSeconds: 600
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - name: prometheus-data
      persistentVolumeClaim:
        claimName: prometheus-data-prometheus-k8s-1
    - name: config
      secret:
        defaultMode: 420
        secretName: prometheus-k8s
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: prometheus-k8s-tls-assets-0
    - emptyDir: {}
      name: config-out
    - configMap:
        defaultMode: 420
        name: prometheus-k8s-rulefiles-0
      name: prometheus-k8s-rulefiles-0
    - name: web-config
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-web-config
    - name: secret-kube-etcd-client-certs
      secret:
        defaultMode: 420
        secretName: kube-etcd-client-certs
    - name: secret-prometheus-k8s-tls
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-tls
    - name: secret-prometheus-k8s-proxy
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-proxy
    - name: secret-prometheus-k8s-thanos-sidecar-tls
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-thanos-sidecar-tls
    - name: secret-kube-rbac-proxy
      secret:
        defaultMode: 420
        secretName: kube-rbac-proxy
    - name: secret-metrics-client-certs
      secret:
        defaultMode: 420
        secretName: metrics-client-certs
    - configMap:
        defaultMode: 420
        name: serving-certs-ca-bundle
      name: configmap-serving-certs-ca-bundle
    - configMap:
        defaultMode: 420
        name: kubelet-serving-ca-bundle
      name: configmap-kubelet-serving-ca-bundle
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: configmap-metrics-client-ca
    - name: secret-prometheus-k8s-htpasswd
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-htpasswd
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - name: secret-grpc-tls
      secret:
        defaultMode: 420
        secretName: prometheus-k8s-grpc-tls-bbs2h7k8eiaor
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: prometheus-trusted-ca-bundle-2rsonso43rc5p
        optional: true
      name: prometheus-trusted-ca-bundle
    - name: kube-api-access-bfwpx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:40Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:40Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:09Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://d45a0cbd938e68a64cf53b532722de895e121658103c94d7c171f725b8710a65
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      lastState: {}
      name: config-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:24Z"
    - containerID: cri-o://4603aa2fd88ae90a475d088dc98efd2e14f5a5b057d2893d340e65e0291e66e9
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:25Z"
    - containerID: cri-o://7f65f18f1d4a80b8999da70929fc8b8a986f5219ecb166c8f459fc6e33e27ec2
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy-thanos
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:25Z"
    - containerID: cri-o://c7384617633251a11ae624f5d75596e94830a61436a77ad4611737541a55a526
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:727fe0f3dcdad60f8beee58590b33815345e12d86f9526af81b45de17fb28f59
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:727fe0f3dcdad60f8beee58590b33815345e12d86f9526af81b45de17fb28f59
      lastState: {}
      name: prometheus
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:24Z"
    - containerID: cri-o://4221c6f36ad46d45efc2c0d1792591e949d09260c4cc59af94dd97c837c0e5c9
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      lastState: {}
      name: prometheus-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:25Z"
    - containerID: cri-o://b02cc8790e79159c8869bf80c4d221f06867556f2331584b7ac22915c630520e
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8a5a316dec56c12072bd11525534dc01cad163fd44766be4e1fb3406796e662d
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8a5a316dec56c12072bd11525534dc01cad163fd44766be4e1fb3406796e662d
      lastState: {}
      name: thanos-sidecar
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:24Z"
    hostIP: 10.0.140.240
    initContainerStatuses:
    - containerID: cri-o://50895fa9f4ca575b2cd9dc61e0d3280730006dd9ff1190a6b81e73c6cce12fee
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      lastState: {}
      name: init-config-reloader
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: cri-o://50895fa9f4ca575b2cd9dc61e0d3280730006dd9ff1190a6b81e73c6cce12fee
          exitCode: 0
          finishedAt: "2022-05-24T18:40:23Z"
          reason: Completed
          startedAt: "2022-05-24T18:40:23Z"
    phase: Running
    podIP: 10.130.2.11
    podIPs:
    - ip: 10.130.2.11
    qosClass: Burstable
    startTime: "2022-05-24T18:40:09Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.9"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.9"
            ],
            "default": true,
            "dns": {}
        }]
      kubectl.kubernetes.io/default-container: prometheus-operator
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:34:57Z"
    generateName: prometheus-operator-599c4fbfc-
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: prometheus-operator
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 0.53.1
      pod-template-hash: 599c4fbfc
    name: prometheus-operator-599c4fbfc-ghjrc
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-operator-599c4fbfc
      uid: e7d3ed62-b9fb-413d-b3de-edd4e8f41bca
    resourceVersion: "60519"
    uid: de11ba12-e429-4d21-b593-18d19a85386b
  spec:
    containers:
    - args:
      - --kubelet-service=kube-system/kubelet
      - --prometheus-config-reloader=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      - --prometheus-instance-namespaces=openshift-monitoring
      - --thanos-ruler-instance-namespaces=openshift-monitoring
      - --alertmanager-instance-namespaces=openshift-monitoring
      - --config-reloader-cpu-limit=0
      - --config-reloader-memory-limit=0
      - --web.enable-tls=true
      - --web.tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --web.tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:6332f67ddb8aaba08639689ea91e5a0075e07dbfaea704a8a2b4cb7645281136
      imagePullPolicy: IfNotPresent
      name: prometheus-operator
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      resources:
        requests:
          cpu: 5m
          memory: 150Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: prometheus-operator-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xxhpl
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=:8443
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --upstream=https://prometheus-operator.openshift-monitoring.svc:8080/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --upstream-ca-file=/etc/configmaps/operator-cert-ca-bundle/service-ca.crt
      - --config-file=/etc/kube-rbac-policy/config.yaml
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 8443
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: prometheus-operator-tls
      - mountPath: /etc/configmaps/operator-cert-ca-bundle
        name: operator-certs-ca-bundle
      - mountPath: /etc/tls/client
        name: metrics-client-ca
      - mountPath: /etc/kube-rbac-policy
        name: prometheus-operator-kube-rbac-proxy-config
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xxhpl
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: prometheus-operator-dockercfg-9hwn2
    nodeName: ip-10-0-166-35.ec2.internal
    nodeSelector:
      node-role.kubernetes.io/infra: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: prometheus-operator
    serviceAccountName: prometheus-operator
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - name: prometheus-operator-tls
      secret:
        defaultMode: 420
        secretName: prometheus-operator-tls
    - configMap:
        defaultMode: 420
        items:
        - key: service-ca.crt
          path: service-ca.crt
        name: operator-certs-ca-bundle
      name: operator-certs-ca-bundle
    - name: prometheus-operator-kube-rbac-proxy-config
      secret:
        defaultMode: 420
        secretName: prometheus-operator-kube-rbac-proxy-config
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - name: kube-api-access-xxhpl
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:34:57Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:35:03Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:35:03Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:34:57Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://10697900f781c1d92ea237f408563e92bdafde025f725129e94e680e688bd634
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:35:02Z"
    - containerID: cri-o://f81862ba35a0e62cba182e792cf2e9696ce4ca3b1e07d99943fb63a802499e65
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:6332f67ddb8aaba08639689ea91e5a0075e07dbfaea704a8a2b4cb7645281136
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:6332f67ddb8aaba08639689ea91e5a0075e07dbfaea704a8a2b4cb7645281136
      lastState: {}
      name: prometheus-operator
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:35:02Z"
    hostIP: 10.0.166.35
    phase: Running
    podIP: 10.131.2.9
    podIPs:
    - ip: 10.131.2.9
    qosClass: Burstable
    startTime: "2022-05-24T18:34:57Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.2.5"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.2.5"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:25:30Z"
    generateName: sre-dns-latency-exporter-
    labels:
      controller-revision-hash: 77c4fb4fdb
      name: sre-dns-latency-exporter
      pod-template-generation: "1"
    name: sre-dns-latency-exporter-6vr76
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sre-dns-latency-exporter
      uid: 70b79ab5-c7d4-4dbf-96af-4a340318b62a
    resourceVersion: "69839"
    uid: f9838e5d-a590-40a2-b634-a2f5ed3452a5
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-164-190.ec2.internal
    containers:
    - command:
      - /bin/sh
      - /monitor/start.sh
      env:
      - name: PYTHONPATH
        value: /openshift-python/packages:/support/packages
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 2
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 420
        periodSeconds: 360
        successThreshold: 1
        timeoutSeconds: 240
      name: main
      ports:
      - containerPort: 8080
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 240
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /monitor
        name: monitor-volume
        readOnly: true
      - mountPath: /etc/pki/ca-trust/extracted/pem
        name: trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-frlh8
        readOnly: true
      workingDir: /monitor
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-10-0-164-190.ec2.internal
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: sre-dns-latency-exporter
    serviceAccountName: sre-dns-latency-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sre-dns-latency-exporter-code
      name: monitor-volume
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: sre-dns-latency-exporter-trusted-ca-bundle
      name: trusted-ca-bundle
    - name: kube-api-access-frlh8
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:25:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:08Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:08Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:25:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://5d278ab9cec367fc16e5db901d30258c4ee19c469cbe4f772006511caec131ad
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imageID: quay.io/app-sre/managed-prometheus-exporter-base@sha256:81123c64980b958e5d1c74d054fb82b8e752395dde6e5d92ec158d2b58dfedf6
      lastState: {}
      name: main
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:05Z"
    hostIP: 10.0.164.190
    phase: Running
    podIP: 10.128.2.5
    podIPs:
    - ip: 10.128.2.5
    qosClass: BestEffort
    startTime: "2022-05-24T18:25:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.130.2.2"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.130.2.2"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:27:39Z"
    generateName: sre-dns-latency-exporter-
    labels:
      controller-revision-hash: 77c4fb4fdb
      name: sre-dns-latency-exporter
      pod-template-generation: "1"
    name: sre-dns-latency-exporter-74pbq
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sre-dns-latency-exporter
      uid: 70b79ab5-c7d4-4dbf-96af-4a340318b62a
    resourceVersion: "67587"
    uid: ed60a542-4708-4e38-8650-c64d44641e7e
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-140-240.ec2.internal
    containers:
    - command:
      - /bin/sh
      - /monitor/start.sh
      env:
      - name: PYTHONPATH
        value: /openshift-python/packages:/support/packages
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 2
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 420
        periodSeconds: 360
        successThreshold: 1
        timeoutSeconds: 240
      name: main
      ports:
      - containerPort: 8080
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 240
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /monitor
        name: monitor-volume
        readOnly: true
      - mountPath: /etc/pki/ca-trust/extracted/pem
        name: trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lfrjm
        readOnly: true
      workingDir: /monitor
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: sre-dns-latency-exporter-dockercfg-49t44
    nodeName: ip-10-0-140-240.ec2.internal
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: sre-dns-latency-exporter
    serviceAccountName: sre-dns-latency-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sre-dns-latency-exporter-code
      name: monitor-volume
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: sre-dns-latency-exporter-trusted-ca-bundle
      name: trusted-ca-bundle
    - name: kube-api-access-lfrjm
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:27:39Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:38:46Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:38:46Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:27:39Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://2469ecbea4c7e0693bb80f1e695944a7c5c8d4db15d1681a137706bcc41109be
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imageID: quay.io/app-sre/managed-prometheus-exporter-base@sha256:81123c64980b958e5d1c74d054fb82b8e752395dde6e5d92ec158d2b58dfedf6
      lastState: {}
      name: main
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:38:35Z"
    hostIP: 10.0.140.240
    phase: Running
    podIP: 10.130.2.2
    podIPs:
    - ip: 10.130.2.2
    qosClass: BestEffort
    startTime: "2022-05-24T18:27:39Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.0.28"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.0.28"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:25:30Z"
    generateName: sre-dns-latency-exporter-
    labels:
      controller-revision-hash: 77c4fb4fdb
      name: sre-dns-latency-exporter
      pod-template-generation: "1"
    name: sre-dns-latency-exporter-9gnb8
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sre-dns-latency-exporter
      uid: 70b79ab5-c7d4-4dbf-96af-4a340318b62a
    resourceVersion: "53442"
    uid: 81b1c052-efc0-49f6-8305-79426a7f2688
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-169-205.ec2.internal
    containers:
    - command:
      - /bin/sh
      - /monitor/start.sh
      env:
      - name: PYTHONPATH
        value: /openshift-python/packages:/support/packages
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 2
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 420
        periodSeconds: 360
        successThreshold: 1
        timeoutSeconds: 240
      name: main
      ports:
      - containerPort: 8080
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 240
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /monitor
        name: monitor-volume
        readOnly: true
      - mountPath: /etc/pki/ca-trust/extracted/pem
        name: trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vmgm9
        readOnly: true
      workingDir: /monitor
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: sre-dns-latency-exporter-dockercfg-49t44
    nodeName: ip-10-0-169-205.ec2.internal
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: sre-dns-latency-exporter
    serviceAccountName: sre-dns-latency-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sre-dns-latency-exporter-code
      name: monitor-volume
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: sre-dns-latency-exporter-trusted-ca-bundle
      name: trusted-ca-bundle
    - name: kube-api-access-vmgm9
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:25:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:31:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:31:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:25:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://e6798e0a5849b2b8c02c8a4eafb64da2acdd6c441adb5c32efb56feb0ddea93b
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imageID: quay.io/app-sre/managed-prometheus-exporter-base@sha256:81123c64980b958e5d1c74d054fb82b8e752395dde6e5d92ec158d2b58dfedf6
      lastState: {}
      name: main
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:31:39Z"
    hostIP: 10.0.169.205
    phase: Running
    podIP: 10.128.0.28
    podIPs:
    - ip: 10.128.0.28
    qosClass: BestEffort
    startTime: "2022-05-24T18:25:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.130.0.10"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.130.0.10"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:25:30Z"
    generateName: sre-dns-latency-exporter-
    labels:
      controller-revision-hash: 77c4fb4fdb
      name: sre-dns-latency-exporter
      pod-template-generation: "1"
    name: sre-dns-latency-exporter-9nmg4
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sre-dns-latency-exporter
      uid: 70b79ab5-c7d4-4dbf-96af-4a340318b62a
    resourceVersion: "62209"
    uid: fa207915-b807-41d0-aea8-cd988cb04bf4
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-138-197.ec2.internal
    containers:
    - command:
      - /bin/sh
      - /monitor/start.sh
      env:
      - name: PYTHONPATH
        value: /openshift-python/packages:/support/packages
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 2
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 420
        periodSeconds: 360
        successThreshold: 1
        timeoutSeconds: 240
      name: main
      ports:
      - containerPort: 8080
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 240
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /monitor
        name: monitor-volume
        readOnly: true
      - mountPath: /etc/pki/ca-trust/extracted/pem
        name: trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6tb7r
        readOnly: true
      workingDir: /monitor
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: sre-dns-latency-exporter-dockercfg-49t44
    nodeName: ip-10-0-138-197.ec2.internal
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: sre-dns-latency-exporter
    serviceAccountName: sre-dns-latency-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sre-dns-latency-exporter-code
      name: monitor-volume
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: sre-dns-latency-exporter-trusted-ca-bundle
      name: trusted-ca-bundle
    - name: kube-api-access-6tb7r
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:25:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:36:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:36:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:25:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://2970c9db8ab14053d3260659140621b8e04baaaba4743d7f1f7d5ff53200aefe
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imageID: quay.io/app-sre/managed-prometheus-exporter-base@sha256:81123c64980b958e5d1c74d054fb82b8e752395dde6e5d92ec158d2b58dfedf6
      lastState: {}
      name: main
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:36:11Z"
    hostIP: 10.0.138.197
    phase: Running
    podIP: 10.130.0.10
    podIPs:
    - ip: 10.130.0.10
    qosClass: BestEffort
    startTime: "2022-05-24T18:25:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.4.5"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.4.5"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:28:12Z"
    generateName: sre-dns-latency-exporter-
    labels:
      controller-revision-hash: 77c4fb4fdb
      name: sre-dns-latency-exporter
      pod-template-generation: "1"
    name: sre-dns-latency-exporter-bf78r
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sre-dns-latency-exporter
      uid: 70b79ab5-c7d4-4dbf-96af-4a340318b62a
    resourceVersion: "74784"
    uid: b718a0ca-be3a-468e-af5d-f38685da9f81
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-148-123.ec2.internal
    containers:
    - command:
      - /bin/sh
      - /monitor/start.sh
      env:
      - name: PYTHONPATH
        value: /openshift-python/packages:/support/packages
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 2
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 420
        periodSeconds: 360
        successThreshold: 1
        timeoutSeconds: 240
      name: main
      ports:
      - containerPort: 8080
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 240
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /monitor
        name: monitor-volume
        readOnly: true
      - mountPath: /etc/pki/ca-trust/extracted/pem
        name: trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ksgm5
        readOnly: true
      workingDir: /monitor
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: sre-dns-latency-exporter-dockercfg-49t44
    nodeName: ip-10-0-148-123.ec2.internal
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: sre-dns-latency-exporter
    serviceAccountName: sre-dns-latency-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sre-dns-latency-exporter-code
      name: monitor-volume
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: sre-dns-latency-exporter-trusted-ca-bundle
      name: trusted-ca-bundle
    - name: kube-api-access-ksgm5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:28:12Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:13Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:13Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:28:12Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://97d11682ce77a9704df1a9686595808f52abc570e73945ae2303147041e5fb85
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imageID: quay.io/app-sre/managed-prometheus-exporter-base@sha256:81123c64980b958e5d1c74d054fb82b8e752395dde6e5d92ec158d2b58dfedf6
      lastState: {}
      name: main
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:42:10Z"
    hostIP: 10.0.148.123
    phase: Running
    podIP: 10.128.4.5
    podIPs:
    - ip: 10.128.4.5
    qosClass: BestEffort
    startTime: "2022-05-24T18:28:12Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.129.0.4"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.129.0.4"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:25:30Z"
    generateName: sre-dns-latency-exporter-
    labels:
      controller-revision-hash: 77c4fb4fdb
      name: sre-dns-latency-exporter
      pod-template-generation: "1"
    name: sre-dns-latency-exporter-mb45d
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sre-dns-latency-exporter
      uid: 70b79ab5-c7d4-4dbf-96af-4a340318b62a
    resourceVersion: "71867"
    uid: d96604b4-a43e-461a-9af9-2f6bcb912b91
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-149-121.ec2.internal
    containers:
    - command:
      - /bin/sh
      - /monitor/start.sh
      env:
      - name: PYTHONPATH
        value: /openshift-python/packages:/support/packages
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 2
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 420
        periodSeconds: 360
        successThreshold: 1
        timeoutSeconds: 240
      name: main
      ports:
      - containerPort: 8080
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 240
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /monitor
        name: monitor-volume
        readOnly: true
      - mountPath: /etc/pki/ca-trust/extracted/pem
        name: trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-g52cf
        readOnly: true
      workingDir: /monitor
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-10-0-149-121.ec2.internal
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: sre-dns-latency-exporter
    serviceAccountName: sre-dns-latency-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sre-dns-latency-exporter-code
      name: monitor-volume
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: sre-dns-latency-exporter-trusted-ca-bundle
      name: trusted-ca-bundle
    - name: kube-api-access-g52cf
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:25:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:45Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:40:45Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:25:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://fc48b8c9c908f9b2016e3317730744f28d6a2347d0f9dbb4b23f4eb14f447611
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imageID: quay.io/app-sre/managed-prometheus-exporter-base@sha256:81123c64980b958e5d1c74d054fb82b8e752395dde6e5d92ec158d2b58dfedf6
      lastState: {}
      name: main
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:40:40Z"
    hostIP: 10.0.149.121
    phase: Running
    podIP: 10.129.0.4
    podIPs:
    - ip: 10.129.0.4
    qosClass: BestEffort
    startTime: "2022-05-24T18:25:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.2"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.2"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:27:57Z"
    generateName: sre-dns-latency-exporter-
    labels:
      controller-revision-hash: 77c4fb4fdb
      name: sre-dns-latency-exporter
      pod-template-generation: "1"
    name: sre-dns-latency-exporter-rglbj
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sre-dns-latency-exporter
      uid: 70b79ab5-c7d4-4dbf-96af-4a340318b62a
    resourceVersion: "56619"
    uid: b0c7f5f8-6c47-44fb-a3f6-ac581f189903
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-166-35.ec2.internal
    containers:
    - command:
      - /bin/sh
      - /monitor/start.sh
      env:
      - name: PYTHONPATH
        value: /openshift-python/packages:/support/packages
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 2
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 420
        periodSeconds: 360
        successThreshold: 1
        timeoutSeconds: 240
      name: main
      ports:
      - containerPort: 8080
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 240
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /monitor
        name: monitor-volume
        readOnly: true
      - mountPath: /etc/pki/ca-trust/extracted/pem
        name: trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-wpt2k
        readOnly: true
      workingDir: /monitor
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: sre-dns-latency-exporter-dockercfg-49t44
    nodeName: ip-10-0-166-35.ec2.internal
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: sre-dns-latency-exporter
    serviceAccountName: sre-dns-latency-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sre-dns-latency-exporter-code
      name: monitor-volume
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: sre-dns-latency-exporter-trusted-ca-bundle
      name: trusted-ca-bundle
    - name: kube-api-access-wpt2k
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:27:58Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:32:31Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:32:31Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:27:57Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://d5eda52c4f1230c69cb8482d230dca1e72ae097077880d194bb8fa54af913409
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imageID: quay.io/app-sre/managed-prometheus-exporter-base@sha256:81123c64980b958e5d1c74d054fb82b8e752395dde6e5d92ec158d2b58dfedf6
      lastState: {}
      name: main
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:32:26Z"
    hostIP: 10.0.166.35
    phase: Running
    podIP: 10.131.2.2
    podIPs:
    - ip: 10.131.2.2
    qosClass: BestEffort
    startTime: "2022-05-24T18:27:58Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.129.2.6"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.129.2.6"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:25:30Z"
    generateName: sre-dns-latency-exporter-
    labels:
      controller-revision-hash: 77c4fb4fdb
      name: sre-dns-latency-exporter
      pod-template-generation: "1"
    name: sre-dns-latency-exporter-tm8gj
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sre-dns-latency-exporter
      uid: 70b79ab5-c7d4-4dbf-96af-4a340318b62a
    resourceVersion: "78844"
    uid: 7fd01664-e80a-4ecb-a8ef-5ed80931f211
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-145-179.ec2.internal
    containers:
    - command:
      - /bin/sh
      - /monitor/start.sh
      env:
      - name: PYTHONPATH
        value: /openshift-python/packages:/support/packages
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 2
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 420
        periodSeconds: 360
        successThreshold: 1
        timeoutSeconds: 240
      name: main
      ports:
      - containerPort: 8080
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 240
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /monitor
        name: monitor-volume
        readOnly: true
      - mountPath: /etc/pki/ca-trust/extracted/pem
        name: trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vmgbn
        readOnly: true
      workingDir: /monitor
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-10-0-145-179.ec2.internal
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: sre-dns-latency-exporter
    serviceAccountName: sre-dns-latency-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sre-dns-latency-exporter-code
      name: monitor-volume
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: sre-dns-latency-exporter-trusted-ca-bundle
      name: trusted-ca-bundle
    - name: kube-api-access-vmgbn
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:25:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:44:24Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:44:24Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:25:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://ce4f1dbd91922ea3a67a1d02172bb2993f6c26e68685d10fafd60f4ff100925b
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imageID: quay.io/app-sre/managed-prometheus-exporter-base@sha256:81123c64980b958e5d1c74d054fb82b8e752395dde6e5d92ec158d2b58dfedf6
      lastState: {}
      name: main
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:44:19Z"
    hostIP: 10.0.145.179
    phase: Running
    podIP: 10.129.2.6
    podIPs:
    - ip: 10.129.2.6
    qosClass: BestEffort
    startTime: "2022-05-24T18:25:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.0.6"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.0.6"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:25:30Z"
    generateName: sre-dns-latency-exporter-
    labels:
      controller-revision-hash: 77c4fb4fdb
      name: sre-dns-latency-exporter
      pod-template-generation: "1"
    name: sre-dns-latency-exporter-zc7kp
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sre-dns-latency-exporter
      uid: 70b79ab5-c7d4-4dbf-96af-4a340318b62a
    resourceVersion: "38101"
    uid: 1acaaf69-561b-4c00-b783-e93eb62d5beb
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ip-10-0-128-34.ec2.internal
    containers:
    - command:
      - /bin/sh
      - /monitor/start.sh
      env:
      - name: PYTHONPATH
        value: /openshift-python/packages:/support/packages
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 2
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 420
        periodSeconds: 360
        successThreshold: 1
        timeoutSeconds: 240
      name: main
      ports:
      - containerPort: 8080
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 240
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /monitor
        name: monitor-volume
        readOnly: true
      - mountPath: /etc/pki/ca-trust/extracted/pem
        name: trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-22tdc
        readOnly: true
      workingDir: /monitor
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: sre-dns-latency-exporter-dockercfg-49t44
    nodeName: ip-10-0-128-34.ec2.internal
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: sre-dns-latency-exporter
    serviceAccountName: sre-dns-latency-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sre-dns-latency-exporter-code
      name: monitor-volume
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: sre-dns-latency-exporter-trusted-ca-bundle
      name: trusted-ca-bundle
    - name: kube-api-access-22tdc
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:25:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:27:39Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:27:39Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:25:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://ee8eec332a058333bd0cca34eba7a04e42edaa82881ffedf3996b712bcc74fb0
      image: quay.io/app-sre/managed-prometheus-exporter-base:latest
      imageID: quay.io/app-sre/managed-prometheus-exporter-base@sha256:81123c64980b958e5d1c74d054fb82b8e752395dde6e5d92ec158d2b58dfedf6
      lastState: {}
      name: main
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:27:34Z"
    hostIP: 10.0.128.34
    phase: Running
    podIP: 10.131.0.6
    podIPs:
    - ip: 10.131.0.6
    qosClass: BestEffort
    startTime: "2022-05-24T18:25:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.11"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.2.11"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:34:57Z"
    generateName: telemeter-client-7589ddc4df-
    labels:
      app.kubernetes.io/component: telemetry-metrics-collector
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: telemeter-client
      app.kubernetes.io/part-of: openshift-monitoring
      pod-template-hash: 7589ddc4df
    name: telemeter-client-7589ddc4df-t55z2
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: telemeter-client-7589ddc4df
      uid: b8496268-de30-42b8-a7c4-6ab06236877c
    resourceVersion: "60513"
    uid: 7fe7c7c8-50c0-4bbe-805d-a0d8775c838c
  spec:
    containers:
    - command:
      - /usr/bin/telemeter-client
      - --id=$(ID)
      - --from=$(FROM)
      - --from-ca-file=/etc/serving-certs-ca-bundle/service-ca.crt
      - --from-token-file=/var/run/secrets/kubernetes.io/serviceaccount/token
      - --to=$(TO)
      - --to-token-file=/etc/telemeter/token
      - --listen=localhost:8080
      - --anonymize-salt-file=/etc/telemeter/salt
      - --anonymize-labels=$(ANONYMIZE_LABELS)
      - --match={__name__=~"cluster:usage:.*"}
      - --match={__name__="count:up0"}
      - --match={__name__="count:up1"}
      - --match={__name__="cluster_version"}
      - --match={__name__="cluster_version_available_updates"}
      - --match={__name__="cluster_operator_up"}
      - --match={__name__="cluster_operator_conditions"}
      - --match={__name__="cluster_version_payload"}
      - --match={__name__="cluster_installer"}
      - --match={__name__="cluster_infrastructure_provider"}
      - --match={__name__="cluster_feature_set"}
      - --match={__name__="instance:etcd_object_counts:sum"}
      - --match={__name__="ALERTS",alertstate="firing"}
      - --match={__name__="code:apiserver_request_total:rate:sum"}
      - --match={__name__="cluster:capacity_cpu_cores:sum"}
      - --match={__name__="cluster:capacity_memory_bytes:sum"}
      - --match={__name__="cluster:cpu_usage_cores:sum"}
      - --match={__name__="cluster:memory_usage_bytes:sum"}
      - --match={__name__="openshift:cpu_usage_cores:sum"}
      - --match={__name__="openshift:memory_usage_bytes:sum"}
      - --match={__name__="workload:cpu_usage_cores:sum"}
      - --match={__name__="workload:memory_usage_bytes:sum"}
      - --match={__name__="cluster:virt_platform_nodes:sum"}
      - --match={__name__="cluster:node_instance_type_count:sum"}
      - --match={__name__="cnv:vmi_status_running:count"}
      - --match={__name__="cluster:vmi_request_cpu_cores:sum"}
      - --match={__name__="node_role_os_version_machine:cpu_capacity_cores:sum"}
      - --match={__name__="node_role_os_version_machine:cpu_capacity_sockets:sum"}
      - --match={__name__="subscription_sync_total"}
      - --match={__name__="olm_resolution_duration_seconds"}
      - --match={__name__="csv_succeeded"}
      - --match={__name__="csv_abnormal"}
      - --match={__name__="cluster:kube_persistentvolumeclaim_resource_requests_storage_bytes:provisioner:sum"}
      - --match={__name__="cluster:kubelet_volume_stats_used_bytes:provisioner:sum"}
      - --match={__name__="ceph_cluster_total_bytes"}
      - --match={__name__="ceph_cluster_total_used_raw_bytes"}
      - --match={__name__="ceph_health_status"}
      - --match={__name__="job:ceph_osd_metadata:count"}
      - --match={__name__="job:kube_pv:count"}
      - --match={__name__="job:ceph_pools_iops:total"}
      - --match={__name__="job:ceph_pools_iops_bytes:total"}
      - --match={__name__="job:ceph_versions_running:count"}
      - --match={__name__="job:noobaa_total_unhealthy_buckets:sum"}
      - --match={__name__="job:noobaa_bucket_count:sum"}
      - --match={__name__="job:noobaa_total_object_count:sum"}
      - --match={__name__="noobaa_accounts_num"}
      - --match={__name__="noobaa_total_usage"}
      - --match={__name__="console_url"}
      - --match={__name__="cluster:network_attachment_definition_instances:max"}
      - --match={__name__="cluster:network_attachment_definition_enabled_instance_up:max"}
      - --match={__name__="cluster:ingress_controller_aws_nlb_active:sum"}
      - --match={__name__="insightsclient_request_send_total"}
      - --match={__name__="cam_app_workload_migrations"}
      - --match={__name__="cluster:apiserver_current_inflight_requests:sum:max_over_time:2m"}
      - --match={__name__="cluster:alertmanager_integrations:max"}
      - --match={__name__="cluster:telemetry_selected_series:count"}
      - --match={__name__="openshift:prometheus_tsdb_head_series:sum"}
      - --match={__name__="openshift:prometheus_tsdb_head_samples_appended_total:sum"}
      - --match={__name__="monitoring:container_memory_working_set_bytes:sum"}
      - --match={__name__="namespace_job:scrape_series_added:topk3_sum1h"}
      - --match={__name__="namespace_job:scrape_samples_post_metric_relabeling:topk3"}
      - --match={__name__="monitoring:haproxy_server_http_responses_total:sum"}
      - --match={__name__="rhmi_status"}
      - --match={__name__="cluster_legacy_scheduler_policy"}
      - --match={__name__="cluster_master_schedulable"}
      - --match={__name__="che_workspace_status"}
      - --match={__name__="che_workspace_started_total"}
      - --match={__name__="che_workspace_failure_total"}
      - --match={__name__="che_workspace_start_time_seconds_sum"}
      - --match={__name__="che_workspace_start_time_seconds_count"}
      - --match={__name__="cco_credentials_mode"}
      - --match={__name__="cluster:kube_persistentvolume_plugin_type_counts:sum"}
      - --match={__name__="visual_web_terminal_sessions_total"}
      - --match={__name__="acm_managed_cluster_info"}
      - --match={__name__="cluster:vsphere_vcenter_info:sum"}
      - --match={__name__="cluster:vsphere_esxi_version_total:sum"}
      - --match={__name__="cluster:vsphere_node_hw_version_total:sum"}
      - --match={__name__="openshift:build_by_strategy:sum"}
      - --match={__name__="rhods_aggregate_availability"}
      - --match={__name__="rhods_total_users"}
      - --match={__name__="instance:etcd_disk_wal_fsync_duration_seconds:histogram_quantile",quantile="0.99"}
      - --match={__name__="instance:etcd_mvcc_db_total_size_in_bytes:sum"}
      - --match={__name__="instance:etcd_network_peer_round_trip_time_seconds:histogram_quantile",quantile="0.99"}
      - --match={__name__="instance:etcd_mvcc_db_total_size_in_use_in_bytes:sum"}
      - --match={__name__="instance:etcd_disk_backend_commit_duration_seconds:histogram_quantile",quantile="0.99"}
      - --match={__name__="jaeger_operator_instances_storage_types"}
      - --match={__name__="jaeger_operator_instances_strategies"}
      - --match={__name__="jaeger_operator_instances_agent_strategies"}
      - --match={__name__="appsvcs:cores_by_product:sum"}
      - --match={__name__="nto_custom_profiles:count"}
      - --match={__name__="openshift_csi_share_configmap"}
      - --match={__name__="openshift_csi_share_secret"}
      - --match={__name__="openshift_csi_share_mount_failures_total"}
      - --match={__name__="openshift_csi_share_mount_requests_total"}
      - --limit-bytes=5242880
      env:
      - name: ANONYMIZE_LABELS
      - name: FROM
        value: https://prometheus-k8s.openshift-monitoring.svc:9091
      - name: ID
        value: 3ef9f2d5-498d-4a5e-a004-09e65633e1bb
      - name: TO
        value: https://infogw.api.openshift.com
      - name: HTTP_PROXY
      - name: HTTPS_PROXY
      - name: NO_PROXY
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:3cd352ab6f82a1f5f762b6283f9644e653d37dcdbab27e1fae3d5a82a76d2a9f
      imagePullPolicy: IfNotPresent
      name: telemeter-client
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 40Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/serving-certs-ca-bundle
        name: serving-certs-ca-bundle
      - mountPath: /etc/telemeter
        name: secret-telemeter-client
      - mountPath: /etc/pki/ca-trust/extracted/pem/
        name: telemeter-trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rkwxq
        readOnly: true
    - args:
      - --reload-url=http://localhost:8080/-/reload
      - --watched-dir=/etc/serving-certs-ca-bundle
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      imagePullPolicy: IfNotPresent
      name: reload
      resources:
        requests:
          cpu: 1m
          memory: 10Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/serving-certs-ca-bundle
        name: serving-certs-ca-bundle
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rkwxq
        readOnly: true
    - args:
      - --secure-listen-address=:8443
      - --upstream=http://127.0.0.1:8080/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --config-file=/etc/kube-rbac-policy/config.yaml
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 8443
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 20Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/tls/private
        name: telemeter-client-tls
      - mountPath: /etc/kube-rbac-policy
        name: secret-telemeter-client-kube-rbac-proxy-config
        readOnly: true
      - mountPath: /etc/tls/client
        name: metrics-client-ca
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rkwxq
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: telemeter-client-dockercfg-tz9lv
    nodeName: ip-10-0-166-35.ec2.internal
    nodeSelector:
      node-role.kubernetes.io/infra: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: telemeter-client
    serviceAccountName: telemeter-client
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: telemeter-client-serving-certs-ca-bundle
      name: serving-certs-ca-bundle
    - name: secret-telemeter-client
      secret:
        defaultMode: 420
        secretName: telemeter-client
    - name: telemeter-client-tls
      secret:
        defaultMode: 420
        secretName: telemeter-client-tls
    - name: secret-telemeter-client-kube-rbac-proxy-config
      secret:
        defaultMode: 420
        secretName: telemeter-client-kube-rbac-proxy-config
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: telemeter-trusted-ca-bundle-2rsonso43rc5p
        optional: true
      name: telemeter-trusted-ca-bundle
    - name: kube-api-access-rkwxq
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:34:57Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:35:03Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:35:03Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:34:57Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://54bdc0d369ea9140e8c8d260564048a63e6664d1fb6a7acac2d2eb4e58b57cad
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:35:03Z"
    - containerID: cri-o://f73e416bcb45c0009f192a65e11fefe79858950784cd99375372150d87710d19
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:b5d406a68f3fb45008977ea6f4d1cda50c8a878cf0055c11308b1785d5a06023
      lastState: {}
      name: reload
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:35:02Z"
    - containerID: cri-o://5d83df643bc6310dd3f53e8122e8cd23dc198439585d7a2b22bce258aa44087d
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:3cd352ab6f82a1f5f762b6283f9644e653d37dcdbab27e1fae3d5a82a76d2a9f
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:3cd352ab6f82a1f5f762b6283f9644e653d37dcdbab27e1fae3d5a82a76d2a9f
      lastState: {}
      name: telemeter-client
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:35:02Z"
    hostIP: 10.0.166.35
    phase: Running
    podIP: 10.131.2.11
    podIPs:
    - ip: 10.131.2.11
    qosClass: Burstable
    startTime: "2022-05-24T18:34:57Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.0.15"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.131.0.15"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:28:16Z"
    generateName: thanos-querier-86c47bb76-
    labels:
      app.kubernetes.io/component: query-layer
      app.kubernetes.io/instance: thanos-querier
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: thanos-query
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 0.23.1
      pod-template-hash: 86c47bb76
    name: thanos-querier-86c47bb76-4zbvt
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: thanos-querier-86c47bb76
      uid: 993907a8-c083-4df5-b19a-df958996c1ab
    resourceVersion: "42342"
    uid: fa507cbb-f393-41b9-98cf-733f102fc713
  spec:
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/component: query-layer
              app.kubernetes.io/instance: thanos-querier
              app.kubernetes.io/name: thanos-query
              app.kubernetes.io/part-of: openshift-monitoring
          topologyKey: kubernetes.io/hostname
    containers:
    - args:
      - query
      - --grpc-address=127.0.0.1:10901
      - --http-address=127.0.0.1:9090
      - --log.format=logfmt
      - --query.replica-label=prometheus_replica
      - --query.replica-label=thanos_ruler_replica
      - --store=dnssrv+_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local
      - --query.auto-downsampling
      - --store.sd-dns-resolver=miekgdns
      - --grpc-client-tls-secure
      - --grpc-client-tls-cert=/etc/tls/grpc/client.crt
      - --grpc-client-tls-key=/etc/tls/grpc/client.key
      - --grpc-client-tls-ca=/etc/tls/grpc/ca.crt
      - --grpc-client-server-name=prometheus-grpc
      - --rule=dnssrv+_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local
      - --target=dnssrv+_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local
      - --store=dnssrv+_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local
      - --store=dnssrv+_grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local
      - --rule=dnssrv+_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local
      - --rule=dnssrv+_grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local
      - --target=dnssrv+_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local
      env:
      - name: HOST_IP_ADDRESS
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8a5a316dec56c12072bd11525534dc01cad163fd44766be4e1fb3406796e662d
      imagePullPolicy: IfNotPresent
      name: thanos-query
      ports:
      - containerPort: 9090
        name: http
        protocol: TCP
      resources:
        limits:
          cpu: 500m
          memory: 2Gi
        requests:
          cpu: 5m
          memory: 125Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/grpc
        name: secret-grpc-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fgg7t
        readOnly: true
    - args:
      - -provider=openshift
      - -https-address=:9091
      - -http-address=
      - -email-domain=*
      - -upstream=http://localhost:9090
      - -openshift-service-account=thanos-querier
      - '-openshift-sar={"resource": "namespaces", "verb": "get"}'
      - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}}'
      - -tls-cert=/etc/tls/private/tls.crt
      - -tls-key=/etc/tls/private/tls.key
      - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
      - -cookie-secret-file=/etc/proxy/secrets/session_secret
      - -openshift-ca=/etc/pki/tls/cert.pem
      - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      - -bypass-auth-for=^/-/(healthy|ready)$
      - -htpasswd-file=/etc/proxy/htpasswd/auth
      env:
      - name: HTTP_PROXY
      - name: HTTPS_PROXY
      - name: NO_PROXY
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 4
        httpGet:
          path: /-/healthy
          port: 9091
          scheme: HTTPS
        initialDelaySeconds: 5
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 1
      name: oauth-proxy
      ports:
      - containerPort: 9091
        name: web
        protocol: TCP
      readinessProbe:
        failureThreshold: 20
        httpGet:
          path: /-/ready
          port: 9091
          scheme: HTTPS
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 1m
          memory: 20Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-thanos-querier-tls
      - mountPath: /etc/proxy/secrets
        name: secret-thanos-querier-oauth-cookie
      - mountPath: /etc/pki/ca-trust/extracted/pem/
        name: thanos-querier-trusted-ca-bundle
        readOnly: true
      - mountPath: /etc/proxy/htpasswd
        name: secret-thanos-querier-oauth-htpasswd
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fgg7t
        readOnly: true
    - args:
      - --secure-listen-address=0.0.0.0:9092
      - --upstream=http://127.0.0.1:9095
      - --config-file=/etc/kube-rbac-proxy/config.yaml
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --logtostderr=true
      - --allow-paths=/api/v1/query,/api/v1/query_range,/api/v1/labels,/api/v1/label/*/values,/api/v1/series
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9092
        name: tenancy
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-thanos-querier-tls
      - mountPath: /etc/kube-rbac-proxy
        name: secret-thanos-querier-kube-rbac-proxy
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fgg7t
        readOnly: true
    - args:
      - --insecure-listen-address=127.0.0.1:9095
      - --upstream=http://127.0.0.1:9090
      - --label=namespace
      - --enable-label-apis
      - --error-on-replace
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c3e8963d0e5dbce2e30dc0341c7453c30a42395622905b718a8fe9974da41ab
      imagePullPolicy: IfNotPresent
      name: prom-label-proxy
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fgg7t
        readOnly: true
    - args:
      - --secure-listen-address=0.0.0.0:9093
      - --upstream=http://127.0.0.1:9095
      - --config-file=/etc/kube-rbac-proxy/config.yaml
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --logtostderr=true
      - --allow-paths=/api/v1/rules
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-rules
      ports:
      - containerPort: 9093
        name: tenancy-rules
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-thanos-querier-tls
      - mountPath: /etc/kube-rbac-proxy
        name: secret-thanos-querier-kube-rbac-proxy-rules
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fgg7t
        readOnly: true
    - args:
      - --secure-listen-address=0.0.0.0:9094
      - --upstream=http://127.0.0.1:9090
      - --config-file=/etc/kube-rbac-proxy/config.yaml
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --logtostderr=true
      - --allow-paths=/metrics
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-metrics
      ports:
      - containerPort: 9094
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-thanos-querier-tls
      - mountPath: /etc/kube-rbac-proxy
        name: secret-thanos-querier-kube-rbac-proxy-metrics
      - mountPath: /etc/tls/client
        name: metrics-client-ca
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fgg7t
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: thanos-querier-dockercfg-25jz9
    nodeName: ip-10-0-128-34.ec2.internal
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: thanos-querier
    serviceAccountName: thanos-querier
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - name: secret-thanos-querier-tls
      secret:
        defaultMode: 420
        secretName: thanos-querier-tls
    - name: secret-thanos-querier-oauth-cookie
      secret:
        defaultMode: 420
        secretName: thanos-querier-oauth-cookie
    - name: secret-thanos-querier-kube-rbac-proxy
      secret:
        defaultMode: 420
        secretName: thanos-querier-kube-rbac-proxy
    - name: secret-thanos-querier-kube-rbac-proxy-rules
      secret:
        defaultMode: 420
        secretName: thanos-querier-kube-rbac-proxy-rules
    - name: secret-thanos-querier-kube-rbac-proxy-metrics
      secret:
        defaultMode: 420
        secretName: thanos-querier-kube-rbac-proxy-metrics
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: thanos-querier-trusted-ca-bundle-2rsonso43rc5p
        optional: true
      name: thanos-querier-trusted-ca-bundle
    - name: secret-thanos-querier-oauth-htpasswd
      secret:
        defaultMode: 420
        secretName: thanos-querier-oauth-htpasswd
    - name: secret-grpc-tls
      secret:
        defaultMode: 420
        secretName: thanos-querier-grpc-tls-66fq25vslj8tg
    - name: kube-api-access-fgg7t
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:28:16Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:28:26Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:28:26Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:28:16Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://ae03dd3ffbe093dca6d4f86d6d3149bc92e45256c179d73896b7f2e99e5c5281
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:28:18Z"
    - containerID: cri-o://28e2c4ca0c7d03b3d7c8f8f42825951fd29976b6b1ab059fa811df289d637abd
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy-metrics
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:28:19Z"
    - containerID: cri-o://33a9e7bbe180265020107960ae1b21093c59af178f94d6dc976184dc2a12ad31
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy-rules
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:28:18Z"
    - containerID: cri-o://8638b569142a3b013eb5a2a24fcf761975a071ed452932d166735f83a39af6af
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      lastState: {}
      name: oauth-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:28:18Z"
    - containerID: cri-o://17109fc32a48b93c401da6cf6bdfb92be13119b2f496c500940284f3a9ec0003
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c3e8963d0e5dbce2e30dc0341c7453c30a42395622905b718a8fe9974da41ab
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c3e8963d0e5dbce2e30dc0341c7453c30a42395622905b718a8fe9974da41ab
      lastState: {}
      name: prom-label-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:28:18Z"
    - containerID: cri-o://236add5f02f7e740ac7cf230ec36c6da016dc1d1051ebc65f1151ce46f2859a6
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8a5a316dec56c12072bd11525534dc01cad163fd44766be4e1fb3406796e662d
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8a5a316dec56c12072bd11525534dc01cad163fd44766be4e1fb3406796e662d
      lastState: {}
      name: thanos-query
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:28:18Z"
    hostIP: 10.0.128.34
    phase: Running
    podIP: 10.131.0.15
    podIPs:
    - ip: 10.131.0.15
    qosClass: Burstable
    startTime: "2022-05-24T18:28:16Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.2.16"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.2.16"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:42:29Z"
    generateName: thanos-querier-86c47bb76-
    labels:
      app.kubernetes.io/component: query-layer
      app.kubernetes.io/instance: thanos-querier
      app.kubernetes.io/managed-by: cluster-monitoring-operator
      app.kubernetes.io/name: thanos-query
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 0.23.1
      pod-template-hash: 86c47bb76
    name: thanos-querier-86c47bb76-8lj47
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: thanos-querier-86c47bb76
      uid: 993907a8-c083-4df5-b19a-df958996c1ab
    resourceVersion: "76011"
    uid: 909565bf-db43-477a-9783-8cb4cf9bb94f
  spec:
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/component: query-layer
              app.kubernetes.io/instance: thanos-querier
              app.kubernetes.io/name: thanos-query
              app.kubernetes.io/part-of: openshift-monitoring
          topologyKey: kubernetes.io/hostname
    containers:
    - args:
      - query
      - --grpc-address=127.0.0.1:10901
      - --http-address=127.0.0.1:9090
      - --log.format=logfmt
      - --query.replica-label=prometheus_replica
      - --query.replica-label=thanos_ruler_replica
      - --store=dnssrv+_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local
      - --query.auto-downsampling
      - --store.sd-dns-resolver=miekgdns
      - --grpc-client-tls-secure
      - --grpc-client-tls-cert=/etc/tls/grpc/client.crt
      - --grpc-client-tls-key=/etc/tls/grpc/client.key
      - --grpc-client-tls-ca=/etc/tls/grpc/ca.crt
      - --grpc-client-server-name=prometheus-grpc
      - --rule=dnssrv+_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local
      - --target=dnssrv+_grpc._tcp.prometheus-operated.openshift-monitoring.svc.cluster.local
      - --store=dnssrv+_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local
      - --store=dnssrv+_grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local
      - --rule=dnssrv+_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local
      - --rule=dnssrv+_grpc._tcp.thanos-ruler-operated.openshift-user-workload-monitoring.svc.cluster.local
      - --target=dnssrv+_grpc._tcp.prometheus-operated.openshift-user-workload-monitoring.svc.cluster.local
      env:
      - name: HOST_IP_ADDRESS
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8a5a316dec56c12072bd11525534dc01cad163fd44766be4e1fb3406796e662d
      imagePullPolicy: IfNotPresent
      name: thanos-query
      ports:
      - containerPort: 9090
        name: http
        protocol: TCP
      resources:
        limits:
          cpu: 500m
          memory: 2Gi
        requests:
          cpu: 5m
          memory: 125Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/grpc
        name: secret-grpc-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tncq5
        readOnly: true
    - args:
      - -provider=openshift
      - -https-address=:9091
      - -http-address=
      - -email-domain=*
      - -upstream=http://localhost:9090
      - -openshift-service-account=thanos-querier
      - '-openshift-sar={"resource": "namespaces", "verb": "get"}'
      - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}}'
      - -tls-cert=/etc/tls/private/tls.crt
      - -tls-key=/etc/tls/private/tls.key
      - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
      - -cookie-secret-file=/etc/proxy/secrets/session_secret
      - -openshift-ca=/etc/pki/tls/cert.pem
      - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      - -bypass-auth-for=^/-/(healthy|ready)$
      - -htpasswd-file=/etc/proxy/htpasswd/auth
      env:
      - name: HTTP_PROXY
      - name: HTTPS_PROXY
      - name: NO_PROXY
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 4
        httpGet:
          path: /-/healthy
          port: 9091
          scheme: HTTPS
        initialDelaySeconds: 5
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 1
      name: oauth-proxy
      ports:
      - containerPort: 9091
        name: web
        protocol: TCP
      readinessProbe:
        failureThreshold: 20
        httpGet:
          path: /-/ready
          port: 9091
          scheme: HTTPS
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 1m
          memory: 20Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-thanos-querier-tls
      - mountPath: /etc/proxy/secrets
        name: secret-thanos-querier-oauth-cookie
      - mountPath: /etc/pki/ca-trust/extracted/pem/
        name: thanos-querier-trusted-ca-bundle
        readOnly: true
      - mountPath: /etc/proxy/htpasswd
        name: secret-thanos-querier-oauth-htpasswd
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tncq5
        readOnly: true
    - args:
      - --secure-listen-address=0.0.0.0:9092
      - --upstream=http://127.0.0.1:9095
      - --config-file=/etc/kube-rbac-proxy/config.yaml
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --logtostderr=true
      - --allow-paths=/api/v1/query,/api/v1/query_range,/api/v1/labels,/api/v1/label/*/values,/api/v1/series
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9092
        name: tenancy
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-thanos-querier-tls
      - mountPath: /etc/kube-rbac-proxy
        name: secret-thanos-querier-kube-rbac-proxy
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tncq5
        readOnly: true
    - args:
      - --insecure-listen-address=127.0.0.1:9095
      - --upstream=http://127.0.0.1:9090
      - --label=namespace
      - --enable-label-apis
      - --error-on-replace
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c3e8963d0e5dbce2e30dc0341c7453c30a42395622905b718a8fe9974da41ab
      imagePullPolicy: IfNotPresent
      name: prom-label-proxy
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tncq5
        readOnly: true
    - args:
      - --secure-listen-address=0.0.0.0:9093
      - --upstream=http://127.0.0.1:9095
      - --config-file=/etc/kube-rbac-proxy/config.yaml
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --logtostderr=true
      - --allow-paths=/api/v1/rules
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-rules
      ports:
      - containerPort: 9093
        name: tenancy-rules
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-thanos-querier-tls
      - mountPath: /etc/kube-rbac-proxy
        name: secret-thanos-querier-kube-rbac-proxy-rules
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tncq5
        readOnly: true
    - args:
      - --secure-listen-address=0.0.0.0:9094
      - --upstream=http://127.0.0.1:9090
      - --config-file=/etc/kube-rbac-proxy/config.yaml
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      - --client-ca-file=/etc/tls/client/client-ca.crt
      - --logtostderr=true
      - --allow-paths=/metrics
      - --tls-min-version=VersionTLS12
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy-metrics
      ports:
      - containerPort: 9094
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 1m
          memory: 15Mi
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: secret-thanos-querier-tls
      - mountPath: /etc/kube-rbac-proxy
        name: secret-thanos-querier-kube-rbac-proxy-metrics
      - mountPath: /etc/tls/client
        name: metrics-client-ca
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tncq5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: thanos-querier-dockercfg-25jz9
    nodeName: ip-10-0-164-190.ec2.internal
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: thanos-querier
    serviceAccountName: thanos-querier
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - name: secret-thanos-querier-tls
      secret:
        defaultMode: 420
        secretName: thanos-querier-tls
    - name: secret-thanos-querier-oauth-cookie
      secret:
        defaultMode: 420
        secretName: thanos-querier-oauth-cookie
    - name: secret-thanos-querier-kube-rbac-proxy
      secret:
        defaultMode: 420
        secretName: thanos-querier-kube-rbac-proxy
    - name: secret-thanos-querier-kube-rbac-proxy-rules
      secret:
        defaultMode: 420
        secretName: thanos-querier-kube-rbac-proxy-rules
    - name: secret-thanos-querier-kube-rbac-proxy-metrics
      secret:
        defaultMode: 420
        secretName: thanos-querier-kube-rbac-proxy-metrics
    - configMap:
        defaultMode: 420
        name: metrics-client-ca
      name: metrics-client-ca
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: tls-ca-bundle.pem
        name: thanos-querier-trusted-ca-bundle-2rsonso43rc5p
        optional: true
      name: thanos-querier-trusted-ca-bundle
    - name: secret-thanos-querier-oauth-htpasswd
      secret:
        defaultMode: 420
        secretName: thanos-querier-oauth-htpasswd
    - name: secret-grpc-tls
      secret:
        defaultMode: 420
        secretName: thanos-querier-grpc-tls-66fq25vslj8tg
    - name: kube-api-access-tncq5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:29Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:39Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:39Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:29Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://0a7ca84ff2ce19edc1bf5fb0a2edd0e06df9cbef4f31880505481260348358ec
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:42:34Z"
    - containerID: cri-o://69cce4bc5cec5439d5d6e89e61fd1f4088018d50e941591b62c65d9ac808a253
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy-metrics
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:42:34Z"
    - containerID: cri-o://f66cab21810450dea6551980771e61db6c1764afdaf75ddd83d1503d026873b7
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
      lastState: {}
      name: kube-rbac-proxy-rules
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:42:34Z"
    - containerID: cri-o://07847a5ee6726f0df869fd9ed7e76b068ea9b02536eeced09df74dc2c51ff641
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d787f47ee2a410f924ea00b2428f0cf2275eb059adac96ca1b69c71ad20ccb1d
      lastState: {}
      name: oauth-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:42:33Z"
    - containerID: cri-o://269ed0d9a5a1b944dc55101d3de0fafaf7f772d0b40f78f44c78e3bbccca5d6c
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c3e8963d0e5dbce2e30dc0341c7453c30a42395622905b718a8fe9974da41ab
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c3e8963d0e5dbce2e30dc0341c7453c30a42395622905b718a8fe9974da41ab
      lastState: {}
      name: prom-label-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:42:34Z"
    - containerID: cri-o://baabc4c61b8d19892dc30cf38279a11436965b0c6e554c01f759146e2a2dbab7
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8a5a316dec56c12072bd11525534dc01cad163fd44766be4e1fb3406796e662d
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8a5a316dec56c12072bd11525534dc01cad163fd44766be4e1fb3406796e662d
      lastState: {}
      name: thanos-query
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:42:33Z"
    hostIP: 10.0.164.190
    phase: Running
    podIP: 10.128.2.16
    podIPs:
    - ip: 10.128.2.16
    qosClass: Burstable
    startTime: "2022-05-24T18:42:29Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.4.12"
            ],
            "default": true,
            "dns": {}
        }]
      k8s.v1.cni.cncf.io/networks-status: |-
        [{
            "name": "openshift-sdn",
            "interface": "eth0",
            "ips": [
                "10.128.4.12"
            ],
            "default": true,
            "dns": {}
        }]
      openshift.io/scc: restricted
    creationTimestamp: "2022-05-24T18:42:34Z"
    generateName: token-refresher-7f8c567555-
    labels:
      app.kubernetes.io/component: authentication-proxy
      app.kubernetes.io/name: token-refresher
      app.kubernetes.io/version: master-2021-02-24-1e01b9c
      pod-template-hash: 7f8c567555
    name: token-refresher-7f8c567555-svz87
    namespace: openshift-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: token-refresher-7f8c567555
      uid: 7f40ad39-8781-4a28-9afe-4b41ff7786c4
    resourceVersion: "76067"
    uid: 88a06257-1b67-48c5-b667-e448fe4e4bef
  spec:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - preference:
            matchExpressions:
            - key: node-role.kubernetes.io/infra
              operator: Exists
          weight: 1
    containers:
    - args:
      - --oidc.audience=observatorium-telemeter
      - --oidc.client-id=$(CLIENT_ID)
      - --oidc.client-secret=$(CLIENT_SECRET)
      - --oidc.issuer-url=$(ISSUER_URL)
      - --url=$(RECEIVER_URL)
      env:
      - name: CLIENT_ID
        valueFrom:
          secretKeyRef:
            key: client-id
            name: observatorium-credentials
      - name: CLIENT_SECRET
        valueFrom:
          secretKeyRef:
            key: client-secret
            name: observatorium-credentials
      - name: RECEIVER_URL
        valueFrom:
          secretKeyRef:
            key: receiver-url
            name: observatorium-credentials
      - name: ISSUER_URL
        value: https://sso.redhat.com/auth/realms/redhat-external
      image: quay.io/observatorium/token-refresher@sha256:6ce9b80cd1d907cb6c9ed2a18612f386f7503257772d1d88155a4a2e6773fd00
      imagePullPolicy: IfNotPresent
      name: token-refresher
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      resources: {}
      securityContext:
        capabilities:
          drop:
          - KILL
          - MKNOD
          - SETGID
          - SETUID
        runAsUser: 1000420000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs/
        name: token-refresher-trusted-ca-bundle
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-m5t7d
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: default-dockercfg-pwshv
    nodeName: ip-10-0-148-123.ec2.internal
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000420000
      seLinuxOptions:
        level: s0:c21,c0
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/infra
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: ca-bundle.crt
          path: ca-certificates.crt
        name: token-refresher-trusted-ca-bundle
      name: token-refresher-trusted-ca-bundle
    - name: kube-api-access-m5t7d
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:34Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:40Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:40Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-05-24T18:42:34Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://ed766ac77abe8d164c5b2fa4df714b12aa767ba9236ca706c8301a1e1c0ba9f9
      image: quay.io/observatorium/token-refresher@sha256:6ce9b80cd1d907cb6c9ed2a18612f386f7503257772d1d88155a4a2e6773fd00
      imageID: quay.io/observatorium/token-refresher@sha256:6ce9b80cd1d907cb6c9ed2a18612f386f7503257772d1d88155a4a2e6773fd00
      lastState: {}
      name: token-refresher
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-05-24T18:42:40Z"
    hostIP: 10.0.148.123
    phase: Running
    podIP: 10.128.4.12
    podIPs:
    - ip: 10.128.4.12
    qosClass: BestEffort
    startTime: "2022-05-24T18:42:34Z"
kind: PodList
metadata:
  resourceVersion: "322403"
