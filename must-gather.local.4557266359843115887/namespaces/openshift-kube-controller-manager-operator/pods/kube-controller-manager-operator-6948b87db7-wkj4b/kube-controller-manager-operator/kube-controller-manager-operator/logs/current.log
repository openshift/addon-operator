2022-05-24T18:36:39.648090153Z I0524 18:36:39.648008       1 cmd.go:209] Using service-serving-cert provided certificates
2022-05-24T18:36:39.648466629Z I0524 18:36:39.648449       1 observer_polling.go:159] Starting file observer
2022-05-24T18:36:40.721606706Z I0524 18:36:40.721573       1 builder.go:262] kube-controller-manager-operator version 4.10.0-202204211158.p0.gca3ff53.assembly.stream-ca3ff53-ca3ff5396f45632a4ae9997d9b71441b52b62efd
2022-05-24T18:36:41.415656268Z W0524 18:36:41.415624       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2022-05-24T18:36:41.415656268Z W0524 18:36:41.415639       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2022-05-24T18:36:41.460524888Z I0524 18:36:41.460408       1 secure_serving.go:266] Serving securely on [::]:8443
2022-05-24T18:36:41.461504884Z I0524 18:36:41.461479       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
2022-05-24T18:36:41.461568029Z I0524 18:36:41.461555       1 shared_informer.go:240] Waiting for caches to sync for RequestHeaderAuthRequestController
2022-05-24T18:36:41.461657164Z I0524 18:36:41.461632       1 dynamic_serving_content.go:131] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2022-05-24T18:36:41.462258558Z I0524 18:36:41.462235       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
2022-05-24T18:36:41.462925992Z I0524 18:36:41.462279       1 configmap_cafile_content.go:201] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2022-05-24T18:36:41.462925992Z I0524 18:36:41.462917       1 shared_informer.go:240] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2022-05-24T18:36:41.462956818Z I0524 18:36:41.462451       1 configmap_cafile_content.go:201] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2022-05-24T18:36:41.462956818Z I0524 18:36:41.462952       1 shared_informer.go:240] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2022-05-24T18:36:41.465415118Z I0524 18:36:41.465375       1 leaderelection.go:248] attempting to acquire leader lease openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock...
2022-05-24T18:36:41.546513072Z I0524 18:36:41.546473       1 leaderelection.go:258] successfully acquired lease openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock
2022-05-24T18:36:41.547897983Z I0524 18:36:41.547460       1 event.go:285] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator-lock", UID:"dae1c270-305a-43f9-922e-6ee6d0b82d5d", APIVersion:"v1", ResourceVersion:"63742", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' kube-controller-manager-operator-6948b87db7-wkj4b_9e654ecd-389e-4215-ad61-994889b4791d became leader
2022-05-24T18:36:41.547897983Z I0524 18:36:41.547500       1 event.go:285] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator-lock", UID:"24844fe4-fb72-4254-8122-e619c836d5ce", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"63745", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' kube-controller-manager-operator-6948b87db7-wkj4b_9e654ecd-389e-4215-ad61-994889b4791d became leader
2022-05-24T18:36:41.554446806Z E0524 18:36:41.554414       1 static_resource_controller.go:207] missing informer for namespace "openshift-infra"; no dynamic wiring added, time-based only.
2022-05-24T18:36:41.555054707Z E0524 18:36:41.555027       1 static_resource_controller.go:213] missing informer for namespace "openshift-infra"; no dynamic wiring added, time-based only.
2022-05-24T18:36:41.562084518Z I0524 18:36:41.562064       1 shared_informer.go:247] Caches are synced for RequestHeaderAuthRequestController 
2022-05-24T18:36:41.563566215Z I0524 18:36:41.563541       1 shared_informer.go:247] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file 
2022-05-24T18:36:41.563587968Z I0524 18:36:41.563548       1 shared_informer.go:247] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file 
2022-05-24T18:36:41.578384177Z I0524 18:36:41.578352       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "RevisionController" resync interval is set to 0s which might lead to client request throttling
2022-05-24T18:36:41.578595747Z I0524 18:36:41.578559       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "PruneController" resync interval is set to 0s which might lead to client request throttling
2022-05-24T18:36:41.578744063Z I0524 18:36:41.578715       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "NodeController" resync interval is set to 0s which might lead to client request throttling
2022-05-24T18:36:41.578761828Z I0524 18:36:41.578749       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "UnsupportedConfigOverridesController" resync interval is set to 0s which might lead to client request throttling
2022-05-24T18:36:41.578978272Z I0524 18:36:41.578929       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "LoggingSyncer" resync interval is set to 0s which might lead to client request throttling
2022-05-24T18:36:41.579330930Z I0524 18:36:41.579297       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "GuardController" resync interval is set to 0s which might lead to client request throttling
2022-05-24T18:36:41.659632708Z I0524 18:36:41.659596       1 base_controller.go:67] Waiting for caches to sync for RemoveStaleConditionsController
2022-05-24T18:36:41.660303538Z I0524 18:36:41.660276       1 base_controller.go:67] Waiting for caches to sync for MissingStaticPodController
2022-05-24T18:36:41.660605667Z I0524 18:36:41.660570       1 base_controller.go:67] Waiting for caches to sync for StaticResourceController
2022-05-24T18:36:41.660679318Z I0524 18:36:41.660668       1 base_controller.go:67] Waiting for caches to sync for TargetConfigController
2022-05-24T18:36:41.660736838Z I0524 18:36:41.660725       1 base_controller.go:67] Waiting for caches to sync for ConfigObserver
2022-05-24T18:36:41.660909023Z I0524 18:36:41.660896       1 base_controller.go:67] Waiting for caches to sync for StatusSyncer_kube-controller-manager
2022-05-24T18:36:41.660969103Z I0524 18:36:41.660959       1 base_controller.go:67] Waiting for caches to sync for ResourceSyncController
2022-05-24T18:36:41.661012869Z I0524 18:36:41.661003       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2022-05-24T18:36:41.661063765Z I0524 18:36:41.661054       1 base_controller.go:67] Waiting for caches to sync for SATokenSignerController
2022-05-24T18:36:41.661379345Z I0524 18:36:41.661360       1 base_controller.go:67] Waiting for caches to sync for PruneController
2022-05-24T18:36:41.661791231Z I0524 18:36:41.661760       1 base_controller.go:67] Waiting for caches to sync for InstallerStateController
2022-05-24T18:36:41.661840712Z I0524 18:36:41.661824       1 base_controller.go:67] Waiting for caches to sync for StaticPodStateController
2022-05-24T18:36:41.662040832Z I0524 18:36:41.662001       1 base_controller.go:67] Waiting for caches to sync for NodeController
2022-05-24T18:36:41.662090577Z I0524 18:36:41.662066       1 base_controller.go:67] Waiting for caches to sync for UnsupportedConfigOverridesController
2022-05-24T18:36:41.662111448Z I0524 18:36:41.662096       1 base_controller.go:67] Waiting for caches to sync for LoggingSyncer
2022-05-24T18:36:41.662255001Z I0524 18:36:41.662226       1 base_controller.go:67] Waiting for caches to sync for RevisionController
2022-05-24T18:36:41.662407086Z I0524 18:36:41.662374       1 base_controller.go:67] Waiting for caches to sync for InstallerController
2022-05-24T18:36:41.666401634Z I0524 18:36:41.666363       1 base_controller.go:67] Waiting for caches to sync for GuardController
2022-05-24T18:36:41.666669383Z I0524 18:36:41.666649       1 base_controller.go:67] Waiting for caches to sync for StaticResourceController
2022-05-24T18:36:41.667750797Z I0524 18:36:41.667718       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "InstallerController" resync interval is set to 0s which might lead to client request throttling
2022-05-24T18:36:41.762167035Z I0524 18:36:41.762115       1 base_controller.go:73] Caches are synced for InstallerStateController 
2022-05-24T18:36:41.762167035Z I0524 18:36:41.762156       1 base_controller.go:110] Starting #1 worker of InstallerStateController controller ...
2022-05-24T18:36:41.767701208Z I0524 18:36:41.767661       1 base_controller.go:73] Caches are synced for GuardController 
2022-05-24T18:36:41.767701208Z I0524 18:36:41.767677       1 base_controller.go:110] Starting #1 worker of GuardController controller ...
2022-05-24T18:36:41.860707693Z I0524 18:36:41.860671       1 base_controller.go:73] Caches are synced for MissingStaticPodController 
2022-05-24T18:36:41.860779706Z I0524 18:36:41.860753       1 base_controller.go:110] Starting #1 worker of MissingStaticPodController controller ...
2022-05-24T18:36:41.860812794Z I0524 18:36:41.860687       1 base_controller.go:73] Caches are synced for RemoveStaleConditionsController 
2022-05-24T18:36:41.860821363Z I0524 18:36:41.860813       1 base_controller.go:110] Starting #1 worker of RemoveStaleConditionsController controller ...
2022-05-24T18:36:41.860860051Z I0524 18:36:41.860845       1 base_controller.go:73] Caches are synced for ConfigObserver 
2022-05-24T18:36:41.861052035Z I0524 18:36:41.860880       1 base_controller.go:110] Starting #1 worker of ConfigObserver controller ...
2022-05-24T18:36:41.861536842Z I0524 18:36:41.861513       1 base_controller.go:73] Caches are synced for SATokenSignerController 
2022-05-24T18:36:41.861536842Z I0524 18:36:41.861529       1 base_controller.go:110] Starting #1 worker of SATokenSignerController controller ...
2022-05-24T18:36:41.861561099Z I0524 18:36:41.861549       1 base_controller.go:73] Caches are synced for StatusSyncer_kube-controller-manager 
2022-05-24T18:36:41.861561099Z I0524 18:36:41.861555       1 base_controller.go:110] Starting #1 worker of StatusSyncer_kube-controller-manager controller ...
2022-05-24T18:36:41.861588289Z I0524 18:36:41.861573       1 base_controller.go:73] Caches are synced for CertRotationController 
2022-05-24T18:36:41.861588289Z I0524 18:36:41.861585       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2022-05-24T18:36:41.861846556Z I0524 18:36:41.861827       1 base_controller.go:73] Caches are synced for PruneController 
2022-05-24T18:36:41.861870412Z I0524 18:36:41.861846       1 base_controller.go:110] Starting #1 worker of PruneController controller ...
2022-05-24T18:36:41.862150739Z I0524 18:36:41.862129       1 base_controller.go:73] Caches are synced for NodeController 
2022-05-24T18:36:41.862150739Z I0524 18:36:41.862146       1 base_controller.go:110] Starting #1 worker of NodeController controller ...
2022-05-24T18:36:41.862270412Z I0524 18:36:41.862246       1 base_controller.go:73] Caches are synced for StaticPodStateController 
2022-05-24T18:36:41.864532923Z I0524 18:36:41.864491       1 base_controller.go:110] Starting #1 worker of StaticPodStateController controller ...
2022-05-24T18:36:41.864615889Z I0524 18:36:41.864352       1 base_controller.go:73] Caches are synced for UnsupportedConfigOverridesController 
2022-05-24T18:36:41.864640733Z I0524 18:36:41.864626       1 base_controller.go:110] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2022-05-24T18:36:41.865587216Z I0524 18:36:41.865565       1 base_controller.go:73] Caches are synced for InstallerController 
2022-05-24T18:36:41.865670958Z I0524 18:36:41.865646       1 base_controller.go:110] Starting #1 worker of InstallerController controller ...
2022-05-24T18:36:41.868920886Z I0524 18:36:41.868890       1 base_controller.go:73] Caches are synced for RevisionController 
2022-05-24T18:36:41.868920886Z I0524 18:36:41.868911       1 base_controller.go:73] Caches are synced for LoggingSyncer 
2022-05-24T18:36:41.868944268Z I0524 18:36:41.868919       1 base_controller.go:110] Starting #1 worker of RevisionController controller ...
2022-05-24T18:36:41.868996929Z I0524 18:36:41.868921       1 base_controller.go:110] Starting #1 worker of LoggingSyncer controller ...
2022-05-24T18:36:42.067728670Z I0524 18:36:42.067696       1 base_controller.go:73] Caches are synced for StaticResourceController 
2022-05-24T18:36:42.067728670Z I0524 18:36:42.067716       1 base_controller.go:110] Starting #1 worker of StaticResourceController controller ...
2022-05-24T18:36:42.261356271Z I0524 18:36:42.261317       1 base_controller.go:73] Caches are synced for TargetConfigController 
2022-05-24T18:36:42.261356271Z I0524 18:36:42.261343       1 base_controller.go:110] Starting #1 worker of TargetConfigController controller ...
2022-05-24T18:36:42.261395886Z I0524 18:36:42.261322       1 base_controller.go:73] Caches are synced for StaticResourceController 
2022-05-24T18:36:42.261395886Z I0524 18:36:42.261372       1 base_controller.go:110] Starting #1 worker of StaticResourceController controller ...
2022-05-24T18:36:42.662054194Z I0524 18:36:42.662016       1 base_controller.go:73] Caches are synced for ResourceSyncController 
2022-05-24T18:36:42.662054194Z I0524 18:36:42.662038       1 base_controller.go:110] Starting #1 worker of ResourceSyncController controller ...
2022-05-24T18:36:42.779527972Z I0524 18:36:42.779494       1 request.go:665] Waited for 1.017090175s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T18:36:43.780551526Z I0524 18:36:43.780513       1 request.go:665] Waited for 1.908781398s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-10-ip-10-0-138-197.ec2.internal
2022-05-24T18:36:44.980444277Z I0524 18:36:44.980404       1 request.go:665] Waited for 1.775938026s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/default/endpoints/kubernetes
2022-05-24T18:36:44.984564902Z I0524 18:36:44.984515       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerOK' found expected kube-apiserver endpoints
2022-05-24T18:36:46.180395168Z I0524 18:36:46.180354       1 request.go:665] Waited for 1.395754673s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-138-197.ec2.internal
2022-05-24T18:36:46.807236807Z I0524 18:36:46.807124       1 installer_controller.go:512] "ip-10-0-138-197.ec2.internal" is in transition to 10, but has not made progress because waiting for static pod of revision 10, found 9
2022-05-24T18:36:47.380207333Z I0524 18:36:47.380143       1 request.go:665] Waited for 1.194171269s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-138-197.ec2.internal
2022-05-24T18:36:47.385502274Z I0524 18:36:47.385471       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:36:47.389516202Z I0524 18:36:47.389493       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:36:47.794928685Z I0524 18:36:47.794884       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-10-ip-10-0-149-121.ec2.internal -n openshift-kube-controller-manager because it was missing
2022-05-24T18:36:48.580282530Z I0524 18:36:48.580247       1 request.go:665] Waited for 1.190401539s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-169-205.ec2.internal
2022-05-24T18:36:49.779967900Z I0524 18:36:49.779917       1 request.go:665] Waited for 1.195448155s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-169-205.ec2.internal
2022-05-24T18:36:50.384915128Z I0524 18:36:50.384852       1 installer_controller.go:512] "ip-10-0-138-197.ec2.internal" is in transition to 10, but has not made progress because waiting for static pod of revision 10, found 9
2022-05-24T18:36:50.980432290Z I0524 18:36:50.980402       1 request.go:665] Waited for 1.195455872s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-138-197.ec2.internal
2022-05-24T18:36:52.179936319Z I0524 18:36:52.179902       1 request.go:665] Waited for 1.186167657s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-138-197.ec2.internal
2022-05-24T18:36:52.189677189Z E0524 18:36:52.189637       1 guard_controller.go:253] Missing PodIP in operand kube-controller-manager-ip-10-0-138-197.ec2.internal on node ip-10-0-138-197.ec2.internal
2022-05-24T18:36:52.189677189Z I0524 18:36:52.189663       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:36:53.180161194Z I0524 18:36:53.180129       1 request.go:665] Waited for 1.147221571s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/csr-signer
2022-05-24T18:36:53.983919235Z I0524 18:36:53.983882       1 installer_controller.go:512] "ip-10-0-138-197.ec2.internal" is in transition to 10, but has not made progress because static pod is pending
2022-05-24T18:36:54.379676180Z I0524 18:36:54.379643       1 request.go:665] Waited for 1.193972406s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/csr-signer
2022-05-24T18:36:54.597415752Z E0524 18:36:54.597378       1 base_controller.go:272] GuardController reconciliation failed: Missing PodIP in operand kube-controller-manager-ip-10-0-138-197.ec2.internal on node ip-10-0-138-197.ec2.internal
2022-05-24T18:36:54.598600802Z I0524 18:36:54.598562       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ip-10-0-138-197.ec2.internal on node ip-10-0-138-197.ec2.internal","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 7; 1 nodes are at revision 9; 1 nodes are at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 7; 1 nodes are at revision 9; 1 nodes are at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:36:54.601447445Z I0524 18:36:54.601417       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:36:54.608135232Z I0524 18:36:54.608086       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ip-10-0-138-197.ec2.internal on node ip-10-0-138-197.ec2.internal"
2022-05-24T18:36:55.380221482Z I0524 18:36:55.380170       1 request.go:665] Waited for 1.195731955s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa
2022-05-24T18:36:56.580440221Z I0524 18:36:56.580404       1 request.go:665] Waited for 1.396248672s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-10-ip-10-0-138-197.ec2.internal
2022-05-24T18:36:57.779773460Z I0524 18:36:57.779741       1 request.go:665] Waited for 1.395125848s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T18:36:57.985336932Z I0524 18:36:57.985299       1 installer_controller.go:512] "ip-10-0-138-197.ec2.internal" is in transition to 10, but has not made progress because static pod is pending
2022-05-24T18:36:58.780415211Z I0524 18:36:58.780380       1 request.go:665] Waited for 1.195839945s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-138-197.ec2.internal
2022-05-24T18:36:59.979993446Z I0524 18:36:59.979959       1 request.go:665] Waited for 1.195209211s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-138-197.ec2.internal
2022-05-24T18:36:59.998035437Z I0524 18:36:59.997995       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 7; 1 nodes are at revision 9; 1 nodes are at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 7; 1 nodes are at revision 9; 1 nodes are at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:37:00.008427369Z I0524 18:37:00.008380       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ip-10-0-138-197.ec2.internal on node ip-10-0-138-197.ec2.internal" to "NodeControllerDegraded: All master nodes are ready"
2022-05-24T18:37:01.179699258Z I0524 18:37:01.179659       1 request.go:665] Waited for 1.182000407s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T18:37:01.984968009Z I0524 18:37:01.984928       1 installer_controller.go:512] "ip-10-0-138-197.ec2.internal" is in transition to 10, but has not made progress because static pod is pending
2022-05-24T18:37:02.179961782Z I0524 18:37:02.179916       1 request.go:665] Waited for 1.594850921s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager
2022-05-24T18:37:03.180269127Z I0524 18:37:03.180239       1 request.go:665] Waited for 1.194353578s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-10-ip-10-0-138-197.ec2.internal
2022-05-24T18:37:04.379603835Z I0524 18:37:04.379571       1 request.go:665] Waited for 1.194610136s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-10-ip-10-0-138-197.ec2.internal
2022-05-24T18:37:04.985518471Z I0524 18:37:04.985482       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:37:04.989449600Z I0524 18:37:04.989421       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:37:05.386402109Z I0524 18:37:05.386358       1 installer_controller.go:512] "ip-10-0-138-197.ec2.internal" is in transition to 10, but has not made progress because static pod is pending
2022-05-24T18:37:09.780275763Z I0524 18:37:09.780243       1 request.go:665] Waited for 1.028390847s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-169-205.ec2.internal
2022-05-24T18:37:10.979896378Z I0524 18:37:10.979860       1 request.go:665] Waited for 1.194957156s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-169-205.ec2.internal
2022-05-24T18:37:11.584856493Z I0524 18:37:11.584808       1 installer_controller.go:500] "ip-10-0-138-197.ec2.internal" moving to (v1.NodeStatus) {
2022-05-24T18:37:11.584856493Z  NodeName: (string) (len=28) "ip-10-0-138-197.ec2.internal",
2022-05-24T18:37:11.584856493Z  CurrentRevision: (int32) 10,
2022-05-24T18:37:11.584856493Z  TargetRevision: (int32) 0,
2022-05-24T18:37:11.584856493Z  LastFailedRevision: (int32) 0,
2022-05-24T18:37:11.584856493Z  LastFailedTime: (*v1.Time)(<nil>),
2022-05-24T18:37:11.584856493Z  LastFailedReason: (string) "",
2022-05-24T18:37:11.584856493Z  LastFailedCount: (int) 0,
2022-05-24T18:37:11.584856493Z  LastFallbackCount: (int) 0,
2022-05-24T18:37:11.584856493Z  LastFailedRevisionErrors: ([]string) <nil>
2022-05-24T18:37:11.584856493Z }
2022-05-24T18:37:11.584856493Z  because static pod is ready
2022-05-24T18:37:11.599004911Z I0524 18:37:11.598969       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ip-10-0-138-197.ec2.internal" from revision 9 to 10 because static pod is ready
2022-05-24T18:37:11.600037712Z I0524 18:37:11.599987       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 7; 2 nodes are at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 7; 2 nodes are at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:37:11.609851489Z I0524 18:37:11.609814       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 1 nodes are at revision 7; 1 nodes are at revision 9; 1 nodes are at revision 10" to "NodeInstallerProgressing: 1 nodes are at revision 7; 2 nodes are at revision 10",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 7; 1 nodes are at revision 9; 1 nodes are at revision 10" to "StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 7; 2 nodes are at revision 10"
2022-05-24T18:37:12.779574465Z I0524 18:37:12.779540       1 request.go:665] Waited for 1.179861408s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T18:37:13.384949758Z I0524 18:37:13.384906       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:37:13.388875921Z I0524 18:37:13.388847       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:37:13.779904715Z I0524 18:37:13.779867       1 request.go:665] Waited for 1.394979314s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client
2022-05-24T18:37:14.980406635Z I0524 18:37:14.980367       1 request.go:665] Waited for 1.195637595s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/localhost-recovery-client-token
2022-05-24T18:37:15.184310674Z I0524 18:37:15.184266       1 installer_controller.go:500] "ip-10-0-138-197.ec2.internal" moving to (v1.NodeStatus) {
2022-05-24T18:37:15.184310674Z  NodeName: (string) (len=28) "ip-10-0-138-197.ec2.internal",
2022-05-24T18:37:15.184310674Z  CurrentRevision: (int32) 10,
2022-05-24T18:37:15.184310674Z  TargetRevision: (int32) 0,
2022-05-24T18:37:15.184310674Z  LastFailedRevision: (int32) 0,
2022-05-24T18:37:15.184310674Z  LastFailedTime: (*v1.Time)(<nil>),
2022-05-24T18:37:15.184310674Z  LastFailedReason: (string) "",
2022-05-24T18:37:15.184310674Z  LastFailedCount: (int) 0,
2022-05-24T18:37:15.184310674Z  LastFallbackCount: (int) 0,
2022-05-24T18:37:15.184310674Z  LastFailedRevisionErrors: ([]string) <nil>
2022-05-24T18:37:15.184310674Z }
2022-05-24T18:37:15.184310674Z  because static pod is ready
2022-05-24T18:37:15.980415436Z I0524 18:37:15.980378       1 request.go:665] Waited for 1.192383462s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client
2022-05-24T18:37:17.192965911Z I0524 18:37:17.192921       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-10-ip-10-0-149-121.ec2.internal -n openshift-kube-controller-manager because it was missing
2022-05-24T18:37:17.389103397Z I0524 18:37:17.389065       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:37:17.984441253Z I0524 18:37:17.984407       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 10, but has not made progress because installer is not finished, but in Pending phase
2022-05-24T18:37:18.380353935Z I0524 18:37:18.380303       1 request.go:665] Waited for 1.187066431s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T18:37:19.579494442Z I0524 18:37:19.579457       1 request.go:665] Waited for 1.194545588s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-169-205.ec2.internal
2022-05-24T18:37:20.384545278Z I0524 18:37:20.384507       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 10, but has not made progress because installer is not finished, but in Pending phase
2022-05-24T18:37:20.780235911Z I0524 18:37:20.780201       1 request.go:665] Waited for 1.196079027s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T18:37:21.979686312Z I0524 18:37:21.979654       1 request.go:665] Waited for 1.194271601s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T18:37:22.187556486Z I0524 18:37:22.187521       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:37:22.784300489Z I0524 18:37:22.784253       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:37:24.785636744Z I0524 18:37:24.785582       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 10, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:37:26.784234790Z I0524 18:37:26.784167       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:37:29.383948301Z I0524 18:37:29.383909       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:37:29.387607306Z I0524 18:37:29.387582       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:37:58.978664310Z I0524 18:37:58.978628       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:38:02.361872806Z I0524 18:38:02.361823       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 11 triggered by "secret/localhost-recovery-client-token has changed"
2022-05-24T18:38:02.789132430Z I0524 18:38:02.789075       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/revision-status-11 -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:03.382836580Z I0524 18:38:03.382784       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-manager-pod-11 -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:03.979828935Z I0524 18:38:03.979774       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-11 -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:04.582752018Z I0524 18:38:04.582705       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cluster-policy-controller-config-11 -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:05.178591668Z I0524 18:38:05.178551       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/controller-manager-kubeconfig-11 -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:06.376777488Z I0524 18:38:06.376731       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-cert-syncer-kubeconfig-11 -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:06.977938451Z I0524 18:38:06.977883       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-11 -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:07.581407862Z I0524 18:38:07.581362       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/service-ca-11 -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:08.176675879Z I0524 18:38:08.176630       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/recycler-config-11 -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:08.980440200Z I0524 18:38:08.980387       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/service-account-private-key-11 -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:09.784245396Z I0524 18:38:09.784167       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-11 -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:10.582482041Z I0524 18:38:10.582444       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-11 -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:10.593807214Z I0524 18:38:10.593764       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 10 created because secret/localhost-recovery-client-token has changed
2022-05-24T18:38:10.596259706Z I0524 18:38:10.596223       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 11 triggered by "secret/localhost-recovery-client-token has changed"
2022-05-24T18:38:11.174831402Z I0524 18:38:11.174790       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:38:11.770608512Z I0524 18:38:11.770573       1 request.go:665] Waited for 1.175791797s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T18:38:12.182655038Z W0524 18:38:12.182612       1 staticpod.go:38] revision 11 is unexpectedly already the latest available revision. This is a possible race!
2022-05-24T18:38:12.194134908Z E0524 18:38:12.194087       1 base_controller.go:272] RevisionController reconciliation failed: conflicting latestAvailableRevision 11
2022-05-24T18:38:12.196273695Z I0524 18:38:12.196232       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready\nRevisionControllerDegraded: conflicting latestAvailableRevision 11","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 7; 2 nodes are at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 7; 2 nodes are at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:38:12.206617857Z I0524 18:38:12.206573       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: All master nodes are ready\nRevisionControllerDegraded: conflicting latestAvailableRevision 11"
2022-05-24T18:38:12.213104431Z I0524 18:38:12.213077       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 7; 2 nodes are at revision 10","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 7; 2 nodes are at revision 10","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:38:12.233098887Z I0524 18:38:12.233047       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nRevisionControllerDegraded: conflicting latestAvailableRevision 11" to "NodeControllerDegraded: All master nodes are ready"
2022-05-24T18:38:12.970717588Z I0524 18:38:12.970682       1 request.go:665] Waited for 1.395936316s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-10-ip-10-0-149-121.ec2.internal
2022-05-24T18:38:12.983192661Z I0524 18:38:12.983135       1 installer_controller.go:500] "ip-10-0-149-121.ec2.internal" moving to (v1.NodeStatus) {
2022-05-24T18:38:12.983192661Z  NodeName: (string) (len=28) "ip-10-0-149-121.ec2.internal",
2022-05-24T18:38:12.983192661Z  CurrentRevision: (int32) 7,
2022-05-24T18:38:12.983192661Z  TargetRevision: (int32) 11,
2022-05-24T18:38:12.983192661Z  LastFailedRevision: (int32) 0,
2022-05-24T18:38:12.983192661Z  LastFailedTime: (*v1.Time)(<nil>),
2022-05-24T18:38:12.983192661Z  LastFailedReason: (string) "",
2022-05-24T18:38:12.983192661Z  LastFailedCount: (int) 0,
2022-05-24T18:38:12.983192661Z  LastFallbackCount: (int) 0,
2022-05-24T18:38:12.983192661Z  LastFailedRevisionErrors: ([]string) <nil>
2022-05-24T18:38:12.983192661Z }
2022-05-24T18:38:12.983192661Z  because new revision pending
2022-05-24T18:38:12.999764563Z I0524 18:38:12.999722       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 7; 2 nodes are at revision 10; 0 nodes have achieved new revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 7; 2 nodes are at revision 10; 0 nodes have achieved new revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:38:13.010385996Z I0524 18:38:13.010333       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 1 nodes are at revision 7; 2 nodes are at revision 10" to "NodeInstallerProgressing: 1 nodes are at revision 7; 2 nodes are at revision 10; 0 nodes have achieved new revision 11",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 7; 2 nodes are at revision 10" to "StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 7; 2 nodes are at revision 10; 0 nodes have achieved new revision 11"
2022-05-24T18:38:13.184153034Z I0524 18:38:13.184110       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-11-ip-10-0-138-197.ec2.internal -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:14.170294837Z I0524 18:38:14.170249       1 request.go:665] Waited for 1.186934029s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T18:38:15.370371089Z I0524 18:38:15.370330       1 request.go:665] Waited for 1.594378105s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/cluster-policy-controller-config
2022-05-24T18:38:16.182517011Z I0524 18:38:16.182462       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-11-ip-10-0-149-121.ec2.internal -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:16.378242881Z I0524 18:38:16.378191       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-11-ip-10-0-169-205.ec2.internal -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:16.570588826Z I0524 18:38:16.570544       1 request.go:665] Waited for 1.395292854s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa
2022-05-24T18:38:17.570749116Z I0524 18:38:17.570715       1 request.go:665] Waited for 1.388241283s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-149-121.ec2.internal
2022-05-24T18:38:17.575296395Z I0524 18:38:17.575266       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2022-05-24T18:38:18.769962808Z I0524 18:38:18.769929       1 request.go:665] Waited for 1.395141919s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-138-197.ec2.internal
2022-05-24T18:38:18.775136081Z I0524 18:38:18.775103       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:38:18.779857856Z I0524 18:38:18.779813       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:38:19.180941061Z I0524 18:38:19.180859       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-11-ip-10-0-149-121.ec2.internal -n openshift-kube-controller-manager because it was missing
2022-05-24T18:38:19.969766404Z I0524 18:38:19.969725       1 request.go:665] Waited for 1.189467195s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-169-205.ec2.internal
2022-05-24T18:38:20.374991683Z I0524 18:38:20.374954       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2022-05-24T18:38:20.970452987Z I0524 18:38:20.970412       1 request.go:665] Waited for 1.395058828s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-controller-ca
2022-05-24T18:38:22.169966516Z I0524 18:38:22.169925       1 request.go:665] Waited for 1.363993919s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra
2022-05-24T18:38:23.170365423Z I0524 18:38:23.170324       1 request.go:665] Waited for 1.394135564s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-149-121.ec2.internal
2022-05-24T18:38:23.176118989Z I0524 18:38:23.176087       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2022-05-24T18:38:24.179410602Z I0524 18:38:24.179377       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:38:24.370619601Z I0524 18:38:24.370586       1 request.go:665] Waited for 1.193587221s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-149-121.ec2.internal
2022-05-24T18:38:25.375711224Z I0524 18:38:25.375673       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2022-05-24T18:38:31.176207480Z I0524 18:38:31.176158       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:38:36.436529734Z I0524 18:38:36.436494       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:38:36.466697595Z I0524 18:38:36.466658       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-149-121.ec2.internal\" not ready since 2022-05-24 18:38:36 +0000 UTC because NodeStatusUnknown (Kubelet stopped posting node status.)","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 7; 2 nodes are at revision 10; 0 nodes have achieved new revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 7; 2 nodes are at revision 10; 0 nodes have achieved new revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:38:36.493449959Z I0524 18:38:36.493403       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-149-121.ec2.internal\" not ready since 2022-05-24 18:38:36 +0000 UTC because NodeStatusUnknown (Kubelet stopped posting node status.)"
2022-05-24T18:38:37.174853589Z I0524 18:38:37.174816       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2022-05-24T18:38:37.570751634Z I0524 18:38:37.570707       1 request.go:665] Waited for 1.004158921s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T18:38:38.572914864Z I0524 18:38:38.571987       1 request.go:665] Waited for 1.194821164s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T18:38:39.575002333Z I0524 18:38:39.574960       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2022-05-24T18:38:40.376234338Z I0524 18:38:40.376201       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:38:44.975556607Z I0524 18:38:44.975518       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:38:44.979737861Z I0524 18:38:44.979711       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:38:48.406649978Z I0524 18:38:48.406612       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:39:00.314968354Z I0524 18:39:00.314918       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:39:00.375444615Z I0524 18:39:00.375400       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:39:24.530645820Z I0524 18:39:24.530605       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:39:44.767304995Z I0524 18:39:44.767271       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:39:47.970893441Z I0524 18:39:47.970836       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:39:48.970171524Z I0524 18:39:48.970136       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:00.276165119Z I0524 18:40:00.276127       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:00.317424994Z I0524 18:40:00.317394       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:01.900882416Z I0524 18:40:01.900850       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:08.632081783Z I0524 18:40:08.632011       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:08.658291643Z I0524 18:40:08.658257       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:08.688510165Z I0524 18:40:08.688467       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:10.352471591Z I0524 18:40:10.352438       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:13.228595011Z I0524 18:40:13.228557       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:16.229297203Z I0524 18:40:16.229262       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:16.233895923Z I0524 18:40:16.233867       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:18.675171120Z I0524 18:40:18.675129       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:21.790000703Z I0524 18:40:21.789963       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:25.780556202Z I0524 18:40:25.780502       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:25.805788392Z I0524 18:40:25.805749       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 7; 2 nodes are at revision 10; 0 nodes have achieved new revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 7; 2 nodes are at revision 10; 0 nodes have achieved new revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:40:25.850101166Z I0524 18:40:25.850042       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: The master nodes not ready: node \"ip-10-0-149-121.ec2.internal\" not ready since 2022-05-24 18:38:36 +0000 UTC because NodeStatusUnknown (Kubelet stopped posting node status.)" to "NodeControllerDegraded: All master nodes are ready"
2022-05-24T18:40:25.985747013Z I0524 18:40:25.985705       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2022-05-24T18:40:26.981126334Z I0524 18:40:26.981083       1 request.go:665] Waited for 1.031660897s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra
2022-05-24T18:40:27.982062548Z I0524 18:40:27.982005       1 request.go:665] Waited for 1.030601594s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T18:40:29.181082595Z I0524 18:40:29.181046       1 request.go:665] Waited for 1.192409033s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T18:40:29.384902517Z I0524 18:40:29.384868       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2022-05-24T18:40:30.181858841Z I0524 18:40:30.181819       1 request.go:665] Waited for 1.197747778s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T18:40:30.804230236Z I0524 18:40:30.803565       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:30.817238299Z I0524 18:40:30.816592       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:31.384736950Z I0524 18:40:31.384695       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2022-05-24T18:40:36.188342616Z I0524 18:40:36.188304       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:36.191957930Z I0524 18:40:36.191927       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:37.989231546Z I0524 18:40:37.989195       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:38.785388311Z I0524 18:40:38.785282       1 request.go:665] Waited for 1.158387876s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra
2022-05-24T18:40:39.794635118Z I0524 18:40:39.794596       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2022-05-24T18:40:39.986357748Z I0524 18:40:39.986320       1 request.go:665] Waited for 1.185350484s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager
2022-05-24T18:40:41.181536752Z I0524 18:40:41.181485       1 request.go:665] Waited for 1.184480665s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa
2022-05-24T18:40:42.181940570Z I0524 18:40:42.181899       1 request.go:665] Waited for 1.195890172s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-149-121.ec2.internal
2022-05-24T18:40:42.185883654Z I0524 18:40:42.185628       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:40:42.788738328Z I0524 18:40:42.788702       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:43.382123806Z I0524 18:40:43.382091       1 request.go:665] Waited for 1.311628638s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T18:40:44.582029600Z I0524 18:40:44.581995       1 request.go:665] Waited for 1.397578558s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T18:40:44.784915970Z I0524 18:40:44.784880       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:40:46.784848510Z I0524 18:40:46.784812       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:40:47.386400358Z I0524 18:40:47.386363       1 guard_controller.go:234] Node ip-10-0-149-121.ec2.internal not schedulable, skipping reconciling the guard pod
2022-05-24T18:40:51.384071380Z I0524 18:40:51.384031       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:40:52.186501088Z I0524 18:40:52.186451       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-controller-manager-guard-ip-10-0-149-121.ec2.internal -n openshift-kube-controller-manager because it was missing
2022-05-24T18:40:54.185144284Z I0524 18:40:54.185104       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:40:54.781289389Z I0524 18:40:54.781247       1 request.go:665] Waited for 1.187158602s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2022-05-24T18:40:55.782079003Z I0524 18:40:55.782039       1 request.go:665] Waited for 1.098836939s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T18:40:56.384257797Z I0524 18:40:56.384224       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:40:56.981915711Z I0524 18:40:56.981874       1 request.go:665] Waited for 1.195441293s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T18:40:57.993238325Z I0524 18:40:57.990339       1 request.go:665] Waited for 1.206738079s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-149-121.ec2.internal
2022-05-24T18:40:58.784497382Z I0524 18:40:58.784454       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:40:59.181803885Z I0524 18:40:59.181772       1 request.go:665] Waited for 1.167746576s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-169-205.ec2.internal
2022-05-24T18:41:00.785210646Z I0524 18:41:00.785157       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:41:22.888113540Z I0524 18:41:22.888076       1 request.go:665] Waited for 1.174092644s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-149-121.ec2.internal
2022-05-24T18:41:23.490751086Z I0524 18:41:23.490708       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:41:26.297092964Z I0524 18:41:26.297054       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 7
2022-05-24T18:41:34.491883195Z I0524 18:41:34.491850       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 7
2022-05-24T18:41:37.293358177Z I0524 18:41:37.293295       1 request.go:665] Waited for 1.000861139s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-149-121.ec2.internal
2022-05-24T18:41:38.291601701Z I0524 18:41:38.291560       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because static pod is pending
2022-05-24T18:41:39.690753887Z I0524 18:41:39.690718       1 request.go:665] Waited for 1.000009043s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2022-05-24T18:41:40.290251135Z E0524 18:41:40.290206       1 guard_controller.go:253] Missing PodIP in operand kube-controller-manager-ip-10-0-149-121.ec2.internal on node ip-10-0-149-121.ec2.internal
2022-05-24T18:41:40.300155116Z E0524 18:41:40.300125       1 base_controller.go:272] GuardController reconciliation failed: Missing PodIP in operand kube-controller-manager-ip-10-0-149-121.ec2.internal on node ip-10-0-149-121.ec2.internal
2022-05-24T18:41:40.302054310Z I0524 18:41:40.302020       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ip-10-0-149-121.ec2.internal on node ip-10-0-149-121.ec2.internal","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 7; 2 nodes are at revision 10; 0 nodes have achieved new revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 7; 2 nodes are at revision 10; 0 nodes have achieved new revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:41:40.310280477Z I0524 18:41:40.310244       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ip-10-0-149-121.ec2.internal on node ip-10-0-149-121.ec2.internal"
2022-05-24T18:41:40.890770290Z I0524 18:41:40.890727       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because static pod is pending
2022-05-24T18:41:41.487856645Z I0524 18:41:41.487807       1 request.go:665] Waited for 1.185842905s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T18:41:42.488121214Z I0524 18:41:42.488082       1 request.go:665] Waited for 1.596334047s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-149-121.ec2.internal
2022-05-24T18:41:43.488361059Z I0524 18:41:43.488326       1 request.go:665] Waited for 1.417016039s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T18:41:44.688504411Z I0524 18:41:44.688472       1 request.go:665] Waited for 1.597957147s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-169-205.ec2.internal
2022-05-24T18:41:45.291403999Z I0524 18:41:45.291359       1 installer_controller.go:512] "ip-10-0-149-121.ec2.internal" is in transition to 11, but has not made progress because static pod is pending
2022-05-24T18:41:47.302964422Z I0524 18:41:47.302925       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 7; 2 nodes are at revision 10; 0 nodes have achieved new revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 7; 2 nodes are at revision 10; 0 nodes have achieved new revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:41:47.316385822Z I0524 18:41:47.315793       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ip-10-0-149-121.ec2.internal on node ip-10-0-149-121.ec2.internal" to "NodeControllerDegraded: All master nodes are ready"
2022-05-24T18:41:48.488487444Z I0524 18:41:48.488443       1 request.go:665] Waited for 1.185058731s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-11-ip-10-0-138-197.ec2.internal
2022-05-24T18:41:49.488614042Z I0524 18:41:49.488549       1 request.go:665] Waited for 1.397596486s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-149-121.ec2.internal
2022-05-24T18:41:50.687888279Z I0524 18:41:50.687847       1 request.go:665] Waited for 1.196302169s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T18:41:50.696069331Z I0524 18:41:50.693964       1 installer_controller.go:500] "ip-10-0-149-121.ec2.internal" moving to (v1.NodeStatus) {
2022-05-24T18:41:50.696069331Z  NodeName: (string) (len=28) "ip-10-0-149-121.ec2.internal",
2022-05-24T18:41:50.696069331Z  CurrentRevision: (int32) 11,
2022-05-24T18:41:50.696069331Z  TargetRevision: (int32) 0,
2022-05-24T18:41:50.696069331Z  LastFailedRevision: (int32) 0,
2022-05-24T18:41:50.696069331Z  LastFailedTime: (*v1.Time)(<nil>),
2022-05-24T18:41:50.696069331Z  LastFailedReason: (string) "",
2022-05-24T18:41:50.696069331Z  LastFailedCount: (int) 0,
2022-05-24T18:41:50.696069331Z  LastFallbackCount: (int) 0,
2022-05-24T18:41:50.696069331Z  LastFailedRevisionErrors: ([]string) <nil>
2022-05-24T18:41:50.696069331Z }
2022-05-24T18:41:50.696069331Z  because static pod is ready
2022-05-24T18:41:50.709399749Z I0524 18:41:50.709367       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 2 nodes are at revision 10; 1 nodes are at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 10; 1 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:41:50.710073696Z I0524 18:41:50.710022       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ip-10-0-149-121.ec2.internal" from revision 7 to 11 because static pod is ready
2022-05-24T18:41:50.718227710Z I0524 18:41:50.718167       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 1 nodes are at revision 7; 2 nodes are at revision 10; 0 nodes have achieved new revision 11" to "NodeInstallerProgressing: 2 nodes are at revision 10; 1 nodes are at revision 11",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 7; 2 nodes are at revision 10; 0 nodes have achieved new revision 11" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 10; 1 nodes are at revision 11"
2022-05-24T18:41:51.688047259Z I0524 18:41:51.688015       1 request.go:665] Waited for 1.196840967s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa
2022-05-24T18:41:52.688063399Z I0524 18:41:52.688030       1 request.go:665] Waited for 1.59545882s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-169-205.ec2.internal
2022-05-24T18:41:53.688073837Z I0524 18:41:53.688036       1 request.go:665] Waited for 1.395983448s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-169-205.ec2.internal
2022-05-24T18:41:54.688411980Z I0524 18:41:54.688378       1 request.go:665] Waited for 1.393222409s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client
2022-05-24T18:41:55.888445903Z I0524 18:41:55.888408       1 request.go:665] Waited for 1.187381371s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2022-05-24T18:41:58.090579300Z I0524 18:41:58.090544       1 installer_controller.go:524] node ip-10-0-138-197.ec2.internal with revision 10 is the oldest and needs new revision 11
2022-05-24T18:41:58.090607868Z I0524 18:41:58.090597       1 installer_controller.go:532] "ip-10-0-138-197.ec2.internal" moving to (v1.NodeStatus) {
2022-05-24T18:41:58.090607868Z  NodeName: (string) (len=28) "ip-10-0-138-197.ec2.internal",
2022-05-24T18:41:58.090607868Z  CurrentRevision: (int32) 10,
2022-05-24T18:41:58.090607868Z  TargetRevision: (int32) 11,
2022-05-24T18:41:58.090607868Z  LastFailedRevision: (int32) 0,
2022-05-24T18:41:58.090607868Z  LastFailedTime: (*v1.Time)(<nil>),
2022-05-24T18:41:58.090607868Z  LastFailedReason: (string) "",
2022-05-24T18:41:58.090607868Z  LastFailedCount: (int) 0,
2022-05-24T18:41:58.090607868Z  LastFallbackCount: (int) 0,
2022-05-24T18:41:58.090607868Z  LastFailedRevisionErrors: ([]string) <nil>
2022-05-24T18:41:58.090607868Z }
2022-05-24T18:41:58.100060754Z I0524 18:41:58.100014       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ip-10-0-138-197.ec2.internal" from revision 10 to 11 because node ip-10-0-138-197.ec2.internal with revision 10 is the oldest
2022-05-24T18:41:59.288517011Z I0524 18:41:59.288469       1 request.go:665] Waited for 1.187324368s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-138-197.ec2.internal
2022-05-24T18:42:00.288728844Z I0524 18:42:00.288690       1 request.go:665] Waited for 1.39840092s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller
2022-05-24T18:42:00.695439438Z I0524 18:42:00.695377       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-11-ip-10-0-138-197.ec2.internal -n openshift-kube-controller-manager because it was missing
2022-05-24T18:42:01.488564059Z I0524 18:42:01.488517       1 request.go:665] Waited for 1.195749076s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client
2022-05-24T18:42:01.892443905Z I0524 18:42:01.892405       1 installer_controller.go:512] "ip-10-0-138-197.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2022-05-24T18:42:02.688763180Z I0524 18:42:02.688722       1 request.go:665] Waited for 1.396476404s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-controller-ca
2022-05-24T18:42:03.688796475Z I0524 18:42:03.688763       1 request.go:665] Waited for 1.19287635s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-149-121.ec2.internal
2022-05-24T18:42:04.490800357Z I0524 18:42:04.490761       1 installer_controller.go:512] "ip-10-0-138-197.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:42:04.888526183Z I0524 18:42:04.888494       1 request.go:665] Waited for 1.197458012s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-149-121.ec2.internal
2022-05-24T18:42:05.888555726Z I0524 18:42:05.888508       1 request.go:665] Waited for 1.191934845s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T18:42:06.890146184Z I0524 18:42:06.890108       1 installer_controller.go:512] "ip-10-0-138-197.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:42:36.892024374Z I0524 18:42:36.891985       1 installer_controller.go:512] "ip-10-0-138-197.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:42:40.491747194Z I0524 18:42:40.491699       1 installer_controller.go:512] "ip-10-0-138-197.ec2.internal" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 10
2022-05-24T18:42:43.088430563Z I0524 18:42:43.088395       1 request.go:665] Waited for 1.016925993s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T18:42:48.288629811Z I0524 18:42:48.288594       1 request.go:665] Waited for 1.006677023s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-138-197.ec2.internal
2022-05-24T18:42:49.488287461Z I0524 18:42:49.488246       1 request.go:665] Waited for 1.196799541s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-138-197.ec2.internal
2022-05-24T18:42:49.892462370Z E0524 18:42:49.892413       1 guard_controller.go:253] Missing PodIP in operand kube-controller-manager-ip-10-0-138-197.ec2.internal on node ip-10-0-138-197.ec2.internal
2022-05-24T18:42:50.488456623Z I0524 18:42:50.488416       1 request.go:665] Waited for 1.194105535s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T18:42:50.691805285Z I0524 18:42:50.691762       1 installer_controller.go:512] "ip-10-0-138-197.ec2.internal" is in transition to 11, but has not made progress because static pod is pending
2022-05-24T18:42:52.103115911Z E0524 18:42:52.103080       1 base_controller.go:272] GuardController reconciliation failed: Missing PodIP in operand kube-controller-manager-ip-10-0-138-197.ec2.internal on node ip-10-0-138-197.ec2.internal
2022-05-24T18:42:52.104616457Z I0524 18:42:52.104569       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ip-10-0-138-197.ec2.internal on node ip-10-0-138-197.ec2.internal","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 2 nodes are at revision 10; 1 nodes are at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 10; 1 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:42:52.114496402Z I0524 18:42:52.114453       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ip-10-0-138-197.ec2.internal on node ip-10-0-138-197.ec2.internal"
2022-05-24T18:42:53.288439808Z I0524 18:42:53.288396       1 request.go:665] Waited for 1.184012325s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T18:42:54.098121571Z I0524 18:42:54.098076       1 installer_controller.go:512] "ip-10-0-138-197.ec2.internal" is in transition to 11, but has not made progress because static pod is pending
2022-05-24T18:42:54.288475895Z I0524 18:42:54.288425       1 request.go:665] Waited for 1.397276203s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/trusted-ca-bundle
2022-05-24T18:42:55.488636652Z I0524 18:42:55.488605       1 request.go:665] Waited for 1.140693662s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2022-05-24T18:42:56.688449593Z I0524 18:42:56.688403       1 request.go:665] Waited for 1.197433345s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/serving-cert
2022-05-24T18:42:57.691065270Z I0524 18:42:57.691030       1 installer_controller.go:512] "ip-10-0-138-197.ec2.internal" is in transition to 11, but has not made progress because static pod is pending
2022-05-24T18:42:57.888058571Z I0524 18:42:57.888022       1 request.go:665] Waited for 1.194119069s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/cluster-policy-controller-config
2022-05-24T18:42:59.087856961Z I0524 18:42:59.087805       1 request.go:665] Waited for 1.197112811s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/recycler-config
2022-05-24T18:42:59.301682984Z I0524 18:42:59.301643       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 2 nodes are at revision 10; 1 nodes are at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 10; 1 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:42:59.312131840Z I0524 18:42:59.312087       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ip-10-0-138-197.ec2.internal on node ip-10-0-138-197.ec2.internal" to "NodeControllerDegraded: All master nodes are ready"
2022-05-24T18:43:00.088680901Z I0524 18:43:00.088646       1 request.go:665] Waited for 1.196680808s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-138-197.ec2.internal
2022-05-24T18:43:01.088698248Z I0524 18:43:01.088658       1 request.go:665] Waited for 1.596216847s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller
2022-05-24T18:43:01.491247573Z I0524 18:43:01.491207       1 installer_controller.go:500] "ip-10-0-138-197.ec2.internal" moving to (v1.NodeStatus) {
2022-05-24T18:43:01.491247573Z  NodeName: (string) (len=28) "ip-10-0-138-197.ec2.internal",
2022-05-24T18:43:01.491247573Z  CurrentRevision: (int32) 11,
2022-05-24T18:43:01.491247573Z  TargetRevision: (int32) 0,
2022-05-24T18:43:01.491247573Z  LastFailedRevision: (int32) 0,
2022-05-24T18:43:01.491247573Z  LastFailedTime: (*v1.Time)(<nil>),
2022-05-24T18:43:01.491247573Z  LastFailedReason: (string) "",
2022-05-24T18:43:01.491247573Z  LastFailedCount: (int) 0,
2022-05-24T18:43:01.491247573Z  LastFallbackCount: (int) 0,
2022-05-24T18:43:01.491247573Z  LastFailedRevisionErrors: ([]string) <nil>
2022-05-24T18:43:01.491247573Z }
2022-05-24T18:43:01.491247573Z  because static pod is ready
2022-05-24T18:43:01.500474138Z I0524 18:43:01.500427       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ip-10-0-138-197.ec2.internal" from revision 10 to 11 because static pod is ready
2022-05-24T18:43:01.501976682Z I0524 18:43:01.501938       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 10; 2 nodes are at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 10; 2 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:43:01.509881942Z I0524 18:43:01.509848       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 10; 1 nodes are at revision 11" to "NodeInstallerProgressing: 1 nodes are at revision 10; 2 nodes are at revision 11",Available message changed from "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 10; 1 nodes are at revision 11" to "StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 10; 2 nodes are at revision 11"
2022-05-24T18:43:02.288780470Z I0524 18:43:02.288742       1 request.go:665] Waited for 1.195088899s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client
2022-05-24T18:43:03.488071678Z I0524 18:43:03.488033       1 request.go:665] Waited for 1.395631226s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-138-197.ec2.internal
2022-05-24T18:43:04.688608051Z I0524 18:43:04.688565       1 request.go:665] Waited for 1.197233729s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-138-197.ec2.internal
2022-05-24T18:43:05.291471606Z I0524 18:43:05.291435       1 installer_controller.go:500] "ip-10-0-138-197.ec2.internal" moving to (v1.NodeStatus) {
2022-05-24T18:43:05.291471606Z  NodeName: (string) (len=28) "ip-10-0-138-197.ec2.internal",
2022-05-24T18:43:05.291471606Z  CurrentRevision: (int32) 11,
2022-05-24T18:43:05.291471606Z  TargetRevision: (int32) 0,
2022-05-24T18:43:05.291471606Z  LastFailedRevision: (int32) 0,
2022-05-24T18:43:05.291471606Z  LastFailedTime: (*v1.Time)(<nil>),
2022-05-24T18:43:05.291471606Z  LastFailedReason: (string) "",
2022-05-24T18:43:05.291471606Z  LastFailedCount: (int) 0,
2022-05-24T18:43:05.291471606Z  LastFallbackCount: (int) 0,
2022-05-24T18:43:05.291471606Z  LastFailedRevisionErrors: ([]string) <nil>
2022-05-24T18:43:05.291471606Z }
2022-05-24T18:43:05.291471606Z  because static pod is ready
2022-05-24T18:43:05.688643276Z I0524 18:43:05.688603       1 request.go:665] Waited for 1.196807274s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-11-ip-10-0-169-205.ec2.internal
2022-05-24T18:43:06.888765952Z I0524 18:43:06.888727       1 request.go:665] Waited for 1.196382139s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-11-ip-10-0-149-121.ec2.internal
2022-05-24T18:43:11.090481473Z I0524 18:43:11.090450       1 installer_controller.go:524] node ip-10-0-169-205.ec2.internal with revision 10 is the oldest and needs new revision 11
2022-05-24T18:43:11.090507741Z I0524 18:43:11.090488       1 installer_controller.go:532] "ip-10-0-169-205.ec2.internal" moving to (v1.NodeStatus) {
2022-05-24T18:43:11.090507741Z  NodeName: (string) (len=28) "ip-10-0-169-205.ec2.internal",
2022-05-24T18:43:11.090507741Z  CurrentRevision: (int32) 10,
2022-05-24T18:43:11.090507741Z  TargetRevision: (int32) 11,
2022-05-24T18:43:11.090507741Z  LastFailedRevision: (int32) 0,
2022-05-24T18:43:11.090507741Z  LastFailedTime: (*v1.Time)(<nil>),
2022-05-24T18:43:11.090507741Z  LastFailedReason: (string) "",
2022-05-24T18:43:11.090507741Z  LastFailedCount: (int) 0,
2022-05-24T18:43:11.090507741Z  LastFallbackCount: (int) 0,
2022-05-24T18:43:11.090507741Z  LastFailedRevisionErrors: ([]string) <nil>
2022-05-24T18:43:11.090507741Z }
2022-05-24T18:43:11.102484509Z I0524 18:43:11.102442       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ip-10-0-169-205.ec2.internal" from revision 10 to 11 because node ip-10-0-169-205.ec2.internal with revision 10 is the oldest
2022-05-24T18:43:12.287831842Z I0524 18:43:12.287796       1 request.go:665] Waited for 1.184957455s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-11-ip-10-0-138-197.ec2.internal
2022-05-24T18:43:13.288694969Z I0524 18:43:13.288654       1 request.go:665] Waited for 1.197606368s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-169-205.ec2.internal
2022-05-24T18:43:13.694918360Z I0524 18:43:13.694866       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-11-ip-10-0-169-205.ec2.internal -n openshift-kube-controller-manager because it was missing
2022-05-24T18:43:14.488628217Z I0524 18:43:14.488594       1 request.go:665] Waited for 1.196996917s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T18:43:14.890671570Z I0524 18:43:14.890636       1 installer_controller.go:512] "ip-10-0-169-205.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Pending phase
2022-05-24T18:43:15.488690703Z I0524 18:43:15.488654       1 request.go:665] Waited for 1.396953696s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-149-121.ec2.internal
2022-05-24T18:43:16.488877308Z I0524 18:43:16.488834       1 request.go:665] Waited for 1.198011503s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/serving-cert
2022-05-24T18:43:17.290347451Z I0524 18:43:17.290309       1 installer_controller.go:512] "ip-10-0-169-205.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:43:17.688611406Z I0524 18:43:17.688573       1 request.go:665] Waited for 1.195411628s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/cluster-policy-controller-config
2022-05-24T18:43:18.888402107Z I0524 18:43:18.888358       1 request.go:665] Waited for 1.197582043s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/recycler-config
2022-05-24T18:43:19.691082197Z I0524 18:43:19.691029       1 installer_controller.go:512] "ip-10-0-169-205.ec2.internal" is in transition to 11, but has not made progress because installer is not finished, but in Running phase
2022-05-24T18:43:51.153482180Z I0524 18:43:51.153438       1 request.go:665] Waited for 1.166499759s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-169-205.ec2.internal
2022-05-24T18:43:53.152821159Z I0524 18:43:53.152769       1 request.go:665] Waited for 1.156836857s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T18:43:53.356989875Z I0524 18:43:53.356950       1 installer_controller.go:512] "ip-10-0-169-205.ec2.internal" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 10
2022-05-24T18:43:54.153014483Z I0524 18:43:54.152978       1 request.go:665] Waited for 1.196562259s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T18:43:56.355093518Z I0524 18:43:56.355034       1 installer_controller.go:512] "ip-10-0-169-205.ec2.internal" is in transition to 11, but has not made progress because waiting for static pod of revision 11, found 10
2022-05-24T18:44:00.552825721Z I0524 18:44:00.552780       1 request.go:665] Waited for 1.096134676s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-169-205.ec2.internal
2022-05-24T18:44:01.752654166Z I0524 18:44:01.752616       1 request.go:665] Waited for 1.197054106s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-169-205.ec2.internal
2022-05-24T18:44:01.955756966Z E0524 18:44:01.955720       1 guard_controller.go:253] Missing PodIP in operand kube-controller-manager-ip-10-0-169-205.ec2.internal on node ip-10-0-169-205.ec2.internal
2022-05-24T18:44:02.753004994Z I0524 18:44:02.752963       1 request.go:665] Waited for 1.196297192s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T18:44:02.956871550Z I0524 18:44:02.956834       1 installer_controller.go:512] "ip-10-0-169-205.ec2.internal" is in transition to 11, but has not made progress because static pod is pending
2022-05-24T18:44:04.168568526Z I0524 18:44:04.168530       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ip-10-0-169-205.ec2.internal on node ip-10-0-169-205.ec2.internal","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 10; 2 nodes are at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 10; 2 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:44:04.168957020Z E0524 18:44:04.168924       1 base_controller.go:272] GuardController reconciliation failed: Missing PodIP in operand kube-controller-manager-ip-10-0-169-205.ec2.internal on node ip-10-0-169-205.ec2.internal
2022-05-24T18:44:04.183962222Z I0524 18:44:04.183922       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ip-10-0-169-205.ec2.internal on node ip-10-0-169-205.ec2.internal"
2022-05-24T18:44:05.353276279Z I0524 18:44:05.353239       1 request.go:665] Waited for 1.183556153s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-11-ip-10-0-138-197.ec2.internal
2022-05-24T18:44:06.353333950Z I0524 18:44:06.353299       1 request.go:665] Waited for 1.397405866s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-169-205.ec2.internal
2022-05-24T18:44:06.355873286Z I0524 18:44:06.355840       1 installer_controller.go:512] "ip-10-0-169-205.ec2.internal" is in transition to 11, but has not made progress because static pod is pending
2022-05-24T18:44:07.553514773Z I0524 18:44:07.553479       1 request.go:665] Waited for 1.196597341s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-169-205.ec2.internal
2022-05-24T18:44:08.753402531Z I0524 18:44:08.753367       1 request.go:665] Waited for 1.195671342s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-11-ip-10-0-169-205.ec2.internal
2022-05-24T18:44:09.757258342Z I0524 18:44:09.757218       1 installer_controller.go:512] "ip-10-0-169-205.ec2.internal" is in transition to 11, but has not made progress because static pod is pending
2022-05-24T18:44:10.352700892Z I0524 18:44:10.352662       1 request.go:665] Waited for 1.06864592s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T18:44:11.165679736Z I0524 18:44:11.165632       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:27:37Z","message":"NodeInstallerProgressing: 1 nodes are at revision 10; 2 nodes are at revision 11","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 10; 2 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:44:11.172482585Z I0524 18:44:11.172398       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ip-10-0-169-205.ec2.internal on node ip-10-0-169-205.ec2.internal" to "NodeControllerDegraded: All master nodes are ready"
2022-05-24T18:44:11.353119853Z I0524 18:44:11.353080       1 request.go:665] Waited for 1.195746834s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller
2022-05-24T18:44:12.553204959Z I0524 18:44:12.553146       1 request.go:665] Waited for 1.387383732s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-11-ip-10-0-138-197.ec2.internal
2022-05-24T18:44:13.556382012Z I0524 18:44:13.556346       1 request.go:665] Waited for 1.400485218s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-169-205.ec2.internal
2022-05-24T18:44:13.566487181Z I0524 18:44:13.566451       1 installer_controller.go:500] "ip-10-0-169-205.ec2.internal" moving to (v1.NodeStatus) {
2022-05-24T18:44:13.566487181Z  NodeName: (string) (len=28) "ip-10-0-169-205.ec2.internal",
2022-05-24T18:44:13.566487181Z  CurrentRevision: (int32) 11,
2022-05-24T18:44:13.566487181Z  TargetRevision: (int32) 0,
2022-05-24T18:44:13.566487181Z  LastFailedRevision: (int32) 0,
2022-05-24T18:44:13.566487181Z  LastFailedTime: (*v1.Time)(<nil>),
2022-05-24T18:44:13.566487181Z  LastFailedReason: (string) "",
2022-05-24T18:44:13.566487181Z  LastFailedCount: (int) 0,
2022-05-24T18:44:13.566487181Z  LastFallbackCount: (int) 0,
2022-05-24T18:44:13.566487181Z  LastFailedRevisionErrors: ([]string) <nil>
2022-05-24T18:44:13.566487181Z }
2022-05-24T18:44:13.566487181Z  because static pod is ready
2022-05-24T18:44:13.588600512Z I0524 18:44:13.588564       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:44:13Z","message":"NodeInstallerProgressing: 3 nodes are at revision 11","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:44:13.589696047Z I0524 18:44:13.589654       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ip-10-0-169-205.ec2.internal" from revision 10 to 11 because static pod is ready
2022-05-24T18:44:13.604526972Z I0524 18:44:13.604496       1 status_controller.go:211] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2022-05-24T18:35:50Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2022-05-24T18:44:13Z","message":"NodeInstallerProgressing: 3 nodes are at revision 11","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2022-05-24T18:11:07Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2022-05-24T18:07:53Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"}]}}
2022-05-24T18:44:13.606362831Z I0524 18:44:13.605400       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 11"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 10; 2 nodes are at revision 11" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11"
2022-05-24T18:44:13.612802630Z I0524 18:44:13.612767       1 event.go:285] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"4d8dab4b-5ff6-4460-9c0a-6afb71c129aa", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 11"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 nodes are at revision 10; 2 nodes are at revision 11" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 11"
2022-05-24T18:44:14.753440648Z I0524 18:44:14.753405       1 request.go:665] Waited for 1.164733385s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T18:44:15.952741267Z I0524 18:44:15.952710       1 request.go:665] Waited for 1.397710411s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-169-205.ec2.internal
2022-05-24T18:44:17.152803447Z I0524 18:44:17.152768       1 request.go:665] Waited for 1.196580423s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T18:44:18.352595909Z I0524 18:44:18.352557       1 request.go:665] Waited for 1.196904515s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T18:44:19.353236823Z I0524 18:44:19.353203       1 request.go:665] Waited for 1.19811371s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/kube-controller-manager-pod
2022-05-24T18:44:20.553211170Z I0524 18:44:20.553157       1 request.go:665] Waited for 1.197712431s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/trusted-ca-bundle
2022-05-24T18:46:42.800324737Z I0524 18:46:42.800288       1 request.go:665] Waited for 1.111487147s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-149-121.ec2.internal
2022-05-24T18:46:44.000001063Z I0524 18:46:43.999967       1 request.go:665] Waited for 1.39402744s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T18:46:45.000728605Z I0524 18:46:45.000694       1 request.go:665] Waited for 1.396066855s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T18:56:42.729766023Z I0524 18:56:42.729726       1 request.go:665] Waited for 1.040981289s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-138-197.ec2.internal
2022-05-24T18:56:43.929134909Z I0524 18:56:43.929095       1 request.go:665] Waited for 1.395916914s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-169-205.ec2.internal
2022-05-24T18:56:44.929956242Z I0524 18:56:44.929914       1 request.go:665] Waited for 1.396827959s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T19:06:42.796031687Z I0524 19:06:42.795994       1 request.go:665] Waited for 1.107011832s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-149-121.ec2.internal
2022-05-24T19:06:43.796035688Z I0524 19:06:43.796000       1 request.go:665] Waited for 1.393686964s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T19:06:44.996230049Z I0524 19:06:44.996194       1 request.go:665] Waited for 1.395811525s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T19:16:42.868719925Z I0524 19:16:42.868678       1 request.go:665] Waited for 1.181288809s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T19:16:44.068520534Z I0524 19:16:44.068476       1 request.go:665] Waited for 1.39619176s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-169-205.ec2.internal
2022-05-24T19:16:45.268997839Z I0524 19:16:45.268963       1 request.go:665] Waited for 1.196347142s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T19:26:42.748473211Z I0524 19:26:42.748434       1 request.go:665] Waited for 1.04597026s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T19:26:43.749035790Z I0524 19:26:43.748998       1 request.go:665] Waited for 1.396506735s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T19:26:44.948658014Z I0524 19:26:44.948620       1 request.go:665] Waited for 1.195472801s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T19:36:42.786359688Z I0524 19:36:42.786320       1 request.go:665] Waited for 1.097136716s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-149-121.ec2.internal
2022-05-24T19:36:43.786409012Z I0524 19:36:43.786374       1 request.go:665] Waited for 1.396694346s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-169-205.ec2.internal
2022-05-24T19:36:44.986521660Z I0524 19:36:44.986488       1 request.go:665] Waited for 1.195974559s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T19:46:42.884511460Z I0524 19:46:42.884473       1 request.go:665] Waited for 1.181369458s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T19:46:43.884783352Z I0524 19:46:43.884745       1 request.go:665] Waited for 1.396101597s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T19:46:45.084482082Z I0524 19:46:45.084445       1 request.go:665] Waited for 1.194984376s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-169-205.ec2.internal
2022-05-24T19:56:42.886215832Z I0524 19:56:42.886158       1 request.go:665] Waited for 1.18245134s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-149-121.ec2.internal
2022-05-24T19:56:44.085494581Z I0524 19:56:44.085455       1 request.go:665] Waited for 1.391672649s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T19:56:45.085530965Z I0524 19:56:45.085485       1 request.go:665] Waited for 1.396332269s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T20:06:42.884654795Z I0524 20:06:42.884617       1 request.go:665] Waited for 1.180932285s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T20:06:44.084632758Z I0524 20:06:44.084597       1 request.go:665] Waited for 1.395298534s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-138-197.ec2.internal
2022-05-24T20:06:45.284460583Z I0524 20:06:45.284419       1 request.go:665] Waited for 1.195374413s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-138-197.ec2.internal
2022-05-24T20:07:43.212246390Z I0524 20:07:43.212210       1 request.go:665] Waited for 1.065349267s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T20:16:42.887207650Z I0524 20:16:42.887161       1 request.go:665] Waited for 1.180830887s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T20:16:44.086895877Z I0524 20:16:44.086860       1 request.go:665] Waited for 1.39591032s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-169-205.ec2.internal
2022-05-24T20:16:45.087360363Z I0524 20:16:45.087324       1 request.go:665] Waited for 1.196355311s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2022-05-24T20:26:42.887021795Z I0524 20:26:42.886988       1 request.go:665] Waited for 1.180935598s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T20:26:43.887523059Z I0524 20:26:43.887487       1 request.go:665] Waited for 1.392289783s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T20:36:42.888583526Z I0524 20:36:42.888543       1 request.go:665] Waited for 1.177883976s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T20:36:44.089411351Z I0524 20:36:44.089375       1 request.go:665] Waited for 1.396271292s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2022-05-24T20:36:45.288941765Z I0524 20:36:45.288898       1 request.go:665] Waited for 1.1953371s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2022-05-24T20:46:42.889988900Z I0524 20:46:42.889953       1 request.go:665] Waited for 1.173665487s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T20:46:43.890000497Z I0524 20:46:43.889966       1 request.go:665] Waited for 1.395525379s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-169-205.ec2.internal
2022-05-24T20:46:45.089417694Z I0524 20:46:45.089380       1 request.go:665] Waited for 1.395820111s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2022-05-24T20:56:42.788105303Z I0524 20:56:42.788075       1 request.go:665] Waited for 1.087113615s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T20:56:43.987356336Z I0524 20:56:43.987317       1 request.go:665] Waited for 1.393629129s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T20:56:44.987682107Z I0524 20:56:44.987647       1 request.go:665] Waited for 1.395786453s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-138-197.ec2.internal
2022-05-24T21:06:42.872647138Z I0524 21:06:42.872606       1 request.go:665] Waited for 1.170769866s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T21:06:43.873280791Z I0524 21:06:43.873246       1 request.go:665] Waited for 1.396161858s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-169-205.ec2.internal
2022-05-24T21:06:44.873361419Z I0524 21:06:44.873322       1 request.go:665] Waited for 1.396017292s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/serving-cert
2022-05-24T21:16:42.744434470Z I0524 21:16:42.744396       1 request.go:665] Waited for 1.03595864s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T21:16:43.944540805Z I0524 21:16:43.944504       1 request.go:665] Waited for 1.396356328s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-169-205.ec2.internal
2022-05-24T21:16:45.144249950Z I0524 21:16:45.144199       1 request.go:665] Waited for 1.396011095s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T21:26:42.817664342Z I0524 21:26:42.817619       1 request.go:665] Waited for 1.115630623s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T21:26:44.017687671Z I0524 21:26:44.017645       1 request.go:665] Waited for 1.394827963s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-169-205.ec2.internal
2022-05-24T21:26:45.217606447Z I0524 21:26:45.217569       1 request.go:665] Waited for 1.195225617s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T21:36:42.879221191Z I0524 21:36:42.879164       1 request.go:665] Waited for 1.168108776s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T21:36:44.078906564Z I0524 21:36:44.078863       1 request.go:665] Waited for 1.39339205s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T21:36:45.079265490Z I0524 21:36:45.079230       1 request.go:665] Waited for 1.396049519s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T21:46:42.759615074Z I0524 21:46:42.759568       1 request.go:665] Waited for 1.056737977s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T21:46:43.759939291Z I0524 21:46:43.759901       1 request.go:665] Waited for 1.394783822s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T21:46:44.959431507Z I0524 21:46:44.959397       1 request.go:665] Waited for 1.395816457s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-169-205.ec2.internal
2022-05-24T21:55:43.401510978Z I0524 21:55:43.401469       1 request.go:665] Waited for 1.192695102s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T21:56:42.826822686Z I0524 21:56:42.826781       1 request.go:665] Waited for 1.114617634s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T21:56:43.827846948Z I0524 21:56:43.827813       1 request.go:665] Waited for 1.395299614s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T21:56:45.027173440Z I0524 21:56:45.027135       1 request.go:665] Waited for 1.394929308s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T22:06:42.893640478Z I0524 22:06:42.893606       1 request.go:665] Waited for 1.166078363s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T22:06:43.893862905Z I0524 22:06:43.893827       1 request.go:665] Waited for 1.396258275s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/recycler-config
2022-05-24T22:06:45.093581090Z I0524 22:06:45.093542       1 request.go:665] Waited for 1.195627768s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2022-05-24T22:16:42.894449458Z I0524 22:16:42.894415       1 request.go:665] Waited for 1.176938879s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T22:16:44.094108187Z I0524 22:16:44.094068       1 request.go:665] Waited for 1.39488309s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T22:16:45.094592903Z I0524 22:16:45.094541       1 request.go:665] Waited for 1.396774328s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-169-205.ec2.internal
2022-05-24T22:26:42.894839355Z I0524 22:26:42.894792       1 request.go:665] Waited for 1.178636242s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/recycler-config
2022-05-24T22:26:43.895035361Z I0524 22:26:43.895003       1 request.go:665] Waited for 1.388174743s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T22:26:45.095043510Z I0524 22:26:45.095010       1 request.go:665] Waited for 1.396438547s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-138-197.ec2.internal
2022-05-24T22:36:42.895093907Z I0524 22:36:42.895057       1 request.go:665] Waited for 1.173802155s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/recycler-config
2022-05-24T22:36:43.895349745Z I0524 22:36:43.895315       1 request.go:665] Waited for 1.393550882s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T22:36:44.895732753Z I0524 22:36:44.895700       1 request.go:665] Waited for 1.395433658s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T22:46:42.798465049Z I0524 22:46:42.798420       1 request.go:665] Waited for 1.081446633s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T22:46:43.999260605Z I0524 22:46:43.999223       1 request.go:665] Waited for 1.392498123s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T22:46:45.198617149Z I0524 22:46:45.198580       1 request.go:665] Waited for 1.395748506s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2022-05-24T22:56:42.897838558Z I0524 22:56:42.897803       1 request.go:665] Waited for 1.179014641s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T22:56:43.898234276Z I0524 22:56:43.898189       1 request.go:665] Waited for 1.395842642s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/recycler-config
2022-05-24T22:56:45.097975753Z I0524 22:56:45.097940       1 request.go:665] Waited for 1.195923325s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2022-05-24T23:00:43.450722525Z I0524 23:00:43.450281       1 request.go:665] Waited for 1.040122416s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2022-05-24T23:06:42.899736323Z I0524 23:06:42.899700       1 request.go:665] Waited for 1.18095389s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-149-121.ec2.internal
2022-05-24T23:06:43.899876210Z I0524 23:06:43.899841       1 request.go:665] Waited for 1.395894216s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/recycler-config
2022-05-24T23:06:44.900389574Z I0524 23:06:44.900353       1 request.go:665] Waited for 1.392444126s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T23:16:42.900196939Z I0524 23:16:42.900148       1 request.go:665] Waited for 1.172528328s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2022-05-24T23:16:44.100613926Z I0524 23:16:44.100572       1 request.go:665] Waited for 1.394551382s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T23:16:45.300571337Z I0524 23:16:45.300536       1 request.go:665] Waited for 1.396857096s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-138-197.ec2.internal
2022-05-24T23:26:42.747651310Z I0524 23:26:42.747618       1 request.go:665] Waited for 1.036148168s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T23:26:43.748104937Z I0524 23:26:43.748073       1 request.go:665] Waited for 1.395912555s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-169-205.ec2.internal
2022-05-24T23:26:44.748331580Z I0524 23:26:44.748299       1 request.go:665] Waited for 1.395866218s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/serving-cert
2022-05-24T23:36:42.898513269Z I0524 23:36:42.898472       1 request.go:665] Waited for 1.186862574s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ip-10-0-138-197.ec2.internal
2022-05-24T23:36:43.899157514Z I0524 23:36:43.899122       1 request.go:665] Waited for 1.394619789s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2022-05-24T23:36:45.098752099Z I0524 23:36:45.098715       1 request.go:665] Waited for 1.396036573s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ip-10-0-149-121.ec2.internal
