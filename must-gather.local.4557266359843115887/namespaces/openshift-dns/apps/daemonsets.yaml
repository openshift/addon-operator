---
apiVersion: apps/v1
items:
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
    creationTimestamp: "2022-05-24T18:08:40Z"
    generation: 1
    labels:
      dns.operator.openshift.io/owning-dns: default
    name: dns-default
    namespace: openshift-dns
    ownerReferences:
    - apiVersion: operator.openshift.io/v1
      controller: true
      kind: DNS
      name: default
      uid: b49f021b-a5b7-4c17-bfd7-641f00278e28
    resourceVersion: "78993"
    uid: 2506942e-8a5d-4746-b652-998f429f15b9
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        dns.operator.openshift.io/daemonset-dns: default
    template:
      metadata:
        annotations:
          target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
        creationTimestamp: null
        labels:
          dns.operator.openshift.io/daemonset-dns: default
      spec:
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          command:
          - coredns
          image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:ceb0d1d2015b87e9daf3e57b93f5464f15a1386a6bcab5442b7dba594b058b24
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: dns
          ports:
          - containerPort: 5353
            name: dns
            protocol: UDP
          - containerPort: 5353
            name: dns-tcp
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 3
            successThreshold: 1
            timeoutSeconds: 3
          resources:
            requests:
              cpu: 50m
              memory: 70Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
        - args:
          - --logtostderr
          - --secure-listen-address=:9154
          - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
          - --upstream=http://127.0.0.1:9153/
          - --tls-cert-file=/etc/tls/private/tls.crt
          - --tls-private-key-file=/etc/tls/private/tls.key
          image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:08e8b4004edaeeb125ced09ab2c4cd6d690afaf3a86309c91a994dec8e3ccbf3
          imagePullPolicy: IfNotPresent
          name: kube-rbac-proxy
          ports:
          - containerPort: 9154
            name: metrics
            protocol: TCP
          resources:
            requests:
              cpu: 10m
              memory: 40Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/tls/private
            name: metrics-tls
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: dns
        serviceAccountName: dns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: node-role.kubernetes.io/master
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            name: dns-default
          name: config-volume
        - name: metrics-tls
          secret:
            defaultMode: 420
            secretName: dns-default-metrics-tls
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 10%
      type: RollingUpdate
  status:
    currentNumberScheduled: 6
    desiredNumberScheduled: 6
    numberAvailable: 6
    numberMisscheduled: 0
    numberReady: 6
    observedGeneration: 1
    updatedNumberScheduled: 6
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
    creationTimestamp: "2022-05-24T18:08:40Z"
    generation: 1
    name: node-resolver
    namespace: openshift-dns
    ownerReferences:
    - apiVersion: operator.openshift.io/v1
      controller: true
      kind: DNS
      name: default
      uid: b49f021b-a5b7-4c17-bfd7-641f00278e28
    resourceVersion: "78517"
    uid: 5c7de9d0-6112-4b2c-b19d-25616e667710
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        dns.operator.openshift.io/daemonset-node-resolver: ""
    template:
      metadata:
        annotations:
          target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
        creationTimestamp: null
        labels:
          dns.operator.openshift.io/daemonset-node-resolver: ""
      spec:
        containers:
        - command:
          - /bin/bash
          - -c
          - |
            #!/bin/bash
            set -uo pipefail

            trap 'jobs -p | xargs kill || true; wait; exit 0' TERM

            OPENSHIFT_MARKER="openshift-generated-node-resolver"
            HOSTS_FILE="/etc/hosts"
            TEMP_FILE="/etc/hosts.tmp"

            IFS=', ' read -r -a services <<< "${SERVICES}"

            # Make a temporary file with the old hosts file's attributes.
            cp -f --attributes-only "${HOSTS_FILE}" "${TEMP_FILE}"

            while true; do
              declare -A svc_ips
              for svc in "${services[@]}"; do
                # Fetch service IP from cluster dns if present. We make several tries
                # to do it: IPv4, IPv6, IPv4 over TCP and IPv6 over TCP. The two last ones
                # are for deployments with Kuryr on older OpenStack (OSP13) - those do not
                # support UDP loadbalancers and require reaching DNS through TCP.
                cmds=('dig -t A @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                      'dig -t AAAA @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                      'dig -t A +tcp +retry=0 @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                      'dig -t AAAA +tcp +retry=0 @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"')
                for i in ${!cmds[*]}
                do
                  ips=($(eval "${cmds[i]}"))
                  if [[ "$?" -eq 0 && "${#ips[@]}" -ne 0 ]]; then
                    svc_ips["${svc}"]="${ips[@]}"
                    break
                  fi
                done
              done

              # Update /etc/hosts only if we get valid service IPs
              # We will not update /etc/hosts when there is coredns service outage or api unavailability
              # Stale entries could exist in /etc/hosts if the service is deleted
              if [[ -n "${svc_ips[*]-}" ]]; then
                # Build a new hosts file from /etc/hosts with our custom entries filtered out
                grep -v "# ${OPENSHIFT_MARKER}" "${HOSTS_FILE}" > "${TEMP_FILE}"

                # Append resolver entries for services
                for svc in "${!svc_ips[@]}"; do
                  for ip in ${svc_ips[${svc}]}; do
                    echo "${ip} ${svc} ${svc}.${CLUSTER_DOMAIN} # ${OPENSHIFT_MARKER}" >> "${TEMP_FILE}"
                  done
                done

                # TODO: Update /etc/hosts atomically to avoid any inconsistent behavior
                # Replace /etc/hosts with our modified version if needed
                cmp "${TEMP_FILE}" "${HOSTS_FILE}" || cp -f "${TEMP_FILE}" "${HOSTS_FILE}"
                # TEMP_FILE is not removed to avoid file create/delete and attributes copy churn
              fi
              sleep 60 & wait
              unset svc_ips
            done
          env:
          - name: SERVICES
            value: image-registry.openshift-image-registry.svc
          - name: NAMESERVER
            value: 172.30.0.10
          - name: CLUSTER_DOMAIN
            value: cluster.local
          image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5cb8eed4d9713a7a3da331026e21773c76d52feef9a591921807ccf217f66757
          imagePullPolicy: IfNotPresent
          name: dns-node-resolver
          resources:
            requests:
              cpu: 5m
              memory: 21Mi
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
          - mountPath: /etc/hosts
            name: hosts-file
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: node-resolver
        serviceAccountName: node-resolver
        terminationGracePeriodSeconds: 30
        tolerations:
        - operator: Exists
        volumes:
        - hostPath:
            path: /etc/hosts
            type: File
          name: hosts-file
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 33%
      type: RollingUpdate
  status:
    currentNumberScheduled: 9
    desiredNumberScheduled: 9
    numberAvailable: 9
    numberMisscheduled: 0
    numberReady: 9
    observedGeneration: 1
    updatedNumberScheduled: 9
kind: DaemonSetList
metadata:
  resourceVersion: "310265"
